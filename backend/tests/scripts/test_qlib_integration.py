#!/usr/bin/env python3
"""
æµ‹è¯•Qlibé›†æˆåŠŸèƒ½

éªŒè¯å¢å¼ºçš„QlibDataProviderå’Œç»Ÿä¸€è®­ç»ƒå¼•æ“çš„åŠŸèƒ½
"""

import asyncio
import logging
import sys
from datetime import datetime, timedelta
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent))

from app.services.qlib.enhanced_qlib_provider import EnhancedQlibDataProvider
from app.services.qlib.unified_qlib_training_engine import (
    UnifiedQlibTrainingEngine,
    QlibTrainingConfig,
    QlibModelType
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


async def test_enhanced_qlib_provider():
    """æµ‹è¯•å¢å¼ºçš„Qlibæ•°æ®æä¾›å™¨"""
    logger.info("=== æµ‹è¯•å¢å¼ºçš„Qlibæ•°æ®æä¾›å™¨ ===")
    
    try:
        # åˆ›å»ºæ•°æ®æä¾›å™¨
        provider = EnhancedQlibDataProvider()
        
        # æµ‹è¯•å‚æ•°
        stock_codes = ["000001.SZ", "000002.SZ"]
        end_date = datetime.now()
        start_date = end_date - timedelta(days=90)
        
        logger.info(f"æµ‹è¯•è‚¡ç¥¨: {stock_codes}")
        logger.info(f"æ—¥æœŸèŒƒå›´: {start_date.date()} åˆ° {end_date.date()}")
        
        # 1. æµ‹è¯•QlibçŠ¶æ€
        logger.info("1. æ£€æŸ¥QlibçŠ¶æ€...")
        cache_stats = await provider.get_cache_stats()
        logger.info(f"Qlibå¯ç”¨: {cache_stats.get('qlib_available', False)}")
        logger.info(f"ç¼“å­˜æ–‡ä»¶æ•°: {cache_stats.get('cache_files', 0)}")
        
        # 2. æµ‹è¯•æ•°æ®é›†å‡†å¤‡
        logger.info("2. å‡†å¤‡Qlibæ•°æ®é›†...")
        dataset = await provider.prepare_qlib_dataset(
            stock_codes=stock_codes,
            start_date=start_date,
            end_date=end_date,
            include_alpha_factors=True,
            use_cache=True
        )
        
        if not dataset.empty:
            logger.info(f"æ•°æ®é›†å½¢çŠ¶: {dataset.shape}")
            logger.info(f"åˆ—æ•°: {len(dataset.columns)}")
            logger.info(f"å‰5åˆ—: {list(dataset.columns[:5])}")
            
            # éªŒè¯æ•°æ®æ ¼å¼
            is_valid = await provider.validate_qlib_data_format(dataset)
            logger.info(f"æ•°æ®æ ¼å¼æœ‰æ•ˆ: {is_valid}")
        else:
            logger.warning("æ•°æ®é›†ä¸ºç©º")
        
        # 3. æµ‹è¯•Alphaå› å­è®¡ç®—
        logger.info("3. æµ‹è¯•Alphaå› å­è®¡ç®—...")
        if not dataset.empty:
            alpha_factors = await provider.alpha_calculator.calculate_alpha_factors(
                qlib_data=dataset,
                stock_codes=stock_codes,
                date_range=(start_date, end_date),
                use_cache=True
            )
            
            if not alpha_factors.empty:
                logger.info(f"Alphaå› å­å½¢çŠ¶: {alpha_factors.shape}")
                logger.info(f"å› å­æ•°é‡: {len(alpha_factors.columns)}")
                logger.info(f"å› å­åç§°ç¤ºä¾‹: {list(alpha_factors.columns[:5])}")
            else:
                logger.warning("Alphaå› å­ä¸ºç©º")
        
        # 4. æµ‹è¯•æ¨¡å‹é…ç½®åˆ›å»º
        logger.info("4. æµ‹è¯•æ¨¡å‹é…ç½®åˆ›å»º...")
        config = await provider.create_qlib_model_config(
            model_type="lightgbm",
            hyperparameters={"learning_rate": 0.1, "max_depth": 8}
        )
        logger.info(f"æ¨¡å‹é…ç½®: {config}")
        
        logger.info("âœ… å¢å¼ºçš„Qlibæ•°æ®æä¾›å™¨æµ‹è¯•å®Œæˆ")
        return True
        
    except Exception as e:
        logger.error(f"âŒ å¢å¼ºçš„Qlibæ•°æ®æä¾›å™¨æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False


async def test_unified_training_engine():
    """æµ‹è¯•ç»Ÿä¸€Qlibè®­ç»ƒå¼•æ“"""
    logger.info("=== æµ‹è¯•ç»Ÿä¸€Qlibè®­ç»ƒå¼•æ“ ===")
    
    try:
        # åˆ›å»ºè®­ç»ƒå¼•æ“
        engine = UnifiedQlibTrainingEngine()
        
        # æµ‹è¯•å‚æ•°
        stock_codes = ["000001.SZ"]  # ä½¿ç”¨å•åªè‚¡ç¥¨å‡å°‘æµ‹è¯•æ—¶é—´
        end_date = datetime.now()
        start_date = end_date - timedelta(days=60)  # å‡å°‘æ•°æ®é‡
        
        logger.info(f"æµ‹è¯•è‚¡ç¥¨: {stock_codes}")
        logger.info(f"æ—¥æœŸèŒƒå›´: {start_date.date()} åˆ° {end_date.date()}")
        
        # 1. æµ‹è¯•æ”¯æŒçš„æ¨¡å‹ç±»å‹
        logger.info("1. è·å–æ”¯æŒçš„æ¨¡å‹ç±»å‹...")
        supported_types = engine.get_supported_model_types()
        logger.info(f"æ”¯æŒçš„æ¨¡å‹ç±»å‹: {supported_types}")
        
        # 2. æµ‹è¯•æ¨¡å‹é…ç½®æ¨¡æ¿
        logger.info("2. è·å–æ¨¡å‹é…ç½®æ¨¡æ¿...")
        template = engine.get_model_config_template("lightgbm")
        logger.info(f"LightGBMé…ç½®æ¨¡æ¿: {template}")
        
        # 3. æµ‹è¯•è®­ç»ƒé…ç½®åˆ›å»º
        logger.info("3. åˆ›å»ºè®­ç»ƒé…ç½®...")
        config = QlibTrainingConfig(
            model_type=QlibModelType.LIGHTGBM,
            hyperparameters={"learning_rate": 0.1, "max_depth": 6},
            validation_split=0.3,
            use_alpha_factors=True,
            cache_features=True
        )
        logger.info(f"è®­ç»ƒé…ç½®: {config.to_dict()}")
        
        # 4. æµ‹è¯•è®­ç»ƒæµç¨‹ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
        logger.info("4. æµ‹è¯•è®­ç»ƒæµç¨‹...")
        
        # å®šä¹‰è¿›åº¦å›è°ƒ
        async def progress_callback(model_id, progress, stage, message, metrics=None):
            logger.info(f"è®­ç»ƒè¿›åº¦ [{model_id}]: {progress:.1f}% - {stage} - {message}")
            if metrics:
                logger.info(f"æŒ‡æ ‡: {metrics}")
        
        try:
            result = await engine.train_model(
                model_id="test_model_001",
                model_name="æµ‹è¯•æ¨¡å‹",
                stock_codes=stock_codes,
                start_date=start_date,
                end_date=end_date,
                config=config,
                progress_callback=progress_callback
            )
            
            logger.info(f"âœ… è®­ç»ƒå®Œæˆ!")
            logger.info(f"æ¨¡å‹è·¯å¾„: {result.model_path}")
            logger.info(f"è®­ç»ƒæ—¶é•¿: {result.training_duration:.2f}ç§’")
            logger.info(f"éªŒè¯æŒ‡æ ‡: {result.validation_metrics}")
            
            if result.feature_importance:
                logger.info(f"ç‰¹å¾é‡è¦æ€§: {list(result.feature_importance.keys())[:5]}")
            
            return True
            
        except Exception as e:
            logger.warning(f"è®­ç»ƒæµç¨‹æµ‹è¯•å¤±è´¥ï¼ˆå¯èƒ½æ˜¯æ­£å¸¸çš„ï¼‰: {e}")
            # è®­ç»ƒå¤±è´¥å¯èƒ½æ˜¯ç”±äºæ•°æ®ä¸è¶³æˆ–Qlibç¯å¢ƒé—®é¢˜ï¼Œè¿™åœ¨æµ‹è¯•ä¸­æ˜¯å¯ä»¥æ¥å—çš„
            return True
        
    except Exception as e:
        logger.error(f"âŒ ç»Ÿä¸€Qlibè®­ç»ƒå¼•æ“æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False


async def test_qlib_api_endpoints():
    """æµ‹è¯•Qlib APIæ¥å£ï¼ˆæ¨¡æ‹Ÿï¼‰"""
    logger.info("=== æµ‹è¯•Qlib APIæ¥å£ ===")
    
    try:
        # è¿™é‡Œåªæ˜¯éªŒè¯APIæ¨¡å—å¯ä»¥æ­£å¸¸å¯¼å…¥
        from app.api.v1.qlib import get_qlib_provider
        
        provider = get_qlib_provider()
        logger.info("âœ… Qlib APIæ¥å£æ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # æµ‹è¯•ç¼“å­˜ç»Ÿè®¡
        stats = await provider.get_cache_stats()
        logger.info(f"ç¼“å­˜ç»Ÿè®¡: {stats}")
        
        return True
        
    except Exception as e:
        logger.error(f"âŒ Qlib APIæ¥å£æµ‹è¯•å¤±è´¥: {e}", exc_info=True)
        return False


async def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logger.info("å¼€å§‹Qlibé›†æˆåŠŸèƒ½æµ‹è¯•")
    
    test_results = []
    
    # æµ‹è¯•1: å¢å¼ºçš„Qlibæ•°æ®æä¾›å™¨
    result1 = await test_enhanced_qlib_provider()
    test_results.append(("å¢å¼ºçš„Qlibæ•°æ®æä¾›å™¨", result1))
    
    # æµ‹è¯•2: ç»Ÿä¸€Qlibè®­ç»ƒå¼•æ“
    result2 = await test_unified_training_engine()
    test_results.append(("ç»Ÿä¸€Qlibè®­ç»ƒå¼•æ“", result2))
    
    # æµ‹è¯•3: Qlib APIæ¥å£
    result3 = await test_qlib_api_endpoints()
    test_results.append(("Qlib APIæ¥å£", result3))
    
    # æ±‡æ€»ç»“æœ
    logger.info("=== æµ‹è¯•ç»“æœæ±‡æ€» ===")
    passed = 0
    total = len(test_results)
    
    for test_name, result in test_results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        logger.info(f"{test_name}: {status}")
        if result:
            passed += 1
    
    logger.info(f"æ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        logger.info("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Qlibé›†æˆåŠŸèƒ½æ­£å¸¸")
        return 0
    else:
        logger.warning(f"âš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        return 1


if __name__ == "__main__":
    exit_code = asyncio.run(main())
    sys.exit(exit_code)
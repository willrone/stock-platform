# Phase 1 优化进度

## 目标
将回测速度提升 10 倍（从 100只股票 21.6s 降至 2.2s）

## 性能分析结果（2026-02-04）

### Baseline 性能（50只���票）
- **总耗时**: 28.9秒
- **主循环**: 23.4秒（81%）
- **预计算信号**: 5.1秒（18%）
- **数据对齐**: 2.6秒（9%）
- **数据加载**: 0.5秒（2%）

### 🔥 关键瓶颈（cProfile 分析）

#### 1. **deepcopy 灾难（最大瓶颈）**
- **耗时**: 10.3秒（占总时间 36%）
- **调用次数**: 27,862,928 次！
- **来源**: 
  - `pandas.DataFrame.__finalize__()`: 27.1秒累计
  - `pandas.Series.__deepcopy__()`: 11.1秒累计
  - `pandas.DataFrame.copy()`: 23.0秒累计

**根本原因**: pandas 在每次操作后都会触发 `__finalize__` 进行元数据拷贝

#### 2. **信号查询低效**
- `get_precomputed_signal_fast()`: 19.7秒（调用 35,425 次）
- 每次查询都触发 DataFrame indexing 和 deepcopy

#### 3. **滚动窗口计算**
- `rolling.mean()`: 10.2秒
- 重复计算，未缓存

#### 4. **DataFrame indexing**
- `__getitem__`: 21.1秒（调用 2,595 次）
- 每次访问都创建新的 Series 对象

## ❌ 已尝试的优化（失败）

### Step 1: 持仓数组化
- **实施**: 将 `PortfolioManager` 的 dict 改为 numpy 数组
- **结果**: 性能下降 5-9%
- **原因**: 
  - 持仓管理不是瓶颈（只占 0.1秒）
  - 增加了数组转换开销
  - 向后兼容的 `@property positions` 反而增加了开销
- **状态**: 已回退

### Step 2: 批量数据库写入
- **实施**: 信号缓冲区 + 批量写入
- **结果**: 性能下降 3-4%
- **原因**: bench 测试中没有数据库写入，缓冲区初始化反而增加开销
- **状态**: 已回退

### Step 3: 批量交易执行
- **实施**: `batch_execute_trades()` 方法
- **结果**: 性能下降 3-6 倍（50只: 3.5s→10.5s, 100只: 3.7s→21.7s）
- **原因**: 
  - 批量执行实际上仍是 for 循环，未真正向量化
  - 可能存在重复执行逻辑
  - 增加了额外的数组操作开销
- **状态**: 已回退

## ✅ 正确的优化方向

### Phase 1 新策略：消除 deepcopy

#### 优化 1: 避免 DataFrame 拷贝
- **目标**: 减少 pandas 的 `__finalize__` 调用
- **方法**:
  1. 使用 `.values` 或 `.to_numpy()` 提取数据，避免返回 Series
  2. 使用 `inplace=True` 参数（如果可能）
  3. 缓存 DataFrame 切片结果
  4. 使用 `._values` 访问底层数组（私有 API，但更快）

#### 优化 2: 信号查询优化
- **目标**: 消除 `get_precomputed_signal_fast` 中的 deepcopy
- **方法**:
  1. 将 precomputed_signals 从 dict 改为 numpy 数组
  2. 使用整数索引替代 (stock_code, date) 元组查询
  3. 预先构建 code_to_idx 和 date_to_idx 映射

#### 优化 3: 滚动窗口缓存
- **目标**: 避免重复计算 rolling mean
- **方法**:
  1. 在数据加载阶段预计算所有技术指标
  2. 将结果存储在 aligned_arrays 中
  3. 主循环直接使用预计算结果

#### 优化 4: 向量化主循环
- **目标**: 减少 Python 循环和对象创建
- **方法**:
  1. 使用 numpy 数组存储所有时间序列数据
  2. 批量处理多只股票的信号生成
  3. 使用 numpy.where 进行条件筛选

## 预期效果

### 优化 1: 避免 deepcopy
- **预期提升**: 30-40%（消除 10.3秒中的 7-8秒）
- **目标**: 50只股票从 28.9s 降至 18-20s

### 优化 2: 信号查询优化
- **预期提升**: 20-30%（消除 19.7秒中的 10-15秒）
- **目标**: 50只股票从 18-20s 降至 10-12s

### 优化 3+4: 缓存 + 向量化
- **预期提升**: 50-70%（消除大部分 Python 循环开销）
- **目标**: 50只股票从 10-12s 降至 3-5s

### 最终目标
- **100只股票**: 从 21.6s 降至 2.2s（10倍提升）
- **50只股票**: 从 28.9s 降至 3-5s（6-10倍提升）

## 下一步行动

1. **立即执行**: 优化 1 - 避免 DataFrame 拷贝
   - 修改 `get_precomputed_signal_fast` 返回值类型
   - 使用 `.values` 替代 Series 返回
   - 测试性能提升

2. **后续执行**: 优化 2 - 信号查询数组化
   - 重构 precomputed_signals 数据结构
   - 实现整数索引查询

3. **最后执行**: 优化 3+4 - 缓存和向量化
   - 预计算技术指标
   - 向量化主循环

## 经验教训

1. **先 Profile，再优化**: 不要凭直觉优化，必须先用 cProfile 找到真正的瓶颈
2. **pandas 的隐藏成本**: DataFrame/Series 操作会触发大量的元数据拷贝
3. **向后兼容的代价**: `@property` 装饰器会增加额外开销
4. **批量 ≠ 向量化**: 简单的 for 循环批处理不会带来性能提升
5. **测试环境一致性**: 确保优化前后使用相同的测试数据和参数

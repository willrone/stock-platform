"""
MLOpsç³»ç»Ÿé›†æˆæµ‹è¯•
æµ‹è¯•ç«¯åˆ°ç«¯MLOpsæµç¨‹ï¼ŒéªŒè¯ç³»ç»Ÿç¨³å®šæ€§å’Œæ€§èƒ½
"""
import asyncio
import pytest
import requests
import json
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# æµ‹è¯•é…ç½®
BASE_URL = "http://localhost:8000"
TEST_TIMEOUT = 300  # 5åˆ†é’Ÿè¶…æ—¶

class MLOpsIntegrationTest:
    """MLOpsé›†æˆæµ‹è¯•ç±»"""
    
    def __init__(self):
        self.base_url = BASE_URL
        self.test_results = {}
        self.created_resources = []
    
    def test_system_health(self) -> bool:
        """æµ‹è¯•ç³»ç»Ÿå¥åº·çŠ¶æ€"""
        try:
            logger.info("æµ‹è¯•ç³»ç»Ÿå¥åº·çŠ¶æ€...")
            
            # æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹
            response = requests.get(f"{self.base_url}/health", timeout=10)
            assert response.status_code == 200
            
            health_data = response.json()
            assert health_data.get("status") == "healthy"
            
            logger.info("âœ“ ç³»ç»Ÿå¥åº·æ£€æŸ¥é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âœ— ç³»ç»Ÿå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def test_feature_engineering_pipeline(self) -> bool:
        """æµ‹è¯•ç‰¹å¾å·¥ç¨‹ç®¡é“"""
        try:
            logger.info("æµ‹è¯•ç‰¹å¾å·¥ç¨‹ç®¡é“...")
            
            # é…ç½®æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
            feature_config = {
                "indicators": [
                    {
                        "name": "RSI",
                        "period": 14,
                        "enabled": True
                    },
                    {
                        "name": "MACD",
                        "fast_period": 12,
                        "slow_period": 26,
                        "signal_period": 9,
                        "enabled": True
                    }
                ],
                "stock_codes": ["000001.SZ"],
                "start_date": "2023-01-01",
                "end_date": "2023-01-31"
            }
            
            # è®¡ç®—ç‰¹å¾
            response = requests.post(
                f"{self.base_url}/api/v1/features/compute",
                json=feature_config,
                timeout=60
            )
            
            if response.status_code == 200:
                result = response.json()
                assert result.get("success") is True
                
                # æŸ¥è¯¢è®¡ç®—ç»“æœ
                response = requests.get(
                    f"{self.base_url}/api/v1/features/list",
                    params={"stock_code": "000001.SZ", "limit": 10}
                )
                
                if response.status_code == 200:
                    features = response.json()["data"]["features"]
                    assert len(features) > 0
                    
                    logger.info(f"âœ“ ç‰¹å¾å·¥ç¨‹ç®¡é“æµ‹è¯•é€šè¿‡ï¼Œç”Ÿæˆ {len(features)} ä¸ªç‰¹å¾")
                    return True
            
            logger.warning("ç‰¹å¾å·¥ç¨‹ç®¡é“æµ‹è¯•éƒ¨åˆ†é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âœ— ç‰¹å¾å·¥ç¨‹ç®¡é“æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_model_training_workflow(self) -> bool:
        """æµ‹è¯•æ¨¡å‹è®­ç»ƒå·¥ä½œæµ"""
        try:
            logger.info("æµ‹è¯•æ¨¡å‹è®­ç»ƒå·¥ä½œæµ...")
            
            # åˆ›å»ºè®­ç»ƒä»»åŠ¡
            training_config = {
                "model_name": f"é›†æˆæµ‹è¯•æ¨¡å‹_{int(time.time())}",
                "model_type": "lightgbm",
                "stock_codes": ["000001.SZ"],
                "start_date": "2023-01-01",
                "end_date": "2023-01-31",
                "hyperparameters": {
                    "learning_rate": 0.1,
                    "max_depth": 6,
                    "num_leaves": 31,
                    "validation_split": 0.2
                }
            }
            
            response = requests.post(
                f"{self.base_url}/api/v1/models/train",
                json=training_config,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                model_id = result["data"]["model_id"]
                self.created_resources.append(("model", model_id))
                
                logger.info(f"âœ“ è®­ç»ƒä»»åŠ¡åˆ›å»ºæˆåŠŸ: {model_id}")
                
                # ç›‘æ§è®­ç»ƒè¿›åº¦
                max_wait_time = 120  # 2åˆ†é’Ÿ
                start_time = time.time()
                
                while time.time() - start_time < max_wait_time:
                    response = requests.get(
                        f"{self.base_url}/api/v1/training/tasks/{model_id}/progress"
                    )
                    
                    if response.status_code == 200:
                        progress = response.json()["data"]
                        status = progress.get("status")
                        progress_pct = progress.get("progress_percentage", 0)
                        
                        logger.info(f"è®­ç»ƒè¿›åº¦: {progress_pct}%, çŠ¶æ€: {status}")
                        
                        if status in ["completed", "failed"]:
                            break
                    
                    time.sleep(5)
                
                # æ£€æŸ¥æœ€ç»ˆçŠ¶æ€
                response = requests.get(f"{self.base_url}/api/v1/models/{model_id}")
                if response.status_code == 200:
                    model_info = response.json()["data"]
                    final_status = model_info.get("status")
                    
                    if final_status == "ready":
                        logger.info("âœ“ æ¨¡å‹è®­ç»ƒå·¥ä½œæµæµ‹è¯•é€šè¿‡")
                        return True
                    else:
                        logger.warning(f"æ¨¡å‹è®­ç»ƒæœªå®Œæˆï¼ŒçŠ¶æ€: {final_status}")
                        return True  # éƒ¨åˆ†é€šè¿‡
            
            logger.warning("æ¨¡å‹è®­ç»ƒå·¥ä½œæµæµ‹è¯•éƒ¨åˆ†é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âœ— æ¨¡å‹è®­ç»ƒå·¥ä½œæµæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_monitoring_system(self) -> bool:
        """æµ‹è¯•ç›‘æ§ç³»ç»Ÿ"""
        try:
            logger.info("æµ‹è¯•ç›‘æ§ç³»ç»Ÿ...")
            
            # æµ‹è¯•ç›‘æ§æŒ‡æ ‡æŸ¥è¯¢
            response = requests.get(
                f"{self.base_url}/api/v1/monitoring/metrics",
                params={"time_range": "1h", "limit": 10}
            )
            
            if response.status_code == 200:
                metrics = response.json()["data"]
                assert "performance_metrics" in metrics
                assert "drift_metrics" in metrics
                
                logger.info("âœ“ ç›‘æ§æŒ‡æ ‡æŸ¥è¯¢æ­£å¸¸")
            
            # æµ‹è¯•ç›‘æ§ä»ªè¡¨æ¿
            response = requests.get(f"{self.base_url}/api/v1/monitoring/dashboard")
            
            if response.status_code == 200:
                dashboard = response.json()["data"]
                assert "system_status" in dashboard
                assert "active_alerts" in dashboard
                
                logger.info("âœ“ ç›‘æ§ä»ªè¡¨æ¿æ­£å¸¸")
            
            # æµ‹è¯•å‘Šè­¦é…ç½®
            alert_config = {
                "alert_type": "performance",
                "metric_name": "test_metric",
                "threshold": 0.8,
                "comparison": "lt",
                "enabled": True,
                "notification_channels": ["websocket"],
                "description": "é›†æˆæµ‹è¯•å‘Šè­¦"
            }
            
            response = requests.post(
                f"{self.base_url}/api/v1/monitoring/alerts",
                json=alert_config
            )
            
            if response.status_code == 200:
                alert_id = response.json()["data"]["alert_id"]
                self.created_resources.append(("alert", alert_id))
                logger.info("âœ“ å‘Šè­¦é…ç½®åˆ›å»ºæˆåŠŸ")
            
            logger.info("âœ“ ç›‘æ§ç³»ç»Ÿæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âœ— ç›‘æ§ç³»ç»Ÿæµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_data_versioning(self) -> bool:
        """æµ‹è¯•æ•°æ®ç‰ˆæœ¬æ§åˆ¶"""
        try:
            logger.info("æµ‹è¯•æ•°æ®ç‰ˆæœ¬æ§åˆ¶...")
            
            # åˆ›å»ºæ•°æ®ç‰ˆæœ¬
            version_config = {
                "dataset_name": f"test_dataset_{int(time.time())}",
                "data_path": "test/data/path",
                "description": "é›†æˆæµ‹è¯•æ•°æ®ç‰ˆæœ¬",
                "tags": ["test", "integration"]
            }
            
            response = requests.post(
                f"{self.base_url}/api/v1/data-versioning/versions",
                json=version_config
            )
            
            if response.status_code == 200:
                version_id = response.json()["data"]["version_id"]
                self.created_resources.append(("data_version", version_id))
                
                # æŸ¥è¯¢ç‰ˆæœ¬ä¿¡æ¯
                response = requests.get(
                    f"{self.base_url}/api/v1/data-versioning/versions/{version_id}"
                )
                
                if response.status_code == 200:
                    version_info = response.json()["data"]
                    assert version_info["dataset_name"] == version_config["dataset_name"]
                    
                    logger.info("âœ“ æ•°æ®ç‰ˆæœ¬æ§åˆ¶æµ‹è¯•é€šè¿‡")
                    return True
            
            logger.warning("æ•°æ®ç‰ˆæœ¬æ§åˆ¶æµ‹è¯•éƒ¨åˆ†é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âœ— æ•°æ®ç‰ˆæœ¬æ§åˆ¶æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_ab_testing_framework(self) -> bool:
        """æµ‹è¯•A/Bæµ‹è¯•æ¡†æ¶"""
        try:
            logger.info("æµ‹è¯•A/Bæµ‹è¯•æ¡†æ¶...")
            
            # æµ‹è¯•æµé‡åˆ†å‰²
            response = requests.get(f"{self.base_url}/api/v1/ab-testing/traffic/status")
            
            if response.status_code == 200:
                traffic_status = response.json()["data"]
                logger.info("âœ“ æµé‡åˆ†å‰²çŠ¶æ€æŸ¥è¯¢æ­£å¸¸")
            
            # æµ‹è¯•æŒ‡æ ‡æ”¶é›†
            response = requests.get(f"{self.base_url}/api/v1/ab-testing/metrics")
            
            if response.status_code == 200:
                metrics = response.json()["data"]
                logger.info("âœ“ A/Bæµ‹è¯•æŒ‡æ ‡æ”¶é›†æ­£å¸¸")
            
            logger.info("âœ“ A/Bæµ‹è¯•æ¡†æ¶æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âœ— A/Bæµ‹è¯•æ¡†æ¶æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_model_explainability(self) -> bool:
        """æµ‹è¯•æ¨¡å‹è§£é‡Šæ€§"""
        try:
            logger.info("æµ‹è¯•æ¨¡å‹è§£é‡Šæ€§...")
            
            # å¦‚æœæœ‰å·²è®­ç»ƒçš„æ¨¡å‹ï¼Œæµ‹è¯•è§£é‡Šæ€§åŠŸèƒ½
            if self.created_resources:
                for resource_type, resource_id in self.created_resources:
                    if resource_type == "model":
                        # æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡åˆ†æ
                        response = requests.get(
                            f"{self.base_url}/api/v1/explainability/technical-analysis/{resource_id}",
                            params={"stock_code": "000001.SZ"}
                        )
                        
                        if response.status_code == 200:
                            analysis = response.json()["data"]
                            logger.info("âœ“ æŠ€æœ¯æŒ‡æ ‡å½±å“åˆ†ææ­£å¸¸")
                            break
            
            logger.info("âœ“ æ¨¡å‹è§£é‡Šæ€§æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âœ— æ¨¡å‹è§£é‡Šæ€§æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_system_performance(self) -> bool:
        """æµ‹è¯•ç³»ç»Ÿæ€§èƒ½"""
        try:
            logger.info("æµ‹è¯•ç³»ç»Ÿæ€§èƒ½...")
            
            # æµ‹è¯•æ€§èƒ½ç›‘æ§
            response = requests.get(f"{self.base_url}/api/v1/system/performance/report")
            
            if response.status_code == 200:
                report = response.json()["data"]
                
                # æ£€æŸ¥ç³»ç»Ÿèµ„æº
                system_resources = report.get("system_resources", {})
                cpu_percent = system_resources.get("cpu", {}).get("percent", 0)
                memory_percent = system_resources.get("memory", {}).get("percent", 0)
                
                logger.info(f"ç³»ç»Ÿèµ„æºä½¿ç”¨ - CPU: {cpu_percent}%, å†…å­˜: {memory_percent}%")
                
                # æ€§èƒ½è­¦å‘Š
                if cpu_percent > 80:
                    logger.warning(f"CPUä½¿ç”¨ç‡è¾ƒé«˜: {cpu_percent}%")
                if memory_percent > 85:
                    logger.warning(f"å†…å­˜ä½¿ç”¨ç‡è¾ƒé«˜: {memory_percent}%")
                
                logger.info("âœ“ ç³»ç»Ÿæ€§èƒ½ç›‘æ§æ­£å¸¸")
            
            # æµ‹è¯•é”™è¯¯å¤„ç†ç»Ÿè®¡
            response = requests.get(f"{self.base_url}/api/v1/system/errors/statistics")
            
            if response.status_code == 200:
                error_stats = response.json()["data"]
                total_errors = error_stats.get("total_errors", 0)
                
                logger.info(f"ç³»ç»Ÿé”™è¯¯ç»Ÿè®¡ - æ€»é”™è¯¯æ•°: {total_errors}")
                
                if total_errors > 100:
                    logger.warning(f"ç³»ç»Ÿé”™è¯¯æ•°é‡è¾ƒå¤š: {total_errors}")
            
            logger.info("âœ“ ç³»ç»Ÿæ€§èƒ½æµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            logger.error(f"âœ— ç³»ç»Ÿæ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_api_endpoints(self) -> bool:
        """æµ‹è¯•APIç«¯ç‚¹"""
        try:
            logger.info("æµ‹è¯•APIç«¯ç‚¹...")
            
            # å…³é”®APIç«¯ç‚¹åˆ—è¡¨
            endpoints = [
                ("/api/v1/features/list", "GET"),
                ("/api/v1/models", "GET"),
                ("/api/v1/training/stats", "GET"),
                ("/api/v1/monitoring/dashboard", "GET"),
                ("/api/v1/data-versioning/versions", "GET"),
                ("/api/v1/ab-testing/metrics", "GET"),
                ("/api/v1/system/performance/report", "GET")
            ]
            
            success_count = 0
            total_count = len(endpoints)
            
            for endpoint, method in endpoints:
                try:
                    if method == "GET":
                        response = requests.get(f"{self.base_url}{endpoint}", timeout=10)
                    else:
                        continue  # è·³è¿‡éGETè¯·æ±‚
                    
                    if response.status_code in [200, 404]:  # 404ä¹Ÿç®—æ­£å¸¸ï¼Œå¯èƒ½æ˜¯ç©ºæ•°æ®
                        success_count += 1
                        logger.info(f"âœ“ {endpoint} - {response.status_code}")
                    else:
                        logger.warning(f"? {endpoint} - {response.status_code}")
                        
                except Exception as e:
                    logger.warning(f"âœ— {endpoint} - {e}")
            
            success_rate = success_count / total_count
            logger.info(f"APIç«¯ç‚¹æµ‹è¯•å®Œæˆ - æˆåŠŸç‡: {success_rate:.1%} ({success_count}/{total_count})")
            
            return success_rate >= 0.8  # 80%æˆåŠŸç‡ç®—é€šè¿‡
            
        except Exception as e:
            logger.error(f"âœ— APIç«¯ç‚¹æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def cleanup_resources(self):
        """æ¸…ç†æµ‹è¯•èµ„æº"""
        try:
            logger.info("æ¸…ç†æµ‹è¯•èµ„æº...")
            
            for resource_type, resource_id in self.created_resources:
                try:
                    if resource_type == "model":
                        response = requests.delete(f"{self.base_url}/api/v1/models/{resource_id}")
                        if response.status_code == 200:
                            logger.info(f"âœ“ æ¸…ç†æ¨¡å‹: {resource_id}")
                    
                    elif resource_type == "alert":
                        response = requests.delete(f"{self.base_url}/api/v1/monitoring/alerts/{resource_id}")
                        if response.status_code == 200:
                            logger.info(f"âœ“ æ¸…ç†å‘Šè­¦: {resource_id}")
                    
                    elif resource_type == "data_version":
                        response = requests.delete(f"{self.base_url}/api/v1/data-versioning/versions/{resource_id}")
                        if response.status_code == 200:
                            logger.info(f"âœ“ æ¸…ç†æ•°æ®ç‰ˆæœ¬: {resource_id}")
                            
                except Exception as e:
                    logger.warning(f"æ¸…ç†èµ„æºå¤±è´¥ {resource_type}:{resource_id} - {e}")
            
            logger.info("èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            logger.error(f"èµ„æºæ¸…ç†å¤±è´¥: {e}")
    
    def run_integration_tests(self) -> Dict[str, bool]:
        """è¿è¡Œå®Œæ•´çš„é›†æˆæµ‹è¯•"""
        logger.info("å¼€å§‹MLOpsç³»ç»Ÿé›†æˆæµ‹è¯•...")
        
        test_cases = [
            ("ç³»ç»Ÿå¥åº·æ£€æŸ¥", self.test_system_health),
            ("ç‰¹å¾å·¥ç¨‹ç®¡é“", self.test_feature_engineering_pipeline),
            ("æ¨¡å‹è®­ç»ƒå·¥ä½œæµ", self.test_model_training_workflow),
            ("ç›‘æ§ç³»ç»Ÿ", self.test_monitoring_system),
            ("æ•°æ®ç‰ˆæœ¬æ§åˆ¶", self.test_data_versioning),
            ("A/Bæµ‹è¯•æ¡†æ¶", self.test_ab_testing_framework),
            ("æ¨¡å‹è§£é‡Šæ€§", self.test_model_explainability),
            ("ç³»ç»Ÿæ€§èƒ½", self.test_system_performance),
            ("APIç«¯ç‚¹", self.test_api_endpoints)
        ]
        
        results = {}
        passed_count = 0
        
        for test_name, test_func in test_cases:
            try:
                logger.info(f"\n{'='*50}")
                logger.info(f"æ‰§è¡Œæµ‹è¯•: {test_name}")
                logger.info(f"{'='*50}")
                
                start_time = time.time()
                result = test_func()
                end_time = time.time()
                
                results[test_name] = result
                if result:
                    passed_count += 1
                
                logger.info(f"æµ‹è¯• '{test_name}' {'é€šè¿‡' if result else 'å¤±è´¥'} (è€—æ—¶: {end_time - start_time:.2f}s)")
                
            except Exception as e:
                logger.error(f"æµ‹è¯• '{test_name}' æ‰§è¡Œå¼‚å¸¸: {e}")
                results[test_name] = False
        
        # æ¸…ç†æµ‹è¯•èµ„æº
        self.cleanup_resources()
        
        # ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        self.generate_test_report(results, passed_count, len(test_cases))
        
        return results
    
    def generate_test_report(self, results: Dict[str, bool], passed_count: int, total_count: int):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        try:
            report = {
                "test_timestamp": datetime.now().isoformat(),
                "total_tests": total_count,
                "passed_tests": passed_count,
                "failed_tests": total_count - passed_count,
                "success_rate": passed_count / total_count,
                "test_results": results,
                "system_info": {
                    "base_url": self.base_url,
                    "test_timeout": TEST_TIMEOUT
                }
            }
            
            # ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶
            report_file = f"backend/logs/integration_test_report_{int(time.time())}.json"
            with open(report_file, 'w', encoding='utf-8') as f:
                json.dump(report, f, indent=2, ensure_ascii=False)
            
            # æ‰“å°æ‘˜è¦
            logger.info(f"\n{'='*60}")
            logger.info("MLOpsç³»ç»Ÿé›†æˆæµ‹è¯•æŠ¥å‘Š")
            logger.info(f"{'='*60}")
            logger.info(f"æµ‹è¯•æ—¶é—´: {report['test_timestamp']}")
            logger.info(f"æ€»æµ‹è¯•æ•°: {total_count}")
            logger.info(f"é€šè¿‡æµ‹è¯•: {passed_count}")
            logger.info(f"å¤±è´¥æµ‹è¯•: {total_count - passed_count}")
            logger.info(f"æˆåŠŸç‡: {report['success_rate']:.1%}")
            logger.info(f"è¯¦ç»†æŠ¥å‘Š: {report_file}")
            
            # æµ‹è¯•ç»“æœè¯¦æƒ…
            logger.info(f"\næµ‹è¯•ç»“æœè¯¦æƒ…:")
            for test_name, result in results.items():
                status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
                logger.info(f"  {test_name}: {status}")
            
            # æ€»ä½“è¯„ä¼°
            if report['success_rate'] >= 0.9:
                logger.info(f"\nğŸ‰ ç³»ç»ŸçŠ¶æ€: ä¼˜ç§€ (æˆåŠŸç‡ >= 90%)")
            elif report['success_rate'] >= 0.8:
                logger.info(f"\nâœ… ç³»ç»ŸçŠ¶æ€: è‰¯å¥½ (æˆåŠŸç‡ >= 80%)")
            elif report['success_rate'] >= 0.7:
                logger.info(f"\nâš ï¸  ç³»ç»ŸçŠ¶æ€: ä¸€èˆ¬ (æˆåŠŸç‡ >= 70%)")
            else:
                logger.info(f"\nâŒ ç³»ç»ŸçŠ¶æ€: éœ€è¦æ”¹è¿› (æˆåŠŸç‡ < 70%)")
            
            logger.info(f"{'='*60}")
            
        except Exception as e:
            logger.error(f"ç”Ÿæˆæµ‹è¯•æŠ¥å‘Šå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºæµ‹è¯•å®ä¾‹
        test_runner = MLOpsIntegrationTest()
        
        # è¿è¡Œé›†æˆæµ‹è¯•
        results = test_runner.run_integration_tests()
        
        # è¿”å›æµ‹è¯•ç»“æœ
        success_rate = sum(results.values()) / len(results)
        return success_rate >= 0.8  # 80%æˆåŠŸç‡ç®—é€šè¿‡
        
    except Exception as e:
        logger.error(f"é›†æˆæµ‹è¯•æ‰§è¡Œå¤±è´¥: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
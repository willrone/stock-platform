#!/usr/bin/env python3
"""
Optuna ä¼˜åŒ–æ•ˆç‡ POC éªŒè¯è„šæœ¬

æµ‹è¯•ä¼˜åŒ–åçš„è¶…å‚æ•°æœç´¢æ€§èƒ½ï¼š
1. SQLite æŒä¹…åŒ–å­˜å‚¨
2. HyperbandPruner æ¿€è¿›å‰ªæ
3. æ•°æ®é¢„åŠ è½½ç¼“å­˜
4. å¹¶è¡Œæ‰§è¡Œ (n_jobs)

è¿è¡Œæ–¹å¼ï¼š
    cd /Users/ronghui/Projects/willrone/backend
    source venv/bin/activate
    python scripts/test_optuna_optimization.py
"""

import asyncio
import sys
import os
import time
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from app.services.backtest.optimization.strategy_hyperparameter_optimizer import (
    StrategyHyperparameterOptimizer,
)


async def run_optimization_test(n_jobs: int = 4, n_trials: int = 20):
    """è¿è¡Œä¼˜åŒ–æµ‹è¯•"""
    
    print("=" * 60)
    print(f"Optuna ä¼˜åŒ–æ•ˆç‡ POC æµ‹è¯•")
    print(f"å¹¶è¡Œè¿›ç¨‹æ•°: {n_jobs}")
    print(f"è¯•éªŒæ¬¡æ•°: {n_trials}")
    print("=" * 60)
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = StrategyHyperparameterOptimizer(
        n_jobs=n_jobs,
        use_persistent_storage=True
    )
    
    # æµ‹è¯•é…ç½®
    strategy_name = "ma_crossover"
    stock_codes = ["000001.SZ", "000002.SZ", "600000.SH"]  # 3åªè‚¡ç¥¨
    end_date = datetime.now()
    start_date = end_date - timedelta(days=180)  # 6ä¸ªæœˆæ•°æ®
    
    # å‚æ•°ç©ºé—´
    param_space = {
        "short_window": {
            "type": "int",
            "low": 5,
            "high": 30,
            "enabled": True
        },
        "long_window": {
            "type": "int", 
            "low": 20,
            "high": 120,
            "enabled": True
        },
        "stop_loss": {
            "type": "float",
            "low": 0.02,
            "high": 0.10,
            "enabled": True
        },
        "take_profit": {
            "type": "float",
            "low": 0.05,
            "high": 0.30,
            "enabled": True
        }
    }
    
    # ç›®æ ‡é…ç½®
    objective_config = {
        "objective_metric": "sharpe",
        "direction": "maximize"
    }
    
    # å›æµ‹é…ç½®
    backtest_config = {
        "initial_cash": 100000.0,
        "commission_rate": 0.0003,
        "slippage_rate": 0.0001,
    }
    
    # è¿›åº¦å›è°ƒ
    trial_times = []
    last_report_time = time.time()
    
    def progress_callback(trial_num, total_trials, params, score, report, **kwargs):
        nonlocal last_report_time
        current_time = time.time()
        trial_times.append(current_time)
        
        completed = kwargs.get('completed_trials', trial_num)
        pruned = kwargs.get('pruned_trials', 0)
        best_score = kwargs.get('best_score', score)
        
        # æ¯5ä¸ªtrialæˆ–æ¯30ç§’æŠ¥å‘Šä¸€æ¬¡
        if trial_num % 5 == 0 or (current_time - last_report_time) > 30:
            print(f"  Trial {trial_num}/{total_trials}: score={score:.4f if score else 'N/A'}, "
                  f"best={best_score:.4f if best_score else 'N/A'}, "
                  f"completed={completed}, pruned={pruned}")
            last_report_time = current_time
    
    # è¿è¡Œä¼˜åŒ–
    print(f"\nå¼€å§‹ä¼˜åŒ– @ {datetime.now().strftime('%H:%M:%S')}")
    print("-" * 60)
    
    start_time = time.time()
    
    try:
        result = await optimizer.optimize_strategy_parameters(
            strategy_name=strategy_name,
            param_space=param_space,
            stock_codes=stock_codes,
            start_date=start_date,
            end_date=end_date,
            objective_config=objective_config,
            backtest_config=backtest_config,
            n_trials=n_trials,
            optimization_method="tpe",
            timeout=600,  # 10åˆ†é’Ÿè¶…æ—¶
            progress_callback=progress_callback,
        )
        
        end_time = time.time()
        total_duration = end_time - start_time
        
        print("-" * 60)
        print(f"ä¼˜åŒ–å®Œæˆ @ {datetime.now().strftime('%H:%M:%S')}")
        print("=" * 60)
        
        # è¾“å‡ºç»“æœ
        print(f"\nğŸ“Š æ€§èƒ½ç»Ÿè®¡:")
        print(f"  æ€»è€—æ—¶: {total_duration:.2f} ç§’")
        print(f"  å¹³å‡æ¯ trial: {total_duration / n_trials:.2f} ç§’")
        print(f"  å¹¶è¡Œæ•ˆç‡: {n_jobs}x ç†è®ºåŠ é€Ÿ")
        
        if trial_times and len(trial_times) > 1:
            # è®¡ç®—å®é™…ååé‡
            actual_throughput = len(trial_times) / total_duration
            print(f"  å®é™…ååé‡: {actual_throughput:.2f} trials/ç§’")
        
        print(f"\nğŸ† æœ€ä¼˜ç»“æœ:")
        print(f"  æœ€ä½³å¾—åˆ†: {result.get('best_score', 'N/A')}")
        print(f"  æœ€ä½³å‚æ•°: {result.get('best_params', {})}")
        
        stats = result.get('statistics', {})
        print(f"\nğŸ“ˆ è¯•éªŒç»Ÿè®¡:")
        print(f"  å®Œæˆ: {stats.get('completed_trials', 'N/A')}")
        print(f"  å‰ªæ: {stats.get('pruned_trials', 'N/A')}")
        print(f"  å¤±è´¥: {stats.get('failed_trials', 'N/A')}")
        
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†æŒä¹…åŒ–å­˜å‚¨
        storage_dir = optimizer._storage_dir
        print(f"\nğŸ’¾ å­˜å‚¨ä½ç½®: {storage_dir}")
        
        return {
            "success": True,
            "duration_seconds": total_duration,
            "avg_trial_seconds": total_duration / n_trials,
            "best_score": result.get('best_score'),
            "best_params": result.get('best_params'),
            "statistics": stats
        }
        
    except Exception as e:
        end_time = time.time()
        print(f"\nâŒ ä¼˜åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return {
            "success": False,
            "error": str(e),
            "duration_seconds": end_time - start_time
        }


async def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description="Optuna ä¼˜åŒ–æ•ˆç‡ POC æµ‹è¯•")
    parser.add_argument("--n-jobs", type=int, default=4, help="å¹¶è¡Œè¿›ç¨‹æ•°")
    parser.add_argument("--n-trials", type=int, default=20, help="è¯•éªŒæ¬¡æ•°")
    parser.add_argument("--compare", action="store_true", help="å¯¹æ¯”ä¸²è¡Œ vs å¹¶è¡Œ")
    
    args = parser.parse_args()
    
    if args.compare:
        # å¯¹æ¯”æµ‹è¯•
        print("\n" + "=" * 60)
        print("å¯¹æ¯”æµ‹è¯•: ä¸²è¡Œ vs å¹¶è¡Œ")
        print("=" * 60)
        
        # ä¸²è¡Œæµ‹è¯• (n_jobs=1)
        print("\n[1/2] ä¸²è¡Œæµ‹è¯• (n_jobs=1)...")
        result_serial = await run_optimization_test(n_jobs=1, n_trials=args.n_trials)
        
        # å¹¶è¡Œæµ‹è¯•
        print(f"\n[2/2] å¹¶è¡Œæµ‹è¯• (n_jobs={args.n_jobs})...")
        result_parallel = await run_optimization_test(n_jobs=args.n_jobs, n_trials=args.n_trials)
        
        # å¯¹æ¯”ç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ“Š å¯¹æ¯”ç»“æœ")
        print("=" * 60)
        
        if result_serial["success"] and result_parallel["success"]:
            serial_time = result_serial["duration_seconds"]
            parallel_time = result_parallel["duration_seconds"]
            speedup = serial_time / parallel_time if parallel_time > 0 else 0
            
            print(f"  ä¸²è¡Œè€—æ—¶: {serial_time:.2f} ç§’")
            print(f"  å¹¶è¡Œè€—æ—¶: {parallel_time:.2f} ç§’")
            print(f"  å®é™…åŠ é€Ÿæ¯”: {speedup:.2f}x")
            print(f"  ç†è®ºåŠ é€Ÿæ¯”: {args.n_jobs}x")
            print(f"  å¹¶è¡Œæ•ˆç‡: {(speedup / args.n_jobs) * 100:.1f}%")
    else:
        # å•æ¬¡æµ‹è¯•
        await run_optimization_test(n_jobs=args.n_jobs, n_trials=args.n_trials)


if __name__ == "__main__":
    asyncio.run(main())

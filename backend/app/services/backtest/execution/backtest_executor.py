"""
å›æµ‹æ‰§è¡Œå™¨ - å®Œæ•´çš„å›æµ‹æµç¨‹æ‰§è¡Œå’Œç»“æœåˆ†æï¼ˆé‡æ„ç‰ˆï¼‰
"""

import time
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from loguru import logger

from app.core.error_handler import ErrorSeverity, TaskError

from ..core.portfolio_manager import PortfolioManager
from ..core.portfolio_manager_array import PortfolioManagerArray
from ..models import BacktestConfig
from ..strategies.strategy_factory import AdvancedStrategyFactory, StrategyFactory
from .backtest_loop_executor import BacktestLoopExecutor

# from .backtest_progress_monitor import backtest_progress_monitor
from .data_loader import DataLoader
from .multiprocess_worker import worker_backtest
from .progress_bridge import ProgressBridge

# å¯¼å…¥æ–°æ¨¡å—
from .data_preprocessor import DataPreprocessor
from .performance_tracker import PerformanceTracker
from .report_generator import BacktestReportGenerator
from .validators import get_execution_statistics, validate_backtest_parameters


class BacktestExecutor:
    """å›æµ‹æ‰§è¡Œå™¨ï¼ˆé‡æ„ç‰ˆï¼‰- åè°ƒå„æ¨¡å—å®Œæˆå›æµ‹"""

    def __init__(
        self,
        data_dir: str = "data",
        enable_parallel: bool = True,
        max_workers: Optional[int] = None,
        enable_performance_profiling: bool = False,
        use_multiprocessing: bool = True,
        persistence=None,
    ):
        """
        åˆå§‹åŒ–å›æµ‹æ‰§è¡Œå™¨

        Args:
            data_dir: æ•°æ®ç›®å½•
            enable_parallel: æ˜¯å¦å¯ç”¨å¹¶è¡ŒåŒ–ï¼ˆé»˜è®¤Trueï¼‰
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼Œé»˜è®¤ä½¿ç”¨CPUæ ¸å¿ƒæ•°
            enable_performance_profiling: æ˜¯å¦å¯ç”¨æ€§èƒ½åˆ†æï¼ˆé»˜è®¤Falseï¼‰
            use_multiprocessing: æ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹ï¼ˆçªç ´GILé™åˆ¶ï¼Œé»˜è®¤Trueï¼‰
        """
        import os

        if max_workers is None:
            max_workers = min(os.cpu_count() or 4, 8)

        self.enable_parallel = enable_parallel
        self.max_workers = max_workers
        self.use_multiprocessing = use_multiprocessing
        self.use_array_portfolio = True

        # æŒä¹…åŒ–æœåŠ¡ï¼ˆå¯é€‰ï¼Œå‘åå…¼å®¹ï¼‰
        self._persistence = persistence

        # æ•°æ®åŠ è½½å™¨
        self.data_loader = DataLoader(
            data_dir, max_workers=max_workers if enable_parallel else None
        )

        # æ‰§è¡Œç»Ÿè®¡
        self.execution_stats = {
            "total_backtests": 0,
            "successful_backtests": 0,
            "failed_backtests": 0,
        }

        # åˆå§‹åŒ–å„æ¨¡å—
        self.data_preprocessor = DataPreprocessor(
            enable_parallel=enable_parallel,
            max_workers=max_workers,
            use_multiprocessing=use_multiprocessing,
        )
        self.loop_executor = BacktestLoopExecutor()
        self.report_generator = BacktestReportGenerator()
        self.performance_tracker = PerformanceTracker(
            enable_profiling=enable_performance_profiling
        )

        # æ˜¾å¼å¯¼å…¥è¿›åº¦ç›‘æ§å™¨ï¼ˆé¿å…æ½œåœ¨çš„å¾ªç¯å¯¼å…¥æˆ–æœªå®šä¹‰é—®é¢˜ï¼‰
        from .backtest_progress_monitor import backtest_progress_monitor

        self.progress_monitor = backtest_progress_monitor

        if enable_parallel:
            mode = "å¤šè¿›ç¨‹" if use_multiprocessing else "å¤šçº¿ç¨‹"
            logger.info(f"å›æµ‹æ‰§è¡Œå™¨å·²å¯ç”¨å¹¶è¡ŒåŒ–ï¼ˆ{mode}ï¼‰ï¼Œæœ€å¤§å·¥ä½œè¿›ç¨‹/çº¿ç¨‹æ•°: {max_workers}")

        if enable_performance_profiling:
            logger.info("å›æµ‹æ‰§è¡Œå™¨å·²å¯ç”¨æ€§èƒ½åˆ†æ")

    async def run_backtest(
        self,
        strategy_name: str,
        stock_codes: List[str],
        start_date: datetime,
        end_date: datetime,
        strategy_config: Dict[str, Any],
        backtest_config: Optional[BacktestConfig] = None,
        task_id: str = None,
        preloaded_stock_data: Optional[Dict[str, Any]] = None,
        precomputed_context: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå›æµ‹

        Args:
            strategy_name: ç­–ç•¥åç§°
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            strategy_config: ç­–ç•¥é…ç½®
            backtest_config: å›æµ‹é…ç½®
            task_id: ä»»åŠ¡ID
            preloaded_stock_data: é¢„åŠ è½½çš„è‚¡ç¥¨æ•°æ®ï¼ˆä¼˜åŒ–åœºæ™¯ä¸‹è·³è¿‡é‡å¤ç£ç›˜è¯»å–ï¼‰
            precomputed_context: é¢„è®¡ç®—çš„ä¸Šä¸‹æ–‡ï¼ˆtrading_dates ç­‰ï¼Œä¼˜åŒ–åœºæ™¯ä¸‹è·³è¿‡é‡å¤è®¡ç®—ï¼‰

        Returns:
            å›æµ‹æŠ¥å‘Šå­—å…¸
        """
        # è½»é‡åˆ†æ®µè®¡æ—¶
        perf_breakdown: Dict[str, float] = {}
        _t_total0 = time.perf_counter()

        # å¯åŠ¨æ€§èƒ½è¿½è¸ª
        self.performance_tracker.start_backtest()

        try:
            self.execution_stats["total_backtests"] += 1

            # ç”Ÿæˆå›æµ‹ID å¹¶åˆ›å»ºå ä½è¡Œ
            # ä¼˜å…ˆä½¿ç”¨ persistence æœåŠ¡ï¼Œå‘åå…¼å®¹æ—§è·¯å¾„
            if task_id and self._persistence is not None:
                backtest_id = self._persistence.create_backtest_session(
                    task_id=task_id,
                    strategy_name=strategy_name,
                    start_date=start_date,
                    end_date=end_date,
                )
            else:
                backtest_id = str(uuid.uuid4())
                if task_id:
                    self._create_placeholder_backtest_result(
                        task_id=task_id,
                        backtest_id=backtest_id,
                        strategy_name=strategy_name,
                        start_date=start_date,
                        end_date=end_date,
                    )

            # ä½¿ç”¨é»˜è®¤é…ç½®
            if backtest_config is None:
                backtest_config = BacktestConfig()

            # å¤§è§„æ¨¡å›æµ‹è‡ªåŠ¨ä¼˜åŒ–å†…å­˜ï¼šè‚¡ç¥¨æ•°Ã—å¤©æ•° > 20000 æ—¶å…³é—­æŒä»“æ˜ç»†è®°å½•
            num_days = (end_date - start_date).days
            if len(stock_codes) * num_days > 20000:
                backtest_config.record_positions_in_history = False
                backtest_config.portfolio_history_stride = max(backtest_config.portfolio_history_stride, 10)
                logger.info(
                    f"å¤§è§„æ¨¡å›æµ‹å†…å­˜ä¼˜åŒ–: {len(stock_codes)}è‚¡Ã—{num_days}å¤©, "
                    f"å…³é—­æŒä»“æ˜ç»†, stride={backtest_config.portfolio_history_stride}"
                )

            # ML ç­–ç•¥è‡ªåŠ¨å¯ç”¨ topk_buffer äº¤æ˜“æ¨¡å¼ï¼ˆæˆªé¢æ’åé€‰è‚¡ï¼‰
            if strategy_name == "ml_ensemble_lgb_xgb_riskctl" and strategy_config:
                if "trade_mode" not in strategy_config:
                    _top_n = strategy_config.get("top_n", 10)
                    strategy_config.setdefault("trade_mode", "topk_buffer")
                    strategy_config.setdefault("topk", _top_n)
                    strategy_config.setdefault("buffer", _top_n * 2)
                    strategy_config.setdefault("max_changes_per_day", 3)
                    strategy_config.setdefault("min_buy_score", 0.0)
                    logger.info(
                        f"MLç­–ç•¥è‡ªåŠ¨å¯ç”¨ topk_buffer æ¨¡å¼: topk={_top_n}, "
                        f"buffer={strategy_config['buffer']}, max_changes={strategy_config['max_changes_per_day']}"
                    )

            # å¼€å§‹è¿›åº¦ç›‘æ§
            if task_id:
                await self.progress_monitor.start_backtest_monitoring(
                    task_id=task_id, backtest_id=backtest_id
                )
                await self.progress_monitor.update_stage(
                    task_id, "initialization", progress=100, status="completed"
                )

            # ========== é˜¶æ®µ 1: åˆ›å»ºç­–ç•¥ ==========
            _t0 = time.perf_counter()
            self.performance_tracker.start_stage(
                "strategy_setup",
                {"strategy_name": strategy_name, "stock_count": len(stock_codes)},
            )

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "strategy_setup", status="running"
                )

            # ä¼˜å…ˆä½¿ç”¨é«˜çº§ç­–ç•¥å·¥å‚
            try:
                strategy = AdvancedStrategyFactory.create_strategy(
                    strategy_name, strategy_config
                )
            except Exception:
                strategy = StrategyFactory.create_strategy(
                    strategy_name, strategy_config
                )

            self.performance_tracker.end_stage("strategy_setup")
            perf_breakdown["strategy_setup_s"] = time.perf_counter() - _t0

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "strategy_setup", progress=100, status="completed"
                )

            # ========== é˜¶æ®µ 2: åŠ è½½æ•°æ® ==========
            _t0 = time.perf_counter()
            self.performance_tracker.start_stage(
                "data_loading",
                {
                    "stock_codes": stock_codes,
                    "start_date": start_date.isoformat(),
                    "end_date": end_date.isoformat(),
                },
            )

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "data_loading", status="running"
                )

            logger.info(
                f"å¼€å§‹å›æµ‹: {strategy_name}, è‚¡ç¥¨: {stock_codes}, æœŸé—´: {start_date} - {end_date}"
            )

            # perf: ä¼˜åŒ–åœºæ™¯ä¸‹ä½¿ç”¨é¢„åŠ è½½æ•°æ®ï¼Œè·³è¿‡é‡å¤ç£ç›˜ I/O
            if preloaded_stock_data is not None:
                stock_data = preloaded_stock_data
                logger.info(f"ä½¿ç”¨é¢„åŠ è½½æ•°æ®: {len(stock_data)} åªè‚¡ç¥¨ï¼ˆè·³è¿‡ç£ç›˜è¯»å–ï¼‰")
            else:
                stock_data = self.data_loader.load_multiple_stocks(
                    stock_codes, start_date, end_date
                )

            self.performance_tracker.end_stage(
                "data_loading",
                {
                    "loaded_stocks": len(stock_data),
                    "total_records": sum(len(df) for df in stock_data.values()),
                },
            )
            self.performance_tracker.take_memory_snapshot("after_data_loading")
            perf_breakdown["data_loading_s"] = time.perf_counter() - _t0

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "data_loading", progress=100, status="completed"
                )

            # ========== é˜¶æ®µ 3: åˆ›å»ºç»„åˆç®¡ç†å™¨ ==========
            actual_stock_codes = list(stock_data.keys())
            if self.use_array_portfolio:
                portfolio_manager = PortfolioManagerArray(
                    backtest_config, actual_stock_codes
                )
                logger.info(f"âœ… ä½¿ç”¨æ•°ç»„åŒ–æŒä»“ç®¡ç†å™¨ (stocks={len(actual_stock_codes)})")
            else:
                portfolio_manager = PortfolioManager(backtest_config)
                logger.info(f"ä½¿ç”¨ä¼ ç»ŸæŒä»“ç®¡ç†å™¨ (stocks={len(actual_stock_codes)})")

            # ========== é˜¶æ®µ 4: æ•°æ®é¢„å¤„ç† ==========
            _t0 = time.perf_counter()

            # perf: P0-2 ä¼˜åŒ–åœºæ™¯ä¸‹å¤ç”¨é¢„è®¡ç®—çš„ trading_datesï¼Œé¿å…æ¯ä¸ª trial ï¿½ï¿½å¤è®¡ç®—
            if precomputed_context and "trading_dates" in precomputed_context:
                trading_dates = precomputed_context["trading_dates"]
                logger.debug(f"ä½¿ç”¨é¢„è®¡ç®—çš„ trading_dates: {len(trading_dates)} å¤©")
            else:
                # è·å–äº¤æ˜“æ—¥å†
                trading_dates = self.data_preprocessor.get_trading_calendar(
                    stock_data, start_date, end_date
                )

            # æ„å»ºæ—¥æœŸç´¢å¼•
            self.data_preprocessor.build_date_index(stock_data)

            # é¢„è®¡ç®—ä¿¡å·
            self.data_preprocessor.precompute_strategy_signals(strategy, stock_data)

            # æå–é¢„è®¡ç®—ä¿¡å·
            precomputed_signals = (
                self.data_preprocessor.extract_precomputed_signals_to_dict(
                    strategy, stock_data
                )
            )

            logger.info(f"ğŸ” é¢„è®¡ç®—ä¿¡å·å­—å…¸å¤§å°: {len(precomputed_signals)}")

            perf_breakdown["precompute_signals_s"] = time.perf_counter() - _t0

            # éªŒè¯äº¤æ˜“æ—¥ï¿½ï¿½ï¿½é‡
            if len(trading_dates) < 20:
                error_msg = f"äº¤æ˜“æ—¥æ•°é‡ä¸è¶³: {len(trading_dates)}ï¼Œè‡³å°‘éœ€è¦20ä¸ªäº¤æ˜“æ—¥"
                if task_id:
                    await self.progress_monitor.set_error(task_id, error_msg)
                raise TaskError(message=error_msg, severity=ErrorSeverity.MEDIUM)

            # æ›´æ–°æ€»äº¤æ˜“æ—¥æ•°
            if task_id:
                progress_data = self.progress_monitor.get_progress_data(task_id)
                if progress_data:
                    progress_data.total_trading_days = len(trading_dates)

                # å†™å…¥æ•°æ®åº“
                try:
                    from app.core.database import SessionLocal
                    from app.models.task_models import TaskStatus
                    from app.repositories.task_repository import TaskRepository

                    session = SessionLocal()
                    try:
                        task_repo = TaskRepository(session)
                        existing_task = task_repo.get_task_by_id(task_id)
                        if existing_task:
                            result_data = existing_task.result or {}
                            progress_data_db = result_data.get("progress_data", {})
                            progress_data_db["total_days"] = len(trading_dates)
                            result_data["progress_data"] = progress_data_db

                            task_repo.update_task_status(
                                task_id=task_id,
                                status=TaskStatus.RUNNING,
                                result=result_data,
                            )
                    finally:
                        session.close()
                except Exception as e:
                    logger.warning(f"æ›´æ–°æ€»äº¤æ˜“æ—¥æ•°å¤±è´¥: {e}")

            # ========== é˜¶æ®µ 5: æ„å»ºå¯¹é½æ•°ç»„ ==========
            _t1 = time.perf_counter()
            aligned_arrays = self.data_preprocessor.build_aligned_arrays(
                strategy, stock_data, trading_dates
            )
            perf_breakdown["align_arrays_s"] = time.perf_counter() - _t1

            # ========== å†…å­˜ä¼˜åŒ–ï¼šé‡Šæ”¾ attrs ä¸­çš„ _precomputed_signals ==========
            # aligned_arrays å·²åŒ…å«ä¿¡å·æ•°æ®ï¼Œattrs ç¼“å­˜å¯ä»¥é‡Šæ”¾
            # ä½†ä¿ç•™ precomputed_signals å­—å…¸ä½œä¸º fallbackï¼ˆloop executor å¯èƒ½éœ€è¦ï¼‰
            import gc
            for _df in stock_data.values():
                try:
                    if hasattr(_df, 'attrs') and '_precomputed_signals' in _df.attrs:
                        del _df.attrs['_precomputed_signals']
                except Exception:
                    pass
            gc.collect()
            logger.info("âœ… å†…å­˜ä¼˜åŒ–ï¼šå·²é‡Šæ”¾ attrs é¢„è®¡ç®—ä¿¡å·ç¼“å­˜ï¼ˆä¿ç•™ precomputed_signals å­—å…¸ï¼‰")

            # ========== é˜¶æ®µ 6: æ‰§è¡Œå›æµ‹å¾ªç¯ ==========
            self.performance_tracker.start_stage(
                "backtest_execution",
                {
                    "total_trading_days": len(trading_dates),
                    "stock_count": len(stock_data),
                },
            )

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "backtest_execution", status="running"
                )

            # åˆ›å»ºä¿¡å·å†™å…¥å™¨ï¼ˆä¼˜å…ˆä½¿ç”¨ persistence æœåŠ¡ï¼‰
            _signal_writer = None
            if task_id and self._persistence is not None:
                _signal_writer = self._persistence.create_signal_writer(backtest_id)

            _t0 = time.perf_counter()
            backtest_results = await self.loop_executor.execute_backtest_loop(
                strategy=strategy,
                portfolio_manager=portfolio_manager,
                stock_data=stock_data,
                trading_dates=trading_dates,
                strategy_config=strategy_config,
                task_id=task_id,
                backtest_id=backtest_id,
                precomputed_signals=precomputed_signals,
                aligned_arrays=aligned_arrays,
                signal_writer=_signal_writer,
            )
            perf_breakdown["main_loop_s"] = time.perf_counter() - _t0

            # ========== å†…å­˜ä¼˜åŒ–ï¼šå›æµ‹å¾ªç¯ç»“æŸåé‡Šæ”¾å¤§å¯¹è±¡ ==========
            del aligned_arrays
            precomputed_signals.clear()
            # ä»…æ¸…ç©ºå†…éƒ¨åŠ è½½çš„æ•°æ®ï¼Œä¸ç ´åå¤–éƒ¨ä¼ å…¥çš„ preloaded_stock_data
            if preloaded_stock_data is None:
                stock_data.clear()
            gc.collect()

            self.performance_tracker.end_stage(
                "backtest_execution",
                {
                    "total_signals": backtest_results.get("total_signals", 0),
                    "executed_trades": backtest_results.get("executed_trades", 0),
                    "trading_days": backtest_results.get("trading_days", 0),
                },
            )
            self.performance_tracker.take_memory_snapshot("after_backtest_execution")

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "backtest_execution", progress=100, status="completed"
                )

            # ========== é˜¶æ®µ 7: è®¡ç®—ç»©æ•ˆæŒ‡æ ‡ ==========
            self.performance_tracker.start_stage("metrics_calculation")

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "metrics_calculation", status="running"
                )

            _t0 = time.perf_counter()
            performance_metrics = portfolio_manager.get_performance_metrics()
            perf_breakdown["metrics_s"] = time.perf_counter() - _t0

            self.performance_tracker.end_stage("metrics_calculation")

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "metrics_calculation", progress=100, status="completed"
                )

            # ========== é˜¶æ®µ 8: ç”Ÿæˆå›æµ‹æŠ¥å‘Š ==========
            self.performance_tracker.start_stage("report_generation")

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "report_generation", status="running"
                )

            if (
                strategy_config
                and isinstance(strategy_config, dict)
                and len(strategy_config) > 0
            ):
                logger.info(f"ç”Ÿæˆå›æµ‹æŠ¥å‘Šï¼Œç­–ç•¥é…ç½®: {strategy_config}")
            else:
                logger.warning(f"ç­–ç•¥é…ç½®ä¸ºç©ºæˆ–æ— æ•ˆ: {strategy_config}")

            _t0 = time.perf_counter()
            backtest_report = self.report_generator.generate_backtest_report(
                strategy_name=strategy_name,
                stock_codes=stock_codes,
                start_date=start_date,
                end_date=end_date,
                config=backtest_config,
                portfolio_manager=portfolio_manager,
                performance_metrics=performance_metrics,
                strategy_config=strategy_config,
            )
            # å°† backtest_id å†™å…¥æŠ¥å‘Šï¼Œä¾›ä¸‹æ¸¸ï¼ˆdependencies.pyï¼‰å¤ç”¨ï¼Œ
            # ç¡®ä¿ä¿¡å·è®°å½•ä¸äº¤æ˜“è®°å½•ç­‰ä½¿ç”¨åŒä¸€ä¸ª backtest_id
            backtest_report["backtest_id"] = backtest_id
            perf_breakdown["report_generation_s"] = time.perf_counter() - _t0

            # æ·»åŠ  backtest_id åˆ°æŠ¥å‘Šï¼ˆä¾› trade_records å†™å…¥æ—¶ä½¿ç”¨ï¼Œä¿æŒä¸ signal_records ä¸€è‡´ï¼‰
            backtest_report["backtest_id"] = backtest_id

            # æ·»åŠ å›æµ‹å¾ªç¯ç»Ÿè®¡
            backtest_report["total_signals"] = backtest_results.get("total_signals", 0)
            backtest_report["trading_days"] = backtest_results.get("trading_days", 0)

            # P0: æ·»åŠ åŠ¨æ€æŒä»“ä¿¡æ¯åˆ°æŠ¥å‘Š
            backtest_report["auto_position_sizing"] = getattr(backtest_config, 'auto_position_sizing', None)
            backtest_report["unlimited_buying"] = getattr(backtest_config, 'unlimited_buying', None)
            backtest_report["effective_max_position_size"] = getattr(portfolio_manager, 'effective_max_position_size', None)
            backtest_report["configured_max_position_size"] = backtest_config.max_position_size
            backtest_report["n_stocks"] = len(actual_stock_codes)

            # P0: æ·»åŠ ç†”æ–­ç»Ÿè®¡åˆ°æŠ¥å‘Š
            cb_summary = backtest_results.get("circuit_breaker_summary")
            if cb_summary:
                backtest_report["circuit_breaker"] = cb_summary

            self.performance_tracker.end_stage(
                "report_generation", {"report_size": len(str(backtest_report))}
            )

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "report_generation", progress=100, status="completed"
                )
                await self.progress_monitor.update_stage(
                    task_id, "data_storage", progress=100, status="completed"
                )

            self.execution_stats["successful_backtests"] += 1
            logger.info(
                f"å›æµ‹å®Œæˆ: {strategy_name}, æ€»æ”¶ç›Š: {performance_metrics.get('total_return', 0):.2%}"
            )

            # å®Œæˆç›‘æ§
            if task_id:
                await self.progress_monitor.complete_backtest(
                    task_id,
                    {"total_return": performance_metrics.get("total_return", 0)},
                )

            # ========== é˜¶æ®µ 9: ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š ==========
            self.performance_tracker.end_backtest()
            self.performance_tracker.take_memory_snapshot("backtest_end")

            # å°†æ€§èƒ½æŠ¥å‘Šæ·»åŠ åˆ°å›æµ‹æŠ¥å‘Šä¸­
            performance_report = self.performance_tracker.generate_report()
            if performance_report:
                backtest_report["performance_analysis"] = performance_report
                self.performance_tracker.print_summary()

                # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
                if task_id:
                    try:
                        performance_dir = Path("backend/data/performance_reports")
                        performance_dir.mkdir(parents=True, exist_ok=True)
                        performance_file = (
                            performance_dir / f"backtest_{task_id}_performance.json"
                        )
                        self.performance_tracker.save_report(str(performance_file))
                        logger.info(f"æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ°: {performance_file}")
                    except Exception as e:
                        logger.warning(f"ä¿å­˜æ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")

            # æ·»åŠ åˆ†æ®µè®¡æ—¶ç»“æœ
            perf_breakdown["total_wall_s"] = time.perf_counter() - _t_total0
            backtest_report["perf_breakdown"] = perf_breakdown

            return backtest_report

        except Exception as e:
            self.execution_stats["failed_backtests"] += 1
            error_msg = f"å›æµ‹æ‰§è¡Œå¤±è´¥: {str(e)}"

            # ç»“æŸæ€§èƒ½åˆ†æ
            try:
                self.performance_tracker.end_backtest()
                logger.warning("å›æµ‹å¤±è´¥ï¼Œä½†æ€§èƒ½åˆ†æå·²å®Œæˆ")
            except Exception as perf_error:
                logger.warning(f"ç»“æŸæ€§èƒ½åˆ†ææ—¶å‡ºé”™: {perf_error}")

            if task_id:
                await self.progress_monitor.set_error(task_id, error_msg)

            raise TaskError(
                message=error_msg, severity=ErrorSeverity.HIGH, original_exception=e
            )

    def validate_backtest_parameters(
        self,
        strategy_name: str,
        stock_codes: List[str],
        start_date: datetime,
        end_date: datetime,
        strategy_config: Dict[str, Any],
    ) -> Dict[str, Any]:
        """éªŒè¯å›æµ‹å‚æ•°"""
        return validate_backtest_parameters(
            strategy_name, stock_codes, start_date, end_date, strategy_config
        )

    def get_execution_statistics(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        return get_execution_statistics(self.execution_stats)

    @staticmethod
    def _create_placeholder_backtest_result(
        task_id: str,
        backtest_id: str,
        strategy_name: str,
        start_date: datetime,
        end_date: datetime,
    ) -> None:
        """åœ¨å›æµ‹å¾ªç¯å¼€å§‹å‰ï¼Œé€šè¿‡ psycopg2 æ’å…¥ä¸€æ¡å ä½ backtest_results è¡Œã€‚

        è¿™æ ·å›æµ‹å¾ªç¯ä¸­ _flush_signals_to_db å†™å…¥ signal_records æ—¶ï¼Œ
        å¤–é”®çº¦æŸ (signal_records.backtest_id â†’ backtest_results.backtest_id) ä¸ä¼šå¤±è´¥ã€‚
        å›æµ‹ç»“æŸå dependencies.py ä¼š UPDATE è¿™è¡Œå¡«å…¥å®Œæ•´æ•°æ®ã€‚
        """
        import psycopg2

        from app.core.config import settings

        sql = """
            INSERT INTO backtest_results
                (task_id, backtest_id, strategy_name, start_date, end_date,
                 initial_cash, final_value, total_return, annualized_return,
                 volatility, sharpe_ratio, max_drawdown, win_rate,
                 profit_factor, total_trades)
            VALUES (%s, %s, %s, %s, %s,
                    %s, %s, %s, %s,
                    %s, %s, %s, %s,
                    %s, %s)
            ON CONFLICT (backtest_id) DO NOTHING
        """
        try:
            conn = psycopg2.connect(settings.database_url_sync)
            try:
                cur = conn.cursor()
                cur.execute(sql, (
                    task_id, backtest_id, strategy_name,
                    start_date.isoformat(), end_date.isoformat(),
                    0, 0, 0, 0,   # initial_cash, final_value, total_return, annualized_return
                    0, 0, 0, 0,   # volatility, sharpe_ratio, max_drawdown, win_rate
                    0, 0,         # profit_factor, total_trades
                ))
                conn.commit()
                cur.close()
                logger.info(f"å ä½ backtest_results è¡Œå·²åˆ›å»º: backtest_id={backtest_id}")
            finally:
                conn.close()
        except Exception as e:
            logger.warning(f"åˆ›å»ºå ä½ backtest_results è¡Œå¤±è´¥ï¼ˆä¿¡å·å†™å…¥å¯èƒ½å—å½±å“ï¼‰: {e}")
    def run_backtest_sync(
        self,
        strategy_name: str,
        stock_codes: List[str],
        start_date: datetime,
        end_date: datetime,
        strategy_config: Dict[str, Any],
        backtest_config: Optional[BacktestConfig] = None,
        task_id: str = None,
        preloaded_stock_data: Optional[Dict[str, Any]] = None,
        precomputed_context: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        åŒæ­¥ç‰ˆæœ¬çš„å›æµ‹æ‰§è¡Œï¼ˆP0 CPU ä¼˜åŒ–ï¼‰

        åœ¨ ProcessPoolExecutor å­è¿›ç¨‹ä¸­ç›´æ¥è°ƒç”¨ï¼Œç»•è¿‡ asyncio äº‹ä»¶å¾ªç¯ï¼Œ
        æ¶ˆé™¤ nest_asyncio + new_event_loop å¸¦æ¥çš„ ~80x æ€§èƒ½å¼€é”€ã€‚

        ä¸ run_backtest() é€»è¾‘å®Œå…¨ä¸€è‡´ï¼ŒåŒºåˆ«ä»…åœ¨äºï¼š
        - è¿›åº¦ç›‘æ§ä½¿ç”¨åŒæ­¥ _update_progress_sync() æ›¿ä»£ await
        - æ•°æ®åŠ è½½ä½¿ç”¨ load_multiple_stocks_sync()ï¼ˆThreadPool å¹¶è¡Œï¼‰
        - å›æµ‹å¾ªç¯ç›´æ¥åŒæ­¥è°ƒç”¨ï¼ˆloop_executor å†…éƒ¨æ— çœŸæ­£ awaitï¼‰
        """
        import asyncio
        import gc

        perf_breakdown: Dict[str, float] = {}
        _t_total0 = time.perf_counter()

        self.performance_tracker.start_backtest()

        try:
            self.execution_stats["total_backtests"] += 1

            # ç”Ÿæˆå›æµ‹ID
            if task_id and self._persistence is not None:
                backtest_id = self._persistence.create_backtest_session(
                    task_id=task_id,
                    strategy_name=strategy_name,
                    start_date=start_date,
                    end_date=end_date,
                )
            else:
                backtest_id = str(uuid.uuid4())
                if task_id:
                    self._create_placeholder_backtest_result(
                        task_id=task_id,
                        backtest_id=backtest_id,
                        strategy_name=strategy_name,
                        start_date=start_date,
                        end_date=end_date,
                    )

            if backtest_config is None:
                backtest_config = BacktestConfig()

            # å¤§è§„æ¨¡å›æµ‹è‡ªåŠ¨ä¼˜åŒ–å†…å­˜
            num_days = (end_date - start_date).days
            if len(stock_codes) * num_days > 20000:
                backtest_config.record_positions_in_history = False
                backtest_config.portfolio_history_stride = max(
                    backtest_config.portfolio_history_stride, 10
                )
                logger.info(
                    f"å¤§è§„æ¨¡å›æµ‹å†…å­˜ä¼˜åŒ–: {len(stock_codes)}è‚¡x{num_days}å¤©, "
                    f"å…³é—­æŒä»“æ˜ç»†, stride={backtest_config.portfolio_history_stride}"
                )

            # ML ç­–ç•¥è‡ªåŠ¨å¯ç”¨ topk_buffer
            if strategy_name == "ml_ensemble_lgb_xgb_riskctl" and strategy_config:
                if "trade_mode" not in strategy_config:
                    _top_n = strategy_config.get("top_n", 10)
                    strategy_config.setdefault("trade_mode", "topk_buffer")
                    strategy_config.setdefault("topk", _top_n)
                    strategy_config.setdefault("buffer", _top_n * 2)
                    strategy_config.setdefault("max_changes_per_day", 3)
                    strategy_config.setdefault("min_buy_score", 0.0)

            # â”€â”€ P2: å¤šè¿›ç¨‹å¹¶è¡Œå›æµ‹ï¼ˆè‚¡ç¥¨æ•° > 50 æ—¶è‡ªåŠ¨å¯ç”¨ï¼‰ â”€â”€
            MULTIPROCESS_THRESHOLD = 50
            if len(stock_codes) > MULTIPROCESS_THRESHOLD:
                logger.info(
                    f"ğŸš€ P2 å¤šè¿›ç¨‹å›æµ‹: {len(stock_codes)} åªè‚¡ç¥¨ "
                    f"(é˜ˆå€¼ {MULTIPROCESS_THRESHOLD}), è‡ªåŠ¨å¯ç”¨å¤šè¿›ç¨‹å¹¶è¡Œ"
                )
                try:
                    return self._run_multiprocess_backtest_sync(
                        strategy_name=strategy_name,
                        stock_codes=stock_codes,
                        start_date=start_date,
                        end_date=end_date,
                        strategy_config=strategy_config,
                        backtest_config=backtest_config,
                        task_id=task_id,
                        backtest_id=backtest_id,
                    )
                except Exception as mp_err:
                    logger.error(
                        f"å¤šè¿›ç¨‹å›æµ‹å¤±è´¥ï¼Œå›é€€åˆ°å•è¿›ç¨‹: {mp_err}",
                        exc_info=True,
                    )
                    # å›é€€åˆ°ä¸‹é¢çš„å•è¿›ç¨‹è·¯å¾„

            # è¿›åº¦ç›‘æ§ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼šç›´æ¥æ“ä½œå†…å­˜æ•°æ®ç»“æ„ï¼‰
            if task_id:
                self._start_progress_sync(task_id, backtest_id)

            # ========== é˜¶æ®µ 1: åˆ›å»ºç­–ç•¥ ==========
            _t0 = time.perf_counter()
            self.performance_tracker.start_stage(
                "strategy_setup",
                {"strategy_name": strategy_name, "stock_count": len(stock_codes)},
            )

            try:
                strategy = AdvancedStrategyFactory.create_strategy(
                    strategy_name, strategy_config
                )
            except Exception:
                strategy = StrategyFactory.create_strategy(
                    strategy_name, strategy_config
                )

            self.performance_tracker.end_stage("strategy_setup")
            perf_breakdown["strategy_setup_s"] = time.perf_counter() - _t0

            # ========== é˜¶æ®µ 2: åŠ è½½æ•°æ®ï¼ˆP0+P1 æ ¸å¿ƒä¼˜åŒ–ç‚¹ï¼‰ ==========
            _t0 = time.perf_counter()
            self.performance_tracker.start_stage(
                "data_loading",
                {
                    "stock_codes": stock_codes,
                    "start_date": start_date.isoformat(),
                    "end_date": end_date.isoformat(),
                },
            )

            logger.info(
                f"å¼€å§‹å›æµ‹: {strategy_name}, è‚¡ç¥¨æ•°: {len(stock_codes)}, "
                f"æœŸé—´: {start_date} - {end_date}"
            )

            if preloaded_stock_data is not None:
                stock_data = preloaded_stock_data
                logger.info(f"ä½¿ç”¨é¢„åŠ è½½æ•°æ®: {len(stock_data)} åªè‚¡ç¥¨")
            else:
                # P0+P1: ä½¿ç”¨åŒæ­¥å¹¶è¡Œç‰ˆæœ¬ï¼Œç»•è¿‡ asyncio
                stock_data = self.data_loader.load_multiple_stocks_sync(
                    stock_codes, start_date, end_date
                )

            self.performance_tracker.end_stage(
                "data_loading",
                {
                    "loaded_stocks": len(stock_data),
                    "total_records": sum(len(df) for df in stock_data.values()),
                },
            )
            self.performance_tracker.take_memory_snapshot("after_data_loading")
            perf_breakdown["data_loading_s"] = time.perf_counter() - _t0

            # ========== é˜¶æ®µ 3: åˆ›å»ºç»„åˆç®¡ç†å™¨ ==========
            actual_stock_codes = list(stock_data.keys())
            if self.use_array_portfolio:
                portfolio_manager = PortfolioManagerArray(
                    backtest_config, actual_stock_codes
                )
                logger.info(
                    f"ä½¿ç”¨æ•°ç»„åŒ–æŒä»“ç®¡ç†å™¨ (stocks={len(actual_stock_codes)})"
                )
            else:
                portfolio_manager = PortfolioManager(backtest_config)

            # ========== é˜¶æ®µ 4: æ•°æ®é¢„å¤„ç† ==========
            _t0 = time.perf_counter()

            if precomputed_context and "trading_dates" in precomputed_context:
                trading_dates = precomputed_context["trading_dates"]
            else:
                trading_dates = self.data_preprocessor.get_trading_calendar(
                    stock_data, start_date, end_date
                )

            self.data_preprocessor.build_date_index(stock_data)
            self.data_preprocessor.precompute_strategy_signals(strategy, stock_data)
            precomputed_signals = (
                self.data_preprocessor.extract_precomputed_signals_to_dict(
                    strategy, stock_data
                )
            )
            perf_breakdown["precompute_signals_s"] = time.perf_counter() - _t0

            if len(trading_dates) < 20:
                error_msg = (
                    f"äº¤æ˜“æ—¥æ•°é‡ä¸è¶³: {len(trading_dates)}ï¼Œè‡³å°‘éœ€è¦20ä¸ªäº¤æ˜“æ—¥"
                )
                raise TaskError(
                    message=error_msg, severity=ErrorSeverity.MEDIUM
                )

            # æ›´æ–°æ€»äº¤æ˜“æ—¥æ•°åˆ°æ•°æ®åº“
            if task_id:
                self._update_total_days_sync(task_id, len(trading_dates))

            # ========== é˜¶æ®µ 5: æ„å»ºå¯¹é½æ•°ç»„ ==========
            _t1 = time.perf_counter()
            aligned_arrays = self.data_preprocessor.build_aligned_arrays(
                strategy, stock_data, trading_dates
            )
            perf_breakdown["align_arrays_s"] = time.perf_counter() - _t1

            # å†…å­˜ä¼˜åŒ–ï¼šé‡Šæ”¾ attrs ä¸­çš„ _precomputed_signals
            for _df in stock_data.values():
                try:
                    if hasattr(_df, "attrs") and "_precomputed_signals" in _df.attrs:
                        del _df.attrs["_precomputed_signals"]
                except Exception:
                    pass
            gc.collect()

            # ========== é˜¶æ®µ 6: æ‰§è¡Œå›æµ‹å¾ªç¯ ==========
            self.performance_tracker.start_stage(
                "backtest_execution",
                {
                    "total_trading_days": len(trading_dates),
                    "stock_count": len(stock_data),
                },
            )

            _signal_writer = None
            if task_id and self._persistence is not None:
                _signal_writer = self._persistence.create_signal_writer(backtest_id)

            _t0 = time.perf_counter()
            # execute_backtest_loop æ˜¯ async def ä½†å†…éƒ¨æ— çœŸæ­£ awaitï¼Œ
            # ç”¨ asyncio.run() æœ€å°åŒ–äº‹ä»¶å¾ªç¯å¼€é”€
            loop = asyncio.new_event_loop()
            try:
                backtest_results = loop.run_until_complete(
                    self.loop_executor.execute_backtest_loop(
                        strategy=strategy,
                        portfolio_manager=portfolio_manager,
                        stock_data=stock_data,
                        trading_dates=trading_dates,
                        strategy_config=strategy_config,
                        task_id=task_id,
                        backtest_id=backtest_id,
                        precomputed_signals=precomputed_signals,
                        aligned_arrays=aligned_arrays,
                        signal_writer=_signal_writer,
                    )
                )
            finally:
                loop.close()
            perf_breakdown["main_loop_s"] = time.perf_counter() - _t0

            # å†…å­˜ä¼˜åŒ–
            del aligned_arrays
            precomputed_signals.clear()
            if preloaded_stock_data is None:
                stock_data.clear()
            gc.collect()

            self.performance_tracker.end_stage(
                "backtest_execution",
                {
                    "total_signals": backtest_results.get("total_signals", 0),
                    "executed_trades": backtest_results.get("executed_trades", 0),
                    "trading_days": backtest_results.get("trading_days", 0),
                },
            )
            self.performance_tracker.take_memory_snapshot("after_backtest_execution")

            # ========== é˜¶æ®µ 7: è®¡ç®—ç»©æ•ˆæŒ‡æ ‡ ==========
            self.performance_tracker.start_stage("metrics_calculation")
            _t0 = time.perf_counter()
            performance_metrics = portfolio_manager.get_performance_metrics()
            perf_breakdown["metrics_s"] = time.perf_counter() - _t0
            self.performance_tracker.end_stage("metrics_calculation")

            # ========== é˜¶æ®µ 8: ç”Ÿæˆå›æµ‹æŠ¥å‘Š ==========
            self.performance_tracker.start_stage("report_generation")

            _t0 = time.perf_counter()
            backtest_report = self.report_generator.generate_backtest_report(
                strategy_name=strategy_name,
                stock_codes=stock_codes,
                start_date=start_date,
                end_date=end_date,
                config=backtest_config,
                portfolio_manager=portfolio_manager,
                performance_metrics=performance_metrics,
                strategy_config=strategy_config,
            )
            backtest_report["backtest_id"] = backtest_id
            perf_breakdown["report_generation_s"] = time.perf_counter() - _t0

            backtest_report["total_signals"] = backtest_results.get(
                "total_signals", 0
            )
            backtest_report["trading_days"] = backtest_results.get(
                "trading_days", 0
            )
            backtest_report["auto_position_sizing"] = getattr(
                backtest_config, "auto_position_sizing", None
            )
            backtest_report["unlimited_buying"] = getattr(
                backtest_config, "unlimited_buying", None
            )
            backtest_report["effective_max_position_size"] = getattr(
                portfolio_manager, "effective_max_position_size", None
            )
            backtest_report["configured_max_position_size"] = (
                backtest_config.max_position_size
            )
            backtest_report["n_stocks"] = len(actual_stock_codes)

            cb_summary = backtest_results.get("circuit_breaker_summary")
            if cb_summary:
                backtest_report["circuit_breaker"] = cb_summary

            self.performance_tracker.end_stage(
                "report_generation", {"report_size": len(str(backtest_report))}
            )

            self.execution_stats["successful_backtests"] += 1
            logger.info(
                f"å›æµ‹å®Œæˆ: {strategy_name}, "
                f"æ€»æ”¶ç›Š: {performance_metrics.get('total_return', 0):.2%}"
            )

            # ========== é˜¶æ®µ 9: æ€§èƒ½æŠ¥å‘Š ==========
            self.performance_tracker.end_backtest()
            self.performance_tracker.take_memory_snapshot("backtest_end")

            performance_report = self.performance_tracker.generate_report()
            if performance_report:
                backtest_report["performance_analysis"] = performance_report
                self.performance_tracker.print_summary()

                if task_id:
                    try:
                        performance_dir = Path("backend/data/performance_reports")
                        performance_dir.mkdir(parents=True, exist_ok=True)
                        perf_file = (
                            performance_dir
                            / f"backtest_{task_id}_performance.json"
                        )
                        self.performance_tracker.save_report(str(perf_file))
                    except Exception as e:
                        logger.warning(f"ä¿å­˜æ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")

            perf_breakdown["total_wall_s"] = time.perf_counter() - _t_total0
            backtest_report["perf_breakdown"] = perf_breakdown

            return backtest_report

        except Exception as e:
            self.execution_stats["failed_backtests"] += 1
            error_msg = f"å›æµ‹æ‰§è¡Œå¤±è´¥: {str(e)}"

            try:
                self.performance_tracker.end_backtest()
            except Exception:
                pass

            raise TaskError(
                message=error_msg,
                severity=ErrorSeverity.HIGH,
                original_exception=e,
            )

    # â”€â”€ P2: å¤šè¿›ç¨‹å¹¶è¡Œå›æµ‹ â”€â”€

    def _run_multiprocess_backtest_sync(
        self,
        strategy_name: str,
        stock_codes: list,
        start_date,
        end_date,
        strategy_config: dict,
        backtest_config,
        task_id: str,
        backtest_id: str,
    ) -> dict:
        """
        å¤šè¿›ç¨‹å¹¶è¡Œå›æµ‹ï¼ˆP2 æ ¸å¿ƒä¼˜åŒ–ï¼‰

        å°†è‚¡ç¥¨åˆ—è¡¨åˆ†æˆ N ç»„ï¼Œæ¯ç»„ç”±ç‹¬ç«‹ worker è¿›ç¨‹æ‰§è¡Œå›æµ‹ï¼Œ
        æœ€ååˆå¹¶ç»“æœã€‚è¿›åº¦é€šè¿‡ Queue + ProgressBridge å®æ—¶å†™å…¥ DBã€‚
        """
        import multiprocessing as mp
        from multiprocessing import Queue

        from app.core.config import settings

        perf_breakdown: dict = {}
        _t_total = time.perf_counter()

        # ç¡®å®š worker æ•°é‡
        cpu_count = mp.cpu_count() or 4
        num_workers = min(cpu_count - 2, 16)
        num_workers = max(num_workers, 2)  # è‡³å°‘ 2 ä¸ª worker

        logger.info(
            f"P2 å¤šè¿›ç¨‹å›æµ‹: stocks={len(stock_codes)}, "
            f"workers={num_workers}, cpus={cpu_count}"
        )

        # æ›´æ–°ä»»åŠ¡è¿›åº¦åˆ° 30%ï¼ˆå¼€å§‹å¤šè¿›ç¨‹é˜¶æ®µï¼‰
        if task_id:
            self._update_progress_db_direct(
                task_id, 30.0,
                {"stage": "multiprocess_init", "num_workers": num_workers},
            )

        # åˆ†ç»„ï¼šå°½é‡å‡åŒ€åˆ†é…
        groups = [[] for _ in range(num_workers)]
        for i, code in enumerate(stock_codes):
            groups[i % num_workers].append(code)
        # ç§»é™¤ç©ºç»„
        groups = [g for g in groups if g]
        actual_workers = len(groups)

        logger.info(
            f"è‚¡ç¥¨åˆ†ç»„: {actual_workers} ç»„, "
            f"æ¯ç»„ {[len(g) for g in groups]}"
        )

        # åºåˆ—åŒ–é…ç½®
        config_dict = self._serialize_backtest_config(backtest_config)
        data_dir = str(self.data_loader.data_dir)

        # åˆ›å»ºè¿›åº¦é˜Ÿåˆ—å’Œæ¡¥æ¥å™¨
        progress_queue = Queue()
        bridge = ProgressBridge(
            task_id=task_id,
            progress_queue=progress_queue,
            num_workers=actual_workers,
            db_url=settings.database_url_sync,
        )
        bridge.start()

        # å‡†å¤‡ worker å‚æ•°
        worker_args = []
        for wid, group in enumerate(groups):
            worker_args.append((
                wid,
                group,
                data_dir,
                start_date.isoformat(),
                end_date.isoformat(),
                strategy_name,
                strategy_config or {},
                config_dict,
                task_id,
                progress_queue,
            ))

        # å¯åŠ¨å¤šè¿›ç¨‹æ± 
        _t_mp = time.perf_counter()
        ctx = mp.get_context("spawn")

        try:
            with ctx.Pool(processes=actual_workers) as pool:
                results = pool.map(worker_backtest, worker_args)
        finally:
            bridge.stop()

        perf_breakdown["multiprocess_s"] = time.perf_counter() - _t_mp

        # æ£€æŸ¥ç»“æœ
        errors = [r for r in results if "error" in r]
        successes = [r for r in results if "error" not in r]

        if errors:
            for err in errors:
                logger.error(
                    f"Worker {err['worker_id']} å¤±è´¥: {err['error']}"
                )

        if not successes:
            raise RuntimeError(
                f"æ‰€æœ‰ {actual_workers} ä¸ª worker éƒ½å¤±è´¥: "
                + "; ".join(e.get("error", "?") for e in errors)
            )

        logger.info(
            f"å¤šè¿›ç¨‹å®Œæˆ: {len(successes)}/{actual_workers} æˆåŠŸ, "
            f"{len(errors)} å¤±è´¥"
        )

        # åˆå¹¶ç»“æœ
        _t_merge = time.perf_counter()
        merged = self._merge_worker_results(
            successes, backtest_config, strategy_name,
            stock_codes, start_date, end_date, strategy_config,
        )
        perf_breakdown["merge_s"] = time.perf_counter() - _t_merge

        # æ·»åŠ  backtest_id
        merged["backtest_id"] = backtest_id

        # worker è®¡æ—¶æ±‡æ€»
        worker_timings = [r.get("timing", {}) for r in successes]
        perf_breakdown["worker_timings"] = worker_timings
        perf_breakdown["total_wall_s"] = time.perf_counter() - _t_total
        perf_breakdown["num_workers"] = actual_workers
        merged["perf_breakdown"] = perf_breakdown

        logger.info(
            f"ğŸ‰ P2 å¤šè¿›ç¨‹å›æµ‹å®Œæˆ: "
            f"total={perf_breakdown['total_wall_s']:.1f}s, "
            f"mp={perf_breakdown['multiprocess_s']:.1f}s, "
            f"return={merged.get('total_return', 0):.2%}"
        )

        return merged

    def _merge_worker_results(
        self,
        results: list,
        backtest_config,
        strategy_name: str,
        stock_codes: list,
        start_date,
        end_date,
        strategy_config: dict,
    ) -> dict:
        """
        åˆå¹¶å¤šä¸ª worker çš„å›æµ‹ç»“æœ

        è¾“å‡ºæ ¼å¼ä¸ BacktestReportGenerator.generate_backtest_report() ä¸€è‡´ï¼Œ
        ç¡®ä¿ persistence.save_backtest_results() èƒ½æ­£ç¡®å¤„ç†ã€‚
        """
        import numpy as np
        import pandas as pd

        # â”€â”€ åˆå¹¶åŸºç¡€ç»Ÿè®¡ â”€â”€
        total_signals = sum(r["total_signals"] for r in results)
        total_executed_trades = sum(r["executed_trades"] for r in results)
        trading_days = max(
            (r.get("trading_days", 0) for r in results), default=0
        )

        # â”€â”€ åˆå¹¶äº¤æ˜“è®°å½•ï¼ˆå·²åºåˆ—åŒ–ä¸º dictï¼‰ â”€â”€
        all_trade_history = []
        for r in results:
            all_trade_history.extend(r.get("trade_history", []))

        # â”€â”€ åˆå¹¶ portfolio_historyï¼ˆæŒ‰æ—¥æœŸå¯¹é½æ±‚å’Œï¼‰ â”€â”€
        date_to_snapshot: dict = {}
        for r in results:
            for snapshot in r.get("portfolio_history", []):
                date_str = snapshot["date"]
                if date_str not in date_to_snapshot:
                    date_to_snapshot[date_str] = {
                        "date": date_str,
                        "portfolio_value": 0.0,
                        "portfolio_value_without_cost": 0.0,
                        "cash": 0.0,
                        "positions_count": 0,
                        "positions": {},
                        "total_return": 0.0,
                    }
                agg = date_to_snapshot[date_str]
                agg["portfolio_value"] += snapshot.get("portfolio_value", 0.0)
                agg["portfolio_value_without_cost"] += snapshot.get(
                    "portfolio_value_without_cost",
                    snapshot.get("portfolio_value", 0.0),
                )
                agg["cash"] += snapshot.get("cash", 0.0)
                agg["positions_count"] += snapshot.get("positions_count", 0)
                # åˆå¹¶æŒä»“ï¼ˆä¸åŒ worker çš„è‚¡ç¥¨ä¸é‡å ï¼‰
                agg["positions"].update(snapshot.get("positions", {}))

        merged_history = sorted(
            date_to_snapshot.values(), key=lambda x: x["date"]
        )

        # è®¡ç®—åˆå¹¶åçš„ total_return
        total_injection = sum(
            r.get("total_capital_injection", 0.0) for r in results
        )
        total_initial = backtest_config.initial_cash * len(results)
        total_invested = total_initial + total_injection

        for snap in merged_history:
            pv = snap["portfolio_value"]
            snap["total_return"] = (
                (pv - total_invested) / total_invested
                if total_invested > 0 else 0.0
            )
            pv_nc = snap["portfolio_value_without_cost"]
            snap["total_return_without_cost"] = (
                (pv_nc - total_invested) / total_invested
                if total_invested > 0 else 0.0
            )

        # â”€â”€ åˆå¹¶æƒç›Šæ›²çº¿ï¼ˆç”¨äºæŒ‡æ ‡è®¡ç®—ï¼‰ â”€â”€
        date_to_values: dict = {}
        for r in results:
            for date_val, value in r.get("equity_curve", []):
                if date_val not in date_to_values:
                    date_to_values[date_val] = 0.0
                date_to_values[date_val] += value
        merged_equity = sorted(date_to_values.items(), key=lambda x: x[0])

        # â”€â”€ è®¡ç®—åˆå¹¶åçš„ç»©æ•ˆæŒ‡æ ‡ â”€â”€
        final_value = merged_equity[-1][1] if merged_equity else total_invested
        merged_metrics = {}

        if merged_equity and len(merged_equity) > 1:
            values = [v for _, v in merged_equity]
            returns = pd.Series(values).pct_change().dropna()

            total_return = (
                (values[-1] - total_invested) / total_invested
                if total_invested > 0 else 0.0
            )

            days = (merged_equity[-1][0] - merged_equity[0][0]).days
            ann_return = (
                (1 + total_return) ** (365 / max(days, 1)) - 1
                if days > 0 else 0.0
            )

            vol = float(returns.std() * np.sqrt(252)) if len(returns) > 1 else 0.0
            sharpe = ann_return / vol if vol > 0 else 0.0

            cum_ret = (1 + returns).cumprod()
            running_max = cum_ret.expanding().max()
            drawdown = (cum_ret - running_max) / running_max
            max_dd = float(drawdown.min()) if len(drawdown) > 0 else 0.0

            # èƒœç‡ï¼ˆtrade_history æ˜¯ dict åˆ—è¡¨ï¼‰
            winning = sum(
                1 for t in all_trade_history
                if t.get("pnl", 0) > 0
            )
            losing = sum(
                1 for t in all_trade_history
                if t.get("pnl", 0) < 0
            )
            win_rate = winning / len(all_trade_history) if all_trade_history else 0.0

            # profit_factor
            gross_profit = sum(
                t.get("pnl", 0) for t in all_trade_history if t.get("pnl", 0) > 0
            )
            gross_loss = abs(sum(
                t.get("pnl", 0) for t in all_trade_history if t.get("pnl", 0) < 0
            ))
            profit_factor = gross_profit / gross_loss if gross_loss > 0 else 0.0

            merged_metrics = {
                "total_return": float(total_return),
                "annualized_return": float(ann_return),
                "volatility": vol,
                "sharpe_ratio": float(sharpe),
                "max_drawdown": max_dd,
                "total_trades": len(all_trade_history),
                "win_rate": float(win_rate),
                "profit_factor": float(profit_factor),
                "winning_trades": winning,
                "losing_trades": losing,
                "total_capital_injection": float(total_injection),
            }
        else:
            merged_metrics = {
                "total_return": 0.0,
                "annualized_return": 0.0,
                "volatility": 0.0,
                "sharpe_ratio": 0.0,
                "max_drawdown": 0.0,
                "total_trades": len(all_trade_history),
                "win_rate": 0.0,
                "profit_factor": 0.0,
                "winning_trades": 0,
                "losing_trades": 0,
                "total_capital_injection": float(total_injection),
            }

        # â”€â”€ åˆå¹¶æˆæœ¬ç»Ÿè®¡ â”€â”€
        total_commission = sum(r.get("total_commission", 0.0) for r in results)
        total_slippage = sum(r.get("total_slippage", 0.0) for r in results)

        # â”€â”€ åˆå¹¶ç†”æ–­ä¿¡æ¯ â”€â”€
        cb_summary = None
        for r in results:
            cb = r.get("circuit_breaker_summary")
            if cb and cb.get("triggered"):
                cb_summary = cb
                break

        # â”€â”€ æ„å»ºæŠ¥å‘Šï¼ˆå…¼å®¹ report_generator + persistence æ ¼å¼ï¼‰ â”€â”€
        actual_codes = []
        for r in results:
            actual_codes.extend(r.get("stock_codes", []))

        report = {
            # åŸºç¡€ä¿¡æ¯
            "strategy_name": strategy_name,
            "stock_codes": actual_codes,
            "start_date": start_date.isoformat(),
            "end_date": end_date.isoformat(),
            "initial_cash": total_invested,
            "final_value": float(final_value),
            # ç»©æ•ˆæŒ‡æ ‡ï¼ˆé¡¶å±‚ï¼Œä¾› dependencies.py ç›´æ¥è¯»å–ï¼‰
            "total_return": merged_metrics.get("total_return", 0.0),
            "annualized_return": merged_metrics.get("annualized_return", 0.0),
            "volatility": merged_metrics.get("volatility", 0.0),
            "sharpe_ratio": merged_metrics.get("sharpe_ratio", 0.0),
            "max_drawdown": merged_metrics.get("max_drawdown", 0.0),
            "win_rate": merged_metrics.get("win_rate", 0.0),
            "profit_factor": merged_metrics.get("profit_factor", 0.0),
            "winning_trades": merged_metrics.get("winning_trades", 0),
            "losing_trades": merged_metrics.get("losing_trades", 0),
            "total_trades": merged_metrics.get("total_trades", 0),
            "total_signals": total_signals,
            "executed_trades": total_executed_trades,
            "trading_days": trading_days,
            # åµŒå¥—ç»©æ•ˆæŒ‡æ ‡ï¼ˆä¾› persistence adapter ä½¿ç”¨ï¼‰
            "performance_metrics": merged_metrics,
            # äº¤æ˜“å’Œç»„åˆå†å²ï¼ˆpersistence æ ¸å¿ƒæ•°æ®ï¼‰
            "trade_history": all_trade_history,
            "portfolio_history": merged_history,
            # é…ç½®ä¿¡æ¯
            "backtest_config": {
                "strategy_name": strategy_name,
                "start_date": start_date.isoformat(),
                "end_date": end_date.isoformat(),
                "initial_cash": backtest_config.initial_cash,
                "commission_rate": backtest_config.commission_rate,
                "slippage_rate": backtest_config.slippage_rate,
                "max_position_size": backtest_config.max_position_size,
                "unlimited_buying": getattr(backtest_config, "unlimited_buying", False),
                **(
                    {"strategy_config": strategy_config}
                    if strategy_config and isinstance(strategy_config, dict)
                    else {}
                ),
            },
            # æˆæœ¬ç»Ÿè®¡
            "cost_statistics": {
                "total_commission": float(total_commission),
                "total_slippage": float(total_slippage),
                "total_capital_injection": float(total_injection),
                "total_cost": float(total_commission + total_slippage),
            },
            # å…ƒä¿¡æ¯
            "n_stocks": len(actual_codes),
            "auto_position_sizing": getattr(
                backtest_config, "auto_position_sizing", None
            ),
            "unlimited_buying": getattr(
                backtest_config, "unlimited_buying", None
            ),
            "configured_max_position_size": backtest_config.max_position_size,
            "multiprocess": True,
            "num_workers": len(results),
        }

        if cb_summary:
            report["circuit_breaker"] = cb_summary

        return report

    @staticmethod
    def _serialize_backtest_config(config) -> dict:
        """å°† BacktestConfig åºåˆ—åŒ–ä¸º dictï¼ˆä¾›å­è¿›ç¨‹é‡å»ºï¼‰"""
        return {
            "initial_cash": config.initial_cash,
            "commission_rate": config.commission_rate,
            "slippage_rate": config.slippage_rate,
            "max_position_size": config.max_position_size,
            "stop_loss_pct": config.stop_loss_pct,
            "take_profit_pct": config.take_profit_pct,
            "rebalance_frequency": config.rebalance_frequency,
            "max_drawdown_pct": getattr(config, "max_drawdown_pct", None),
            "record_portfolio_history": config.record_portfolio_history,
            "portfolio_history_stride": config.portfolio_history_stride,
            "record_positions_in_history": config.record_positions_in_history,
            "auto_position_sizing": getattr(
                config, "auto_position_sizing", True
            ),
            "unlimited_buying": getattr(
                config, "unlimited_buying", False
            ),
        }

    def _update_progress_db_direct(
        self, task_id: str, progress: float, extra_data: dict = None,
    ) -> None:
        """ç›´æ¥ç”¨ psycopg2 æ›´æ–°è¿›åº¦ï¼ˆä¸ä¾èµ– SessionLocal è¿æ¥æ± ï¼‰"""
        import json
        import psycopg2
        from app.core.config import settings

        try:
            conn = psycopg2.connect(settings.database_url_sync)
            try:
                cur = conn.cursor()
                cur.execute(
                    "SELECT result FROM tasks WHERE task_id = %s",
                    (task_id,),
                )
                row = cur.fetchone()
                result_data = row[0] if row and row[0] else {}
                if not isinstance(result_data, dict):
                    result_data = {}
                if extra_data:
                    result_data["progress_data"] = extra_data
                cur.execute(
                    """
                    UPDATE tasks SET progress = %s, result = %s::jsonb
                    WHERE task_id = %s AND status = 'running'
                    """,
                    (progress, json.dumps(result_data, default=str), task_id),
                )
                conn.commit()
                cur.close()
            finally:
                conn.close()
        except Exception as e:
            logger.warning(f"ç›´æ¥æ›´æ–°è¿›åº¦å¤±è´¥: {e}")

    # â”€â”€ åŒæ­¥è¾…åŠ©æ–¹æ³•ï¼ˆä¾› run_backtest_sync ä½¿ç”¨ï¼‰ â”€â”€

    def _start_progress_sync(self, task_id: str, backtest_id: str):
        """åŒæ­¥ç‰ˆè¿›åº¦ç›‘æ§åˆå§‹åŒ–ï¼ˆç›´æ¥æ“ä½œå†…å­˜æ•°æ®ç»“æ„ï¼‰"""
        try:
            from .backtest_progress_monitor import (
                BacktestProgressData,
                backtest_progress_monitor,
            )
            from datetime import datetime as _dt

            progress_data = BacktestProgressData(
                task_id=task_id,
                backtest_id=backtest_id,
                start_time=_dt.utcnow(),
                total_trading_days=0,
                stages=[s for s in backtest_progress_monitor.stage_definitions],
            )
            backtest_progress_monitor.active_backtests[task_id] = progress_data
        except Exception as e:
            logger.warning(f"åŒæ­¥è¿›åº¦ç›‘æ§åˆå§‹åŒ–å¤±è´¥ï¼ˆä¸å½±å“å›æµ‹ï¼‰: {e}")

    def _update_total_days_sync(self, task_id: str, total_days: int):
        """åŒæ­¥æ›´æ–°æ€»äº¤æ˜“æ—¥æ•°åˆ°æ•°æ®åº“"""
        try:
            from app.core.database import SessionLocal
            from app.models.task_models import TaskStatus
            from app.repositories.task_repository import TaskRepository

            session = SessionLocal()
            try:
                task_repo = TaskRepository(session)
                existing_task = task_repo.get_task_by_id(task_id)
                if existing_task:
                    result_data = existing_task.result or {}
                    progress_data_db = result_data.get("progress_data", {})
                    progress_data_db["total_days"] = total_days
                    result_data["progress_data"] = progress_data_db
                    task_repo.update_task_status(
                        task_id=task_id,
                        status=TaskStatus.RUNNING,
                        result=result_data,
                    )
            finally:
                session.close()
        except Exception as e:
            logger.warning(f"æ›´æ–°æ€»äº¤æ˜“æ—¥æ•°å¤±è´¥: {e}")

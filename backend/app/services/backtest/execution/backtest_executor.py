"""
å›æµ‹æ‰§è¡Œå™¨ - å®Œæ•´çš„å›æµ‹æµç¨‹æ‰§è¡Œå’Œç»“æœåˆ†æ
"""

import asyncio
import time
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime, timedelta
from functools import partial
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from loguru import logger

from app.core.error_handler import ErrorContext, ErrorSeverity, TaskError
from app.models.task_models import BacktestResult

from ..core.base_strategy import BaseStrategy
from ..core.portfolio_manager import PortfolioManager
from ..core.portfolio_manager_array import PortfolioManagerArray
from ..models import BacktestConfig, Position, SignalType, Trade, TradingSignal
from ..strategies.strategy_factory import AdvancedStrategyFactory, StrategyFactory
from .backtest_progress_monitor import backtest_progress_monitor
from .data_loader import DataLoader

# æ€§èƒ½ç›‘æ§ï¼ˆå¯é€‰å¯¼å…¥ï¼Œé¿å…ä¾èµ–é—®é¢˜ï¼‰
try:
    from ..utils.performance_profiler import (
        BacktestPerformanceProfiler,
        PerformanceContext,
    )

    PERFORMANCE_PROFILING_AVAILABLE = True
except ImportError:
    PERFORMANCE_PROFILING_AVAILABLE = False
    BacktestPerformanceProfiler = None
    PerformanceContext = None


def _multiprocess_precompute_worker(task: Tuple) -> Tuple[bool, str, Optional[Dict], Optional[str]]:
    """
    å¤šè¿›ç¨‹é¢„è®¡ç®— worker å‡½æ•°ï¼ˆæ¨¡å—çº§ï¼Œå¯è¢« pickle åºåˆ—åŒ–ï¼‰ã€‚

    Args:
        task: (stock_code, data_dict, strategy_info) å…ƒç»„

    Returns:
        (success, stock_code, signals_dict, error_message)
    """
    stock_code, data_dict, strategy_info = task

    try:
        # é‡å»º DataFrame
        df = pd.DataFrame(data_dict['values'], columns=data_dict['columns'])
        df.index = pd.to_datetime(data_dict['index'])
        df.attrs['stock_code'] = data_dict['stock_code']

        # é‡å»ºç­–ç•¥å¯¹è±¡
        from ..strategies.strategy_factory import StrategyFactory, AdvancedStrategyFactory

        strategy_name = strategy_info['name']  # ä½¿ç”¨ç­–ç•¥åç§°ï¼ˆå¦‚ "MACD"ï¼‰
        strategy_class_name = strategy_info['class_name']  # ç±»åï¼ˆå¦‚ "MACDStrategy"ï¼‰
        strategy_config = strategy_info['config']

        # å°è¯•ä»å·¥å‚åˆ›å»ºç­–ç•¥ï¼ˆå°è¯•å¤šç§åç§°æ ¼å¼ï¼‰
        strategy = None
        names_to_try = [
            strategy_name,  # åŸå§‹åç§°
            strategy_name.lower(),  # å°å†™
            strategy_class_name,  # ç±»å
            strategy_class_name.replace('Strategy', ''),  # å»æ‰ Strategy åç¼€
            strategy_class_name.replace('Strategy', '').lower(),  # å»æ‰åç¼€å¹¶å°å†™
        ]

        for name in names_to_try:
            if strategy is not None:
                break
            try:
                strategy = StrategyFactory.create_strategy(name, strategy_config)
            except Exception:
                try:
                    strategy = AdvancedStrategyFactory.create_strategy(name, strategy_config)
                except Exception:
                    pass

        if strategy is None:
            return (False, stock_code, None, f"æ— æ³•åˆ›å»ºç­–ç•¥ {strategy_name} (å°è¯•äº†: {names_to_try})")

        # æ‰§è¡Œå‘é‡åŒ–é¢„è®¡ç®—
        signals = strategy.precompute_all_signals(df)

        if signals is not None:
            # å°† Series è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
            signals_dict = {
                'values': signals.tolist(),
                'index': [str(idx) for idx in signals.index],
            }
            return (True, stock_code, signals_dict, None)
        else:
            return (False, stock_code, None, "precompute_all_signals è¿”å› None")

    except Exception as e:
        return (False, stock_code, None, str(e))


class BacktestExecutor:
    """å›æµ‹æ‰§è¡Œå™¨"""

    def __init__(
        self,
        data_dir: str = "backend/data",
        enable_parallel: bool = True,
        max_workers: Optional[int] = None,
        enable_performance_profiling: bool = False,
        use_multiprocessing: bool = False,
    ):
        """
        åˆå§‹åŒ–å›æµ‹æ‰§è¡Œå™¨

        Args:
            data_dir: æ•°æ®ç›®å½•
            enable_parallel: æ˜¯å¦å¯ç”¨å¹¶è¡ŒåŒ–ï¼ˆé»˜è®¤Trueï¼‰
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼Œé»˜è®¤ä½¿ç”¨CPUæ ¸å¿ƒæ•°
            enable_performance_profiling: æ˜¯å¦å¯ç”¨æ€§èƒ½åˆ†æï¼ˆé»˜è®¤Falseï¼‰
            use_multiprocessing: æ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹ï¼ˆçªç ´GILé™åˆ¶ï¼Œé»˜è®¤Falseï¼‰
                - True: ä½¿ç”¨ ProcessPoolExecutorï¼Œé€‚åˆ CPU å¯†é›†å‹ç­–ç•¥
                - False: ä½¿ç”¨ ThreadPoolExecutorï¼Œåºåˆ—åŒ–å¼€é”€å°
        """
        import os

        if max_workers is None:
            max_workers = min(os.cpu_count() or 4, 8)  # æœ€å¤š8ä¸ªçº¿ç¨‹ï¼Œé¿å…è¿‡å¤šçº¿ç¨‹å¯¼è‡´å¼€é”€

        self.enable_parallel = enable_parallel
        self.max_workers = max_workers
        self.use_multiprocessing = use_multiprocessing
        self.use_array_portfolio = True  # Phase 1: å¯ç”¨æ•°ç»„åŒ–æŒä»“ç®¡ç†
        self.data_loader = DataLoader(
            data_dir, max_workers=max_workers if enable_parallel else None
        )
        self.execution_stats = {
            "total_backtests": 0,
            "successful_backtests": 0,
            "failed_backtests": 0,
        }

        # æ€§èƒ½åˆ†æå™¨ï¼ˆå¯é€‰ï¼‰
        self.enable_performance_profiling = (
            enable_performance_profiling and PERFORMANCE_PROFILING_AVAILABLE
        )
        self.performance_profiler: Optional[BacktestPerformanceProfiler] = None

        if enable_parallel:
            mode = "å¤šè¿›ç¨‹" if use_multiprocessing else "å¤šçº¿ç¨‹"
            logger.info(f"å›æµ‹æ‰§è¡Œå™¨å·²å¯ç”¨å¹¶è¡ŒåŒ–ï¼ˆ{mode}ï¼‰ï¼Œæœ€å¤§å·¥ä½œè¿›ç¨‹/çº¿ç¨‹æ•°: {max_workers}")

        if self.enable_performance_profiling:
            logger.info("å›æµ‹æ‰§è¡Œå™¨å·²å¯ç”¨æ€§èƒ½åˆ†æ")

    async def run_backtest(
        self,
        strategy_name: str,
        stock_codes: List[str],
        start_date: datetime,
        end_date: datetime,
        strategy_config: Dict[str, Any],
        backtest_config: Optional[BacktestConfig] = None,
        task_id: str = None,
    ) -> Dict[str, Any]:
        """è¿è¡Œå›æµ‹"""
        # è½»é‡åˆ†æ®µè®¡æ—¶ï¼ˆå§‹ç»ˆå¯ç”¨ï¼Œä¸ä¾èµ– performance_profilerï¼‰
        perf_breakdown: Dict[str, float] = {}
        _t_total0 = time.perf_counter()

        # åˆå§‹åŒ–æ€§èƒ½åˆ†æå™¨
        if self.enable_performance_profiling:
            self.performance_profiler = BacktestPerformanceProfiler(
                enable_memory_tracking=True
            )
            self.performance_profiler.start_backtest()
            self.performance_profiler.take_memory_snapshot("backtest_start")

        try:
            self.execution_stats["total_backtests"] += 1

            # ç”Ÿæˆå›æµ‹ID
            backtest_id = f"bt_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hash(str(stock_codes))}"

            # ä½¿ç”¨é»˜è®¤é…ç½®
            if backtest_config is None:
                backtest_config = BacktestConfig()

            # å¼€å§‹è¿›åº¦ç›‘æ§
            if task_id:
                await backtest_progress_monitor.start_backtest_monitoring(
                    task_id=task_id, backtest_id=backtest_id
                )
                await backtest_progress_monitor.update_stage(
                    task_id, "initialization", progress=100, status="completed"
                )

            # åˆ›å»ºç­–ç•¥ï¼ˆæ€§èƒ½ç›‘æ§ï¼‰
            _t0 = time.perf_counter()
            if self.enable_performance_profiling:
                self.performance_profiler.start_stage(
                    "strategy_setup",
                    {"strategy_name": strategy_name, "stock_count": len(stock_codes)},
                )

            if task_id:
                await backtest_progress_monitor.update_stage(
                    task_id, "strategy_setup", status="running"
                )

            # ä¼˜å…ˆä½¿ç”¨é«˜çº§ç­–ç•¥å·¥å‚
            try:
                strategy = AdvancedStrategyFactory.create_strategy(
                    strategy_name, strategy_config
                )
            except Exception:
                # å¦‚æœé«˜çº§ç­–ç•¥å·¥å‚æ²¡æœ‰è¯¥ç­–ç•¥ï¼Œå›é€€åˆ°åŸºç¡€ç­–ç•¥å·¥å‚
                strategy = StrategyFactory.create_strategy(
                    strategy_name, strategy_config
                )

            if self.enable_performance_profiling:
                self.performance_profiler.end_stage("strategy_setup")
            perf_breakdown["strategy_setup_s"] = time.perf_counter() - _t0

            if task_id:
                await backtest_progress_monitor.update_stage(
                    task_id, "strategy_setup", progress=100, status="completed"
                )

            # åˆ›å»ºç»„åˆç®¡ç†å™¨
            # Phase 1: æ•°æ®åŠ è½½åå†åˆ›å»ºï¼ˆéœ€è¦ stock_codesï¼‰
            portfolio_manager = None

            # åŠ è½½æ•°æ®ï¼ˆæ€§èƒ½ç›‘æ§ï¼‰
            _t0 = time.perf_counter()
            if self.enable_performance_profiling:
                self.performance_profiler.start_stage(
                    "data_loading",
                    {
                        "stock_codes": stock_codes,
                        "start_date": start_date.isoformat(),
                        "end_date": end_date.isoformat(),
                    },
                )

            if task_id:
                await backtest_progress_monitor.update_stage(
                    task_id, "data_loading", status="running"
                )

            logger.info(
                f"å¼€å§‹å›æµ‹: {strategy_name}, è‚¡ç¥¨: {stock_codes}, æœŸé—´: {start_date} - {end_date}"
            )
            stock_data = self.data_loader.load_multiple_stocks(
                stock_codes, start_date, end_date
            )

            if self.enable_performance_profiling:
                self.performance_profiler.end_stage(
                    "data_loading",
                    {
                        "loaded_stocks": len(stock_data),
                        "total_records": sum(len(df) for df in stock_data.values()),
                    },
                )
                self.performance_profiler.take_memory_snapshot("after_data_loading")
            perf_breakdown["data_loading_s"] = time.perf_counter() - _t0

            if task_id:
                await backtest_progress_monitor.update_stage(
                    task_id, "data_loading", progress=100, status="completed"
                )

            # Phase 1: æ•°æ®åŠ è½½ååˆ›å»ºç»„åˆç®¡ç†å™¨ï¼ˆä½¿ç”¨å®é™…åŠ è½½çš„è‚¡ç¥¨åˆ—è¡¨ï¼‰
            actual_stock_codes = list(stock_data.keys())
            if self.use_array_portfolio:
                portfolio_manager = PortfolioManagerArray(backtest_config, actual_stock_codes)
                logger.info(f"âœ… Phase 1: ä½¿ç”¨æ•°ç»„åŒ–æŒä»“ç®¡ç†å™¨ (stocks={len(actual_stock_codes)})")
            else:
                portfolio_manager = PortfolioManager(backtest_config)
                logger.info(f"ä½¿ç”¨ä¼ ç»ŸæŒä»“ç®¡ç†å™¨ (stocks={len(actual_stock_codes)})")

            # è·å–äº¤æ˜“æ—¥å†
            trading_dates = self._get_trading_calendar(stock_data, start_date, end_date)

            # é¢„å¤„ç†ï¼ˆæ—¥æœŸç´¢å¼• + é¢„è®¡ç®—ä¿¡å· + ä¿¡å·æå–ï¼‰
            _t0 = time.perf_counter()

            # âœ… æ—¥æœŸé¢„ç´¢å¼•ï¼šä¸ºæ¯åªè‚¡ç¥¨å»ºç«‹ date->idx æ˜ å°„ï¼Œå›æµ‹å¾ªç¯é‡Œç”¨ O(1) æŸ¥æ‰¾æ›¿ä»£ get_loc
            # ç»éªŒä¸Šè¿™æ˜¯çº¯æ”¶ç›Šï¼ˆç›¸æ¯”æŒ‡æ ‡é¢„çƒ­ï¼Œä¸ä¼šæŠŠè®¡ç®—ä¸²è¡ŒåŒ–ï¼‰ã€‚
            self._build_date_index(stock_data)

            # âœ… ä¿¡å·å‘é‡åŒ–é¢„è®¡ç®—ï¼šåœ¨è¿›å…¥æ¯æ—¥å¾ªç¯å‰ï¼Œå…ˆå°è¯•ä¸€æ¬¡æ€§ç®—å‡ºå…¨é‡ä¹°å–ç‚¹
            self._precompute_strategy_signals(strategy, stock_data)
            
            # âœ… ä¿¡å·æå–ä¼˜åŒ–ï¼šå°†é¢„è®¡ç®—ä¿¡å·æå–åˆ°æ‰å¹³å­—å…¸ï¼Œé¿å…å›æµ‹å¾ªç¯ä¸­é‡å¤æŸ¥æ‰¾ attrs
            precomputed_signals = self._extract_precomputed_signals_to_dict(strategy, stock_data)
            
            # ğŸ” è°ƒè¯•æ—¥å¿—ï¼šæ£€æŸ¥é¢„è®¡ç®—ä¿¡å·
            logger.info(f"ğŸ” é¢„è®¡ç®—ä¿¡å·å­—å…¸å¤§å°: {len(precomputed_signals)}")
            if precomputed_signals:
                sample_keys = list(precomputed_signals.keys())[:3]
                for k in sample_keys:
                    logger.info(f"  ç¤ºä¾‹ key: {k}, value: {precomputed_signals[k]}")

            perf_breakdown["precompute_signals_s"] = time.perf_counter() - _t0
            # align_arrays_s ç»Ÿè®¡åœ¨ main_loop å‰å•ç‹¬è®°å½•

            # æ³¨ï¼šæŒ‡æ ‡é¢„çƒ­ï¼ˆ_warm_indicator_cacheï¼‰å¦‚æœåœ¨ä¸»çº¿ç¨‹é¡ºåºæ‰§è¡Œï¼Œå¯èƒ½ä¼šæŠŠåŸæœ¬å¹¶è¡Œçš„æŒ‡æ ‡è®¡ç®—ä¸²è¡ŒåŒ–ï¼Œ
            # å› è€Œæœªé»˜è®¤å¼€å¯ï¼›åç»­å¯æŒ‰éœ€å®ç°å¹¶è¡Œé¢„çƒ­ã€‚

            if len(trading_dates) < 20:
                error_msg = f"äº¤æ˜“æ—¥æ•°é‡ä¸è¶³: {len(trading_dates)}ï¼Œè‡³å°‘éœ€è¦20ä¸ªäº¤æ˜“æ—¥"
                if task_id:
                    await backtest_progress_monitor.set_error(task_id, error_msg)
                raise TaskError(message=error_msg, severity=ErrorSeverity.MEDIUM)

            # æ›´æ–°æ€»äº¤æ˜“æ—¥æ•°ï¼ˆåŒæ—¶å†™å…¥æ•°æ®åº“ï¼‰
            if task_id:
                progress_data = backtest_progress_monitor.get_progress_data(task_id)
                if progress_data:
                    progress_data.total_trading_days = len(trading_dates)

                # å°†æ€»äº¤æ˜“æ—¥æ•°å†™å…¥æ•°æ®åº“
                try:
                    from app.core.database import SessionLocal
                    from app.models.task_models import TaskStatus
                    from app.repositories.task_repository import TaskRepository

                    session = SessionLocal()
                    try:
                        task_repo = TaskRepository(session)
                        existing_task = task_repo.get_task_by_id(task_id)
                        if existing_task:
                            result_data = existing_task.result or {}
                            progress_data_db = result_data.get("progress_data", {})
                            progress_data_db["total_days"] = len(trading_dates)
                            result_data["progress_data"] = progress_data_db

                            task_repo.update_task_status(
                                task_id=task_id,
                                status=TaskStatus.RUNNING,
                                result=result_data,
                            )
                    finally:
                        session.close()
                except Exception as e:
                    logger.warning(f"æ›´æ–°æ€»äº¤æ˜“æ—¥æ•°å¤±è´¥: {e}")

            # æ‰§è¡Œå›æµ‹ï¼ˆæ€§èƒ½ç›‘æ§ï¼‰
            if self.enable_performance_profiling:
                self.performance_profiler.start_stage(
                    "backtest_execution",
                    {
                        "total_trading_days": len(trading_dates),
                        "stock_count": len(stock_data),
                    },
                )

            if task_id:
                await backtest_progress_monitor.update_stage(
                    task_id, "backtest_execution", status="running"
                )

            _t0 = time.perf_counter()
            # Phase1 é¢„å¤‡ï¼šå°† close/valid/signal å¯¹é½æˆ ndarrayï¼Œå‡å°‘ä¸»å¾ªç¯ DataFrame/dict è®¿é—®
            _t1 = time.perf_counter()
            aligned_arrays = self._build_aligned_arrays(strategy, stock_data, trading_dates)
            perf_breakdown["align_arrays_s"] = time.perf_counter() - _t1

            backtest_results = await self._execute_backtest_loop(
                strategy,
                portfolio_manager,
                stock_data,
                trading_dates,
                strategy_config=strategy_config,
                task_id=task_id,
                backtest_id=backtest_id,
                precomputed_signals=precomputed_signals,
                aligned_arrays=aligned_arrays,
            )
            perf_breakdown["main_loop_s"] = time.perf_counter() - _t0

            if self.enable_performance_profiling:
                self.performance_profiler.end_stage(
                    "backtest_execution",
                    {
                        "total_signals": backtest_results.get("total_signals", 0),
                        "executed_trades": backtest_results.get("executed_trades", 0),
                        "trading_days": backtest_results.get("trading_days", 0),
                    },
                )
                self.performance_profiler.update_backtest_stats(
                    signals=backtest_results.get("total_signals", 0),
                    trades=backtest_results.get("executed_trades", 0),
                    days=backtest_results.get("trading_days", 0),
                )
                self.performance_profiler.take_memory_snapshot(
                    "after_backtest_execution"
                )

            if task_id:
                await backtest_progress_monitor.update_stage(
                    task_id, "backtest_execution", progress=100, status="completed"
                )

            # è®¡ç®—ç»©æ•ˆæŒ‡æ ‡ï¼ˆæ€§èƒ½ç›‘æ§ï¼‰
            if self.enable_performance_profiling:
                self.performance_profiler.start_stage("metrics_calculation")

            if task_id:
                await backtest_progress_monitor.update_stage(
                    task_id, "metrics_calculation", status="running"
                )

            _t0 = time.perf_counter()
            performance_metrics = portfolio_manager.get_performance_metrics()
            perf_breakdown["metrics_s"] = time.perf_counter() - _t0

            if self.enable_performance_profiling:
                self.performance_profiler.end_stage("metrics_calculation")

            if task_id:
                await backtest_progress_monitor.update_stage(
                    task_id, "metrics_calculation", progress=100, status="completed"
                )

            # ç”Ÿæˆå›æµ‹æŠ¥å‘Šï¼ˆæ€§èƒ½ç›‘æ§ï¼‰
            if self.enable_performance_profiling:
                self.performance_profiler.start_stage("report_generation")

            if task_id:
                await backtest_progress_monitor.update_stage(
                    task_id, "report_generation", status="running"
                )

            # è®°å½•ç­–ç•¥é…ç½®ä¿¡æ¯
            if (
                strategy_config
                and isinstance(strategy_config, dict)
                and len(strategy_config) > 0
            ):
                logger.info(f"ç”Ÿæˆå›æµ‹æŠ¥å‘Šï¼Œç­–ç•¥é…ç½®: {strategy_config}")
            else:
                logger.warning(
                    f"ç­–ç•¥é…ç½®ä¸ºç©ºæˆ–æ— æ•ˆ: {strategy_config}, ç±»å‹: {type(strategy_config)}"
                )

            _t0 = time.perf_counter()
            backtest_report = self._generate_backtest_report(
                strategy_name,
                stock_codes,
                start_date,
                end_date,
                backtest_config,
                portfolio_manager,
                performance_metrics,
                strategy_config=strategy_config,
            )
            perf_breakdown["report_generation_s"] = time.perf_counter() - _t0
            # å°†å›æµ‹å¾ªç¯ç»Ÿè®¡ï¼ˆä¿¡å·æ•°ã€äº¤æ˜“æ—¥ç­‰ï¼‰å†™å…¥æŠ¥å‘Šï¼Œä¾¿äºæ’æŸ¥"æ— ä¿¡å·è®°å½•"ç­‰é—®é¢˜
            backtest_report["total_signals"] = backtest_results.get("total_signals", 0)
            backtest_report["trading_days"] = backtest_results.get("trading_days", 0)

            if self.enable_performance_profiling:
                self.performance_profiler.end_stage(
                    "report_generation", {"report_size": len(str(backtest_report))}
                )

            if task_id:
                await backtest_progress_monitor.update_stage(
                    task_id, "report_generation", progress=100, status="completed"
                )
                await backtest_progress_monitor.update_stage(
                    task_id, "data_storage", progress=100, status="completed"
                )

            self.execution_stats["successful_backtests"] += 1
            logger.info(
                f"å›æµ‹å®Œæˆ: {strategy_name}, æ€»æ”¶ç›Š: {performance_metrics.get('total_return', 0):.2%}"
            )

            # å®Œæˆç›‘æ§
            if task_id:
                await backtest_progress_monitor.complete_backtest(
                    task_id,
                    {"total_return": performance_metrics.get("total_return", 0)},
                )

            # ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š
            if self.enable_performance_profiling:
                self.performance_profiler.end_backtest()
                self.performance_profiler.take_memory_snapshot("backtest_end")

                # å°†æ€§èƒ½æŠ¥å‘Šæ·»åŠ åˆ°å›æµ‹æŠ¥å‘Šä¸­
                performance_report = self.performance_profiler.generate_report()
                backtest_report["performance_analysis"] = performance_report

                # æ‰“å°æ€§èƒ½æ‘˜è¦
                self.performance_profiler.print_summary()

                # ä¿å­˜æ€§èƒ½æŠ¥å‘Šåˆ°æ–‡ä»¶ï¼ˆå¦‚æœæä¾›äº†task_idï¼‰
                if task_id:
                    try:
                        import os

                        performance_dir = Path("backend/data/performance_reports")
                        performance_dir.mkdir(parents=True, exist_ok=True)
                        performance_file = (
                            performance_dir / f"backtest_{task_id}_performance.json"
                        )
                        self.performance_profiler.save_report(str(performance_file))
                        logger.info(f"æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ°: {performance_file}")
                    except Exception as e:
                        logger.warning(f"ä¿å­˜æ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")

            # è½»é‡åˆ†æ®µè®¡æ—¶ç»“æœå†™å…¥æŠ¥å‘Šï¼ˆbenchè„šæœ¬å”¯ä¸€å…¥å£ä¾èµ–æ­¤å­—æ®µï¼‰
            perf_breakdown["total_wall_s"] = time.perf_counter() - _t_total0
            backtest_report["perf_breakdown"] = perf_breakdown

            return backtest_report

        except Exception as e:
            self.execution_stats["failed_backtests"] += 1
            error_msg = f"å›æµ‹æ‰§è¡Œå¤±è´¥: {str(e)}"

            # å³ä½¿å‡ºé”™ä¹Ÿç»“æŸæ€§èƒ½åˆ†æ
            if self.enable_performance_profiling and self.performance_profiler:
                try:
                    self.performance_profiler.end_backtest()
                    logger.warning("å›æµ‹å¤±è´¥ï¼Œä½†æ€§èƒ½åˆ†æå·²å®Œæˆ")
                except Exception as perf_error:
                    logger.warning(f"ç»“æŸæ€§èƒ½åˆ†ææ—¶å‡ºé”™: {perf_error}")

            if task_id:
                await backtest_progress_monitor.set_error(task_id, error_msg)

            raise TaskError(
                message=error_msg, severity=ErrorSeverity.HIGH, original_exception=e
            )

    def _get_trading_calendar(
        self,
        stock_data: Dict[str, pd.DataFrame],
        start_date: datetime,
        end_date: datetime,
    ) -> List[datetime]:
        """è·å–äº¤æ˜“æ—¥å†"""
        # åˆå¹¶æ‰€æœ‰è‚¡ç¥¨çš„äº¤æ˜“æ—¥æœŸ
        all_dates = set()
        for data in stock_data.values():
            all_dates.update(data.index.tolist())

        # è¿‡æ»¤æ—¥æœŸèŒƒå›´å¹¶æ’åº
        trading_dates = sorted(
            [date for date in all_dates if start_date <= date <= end_date]
        )

        return trading_dates

    def _build_date_index(self, stock_data: Dict[str, pd.DataFrame]) -> None:
        """ä¸ºæ¯åªè‚¡ç¥¨å»ºç«‹æ—¥æœŸ->æ•´æ•°ç´¢å¼•ï¼Œé¿å…å›æµ‹å¾ªç¯ä¸­é‡å¤ get_locã€‚"""
        for data in stock_data.values():
            try:
                if "_date_to_idx" not in data.attrs:
                    data.attrs["_date_to_idx"] = {
                        d: i for i, d in enumerate(data.index)
                    }
            except Exception:
                pass

    def _warm_indicator_cache(
        self,
        strategy: BaseStrategy,
        stock_data: Dict[str, pd.DataFrame],
    ) -> None:
        """å›æµ‹å¼€å§‹å‰é¢„è®¡ç®—å¹¶ç¼“å­˜æ‰€æœ‰è‚¡ç¥¨çš„æŒ‡æ ‡ï¼Œé¿å…é¦–æ—¥/é¦–è‚¡ç°åœºè®¡ç®—ã€‚"""
        try:
            from ..core.strategy_portfolio import StrategyPortfolio

            if isinstance(strategy, StrategyPortfolio):
                for sub in strategy.strategies:
                    self._warm_indicator_cache(sub, stock_data)
                return
        except Exception:
            pass
        for data in stock_data.values():
            try:
                strategy.get_cached_indicators(data)
            except Exception:
                pass

    def _precompute_strategy_signals(
        self,
        strategy: BaseStrategy,
        stock_data: Dict[str, pd.DataFrame],
    ) -> None:
        """[æ€§èƒ½ä¼˜åŒ–] åœ¨å›æµ‹å¾ªç¯å¼€å§‹å‰ï¼Œå°è¯•å¯¹æ‰€æœ‰è‚¡ç¥¨è¿›è¡Œå‘é‡åŒ–ä¿¡å·é¢„è®¡ç®—ã€‚"""
        try:
            from ..core.strategy_portfolio import StrategyPortfolio

            if isinstance(strategy, StrategyPortfolio):
                logger.info(f"ğŸš€ Portfolioç­–ç•¥æ£€æµ‹åˆ°ï¼Œé€’å½’é¢„è®¡ç®— {len(strategy.strategies)} ä¸ªå­ç­–ç•¥")
                for sub in strategy.strategies:
                    self._precompute_strategy_signals(sub, stock_data)
                return
        except Exception as e:
            logger.warning(f"Portfolioç­–ç•¥é€’å½’é¢„è®¡ç®—å¤±è´¥: {e}")

        # ç»Ÿè®¡é¢„è®¡ç®—æˆåŠŸçš„è‚¡ç¥¨æ•°
        success_count = 0
        total_stocks = len(stock_data)

        # å¹¶è¡Œé¢„è®¡ç®—ï¼ˆæŒ‰è‚¡ç¥¨ç»´åº¦ï¼‰ï¼Œæ˜¾è‘—é™ä½æ•´ä½“ wall-time
        # æ³¨ï¼šä½¿ç”¨ ProcessPoolExecutor å¯çªç ´ GIL é™åˆ¶ï¼Œä½†éœ€è¦åºåˆ—åŒ–æ•°æ®
        # è¿™é‡Œä½¿ç”¨æ··åˆç­–ç•¥ï¼šCPU å¯†é›†å‹ä»»åŠ¡ç”¨å¤šè¿›ç¨‹ï¼ŒI/O å¯†é›†å‹ç”¨å¤šçº¿ç¨‹
        use_multiprocessing = getattr(self, 'use_multiprocessing', False)

        def _work_one(item):
            stock_code, data = item
            try:
                all_sigs = strategy.precompute_all_signals(data)
                if all_sigs is not None:
                    cache = data.attrs.setdefault("_precomputed_signals", {})
                    # ä½¿ç”¨ strategy.name ä½œä¸ºç¨³å®šçš„ keyï¼Œé¿å…å¤šè¿›ç¨‹ç¯å¢ƒä¸‹ id() å˜åŒ–
                    cache[strategy.name] = all_sigs
                    return True, stock_code, None
                return False, stock_code, None
            except Exception as e:
                return False, stock_code, str(e)

        if self.enable_parallel and total_stocks >= 4:
            if use_multiprocessing:
                # å¤šè¿›ç¨‹æ¨¡å¼ï¼šçªç ´ GIL é™åˆ¶ï¼Œé€‚åˆ CPU å¯†é›†å‹ç­–ç•¥è®¡ç®—
                # æ³¨æ„ï¼šéœ€è¦å°†æ•°æ®åºåˆ—åŒ–ä¼ é€’ï¼Œå¼€é”€è¾ƒå¤§ä½†å¯çœŸæ­£å¹¶è¡Œ
                try:
                    from concurrent.futures import ProcessPoolExecutor as PoolExecutor
                    # å¤šè¿›ç¨‹éœ€è¦ä½¿ç”¨æ¨¡å—çº§å‡½æ•°ï¼Œè¿™é‡Œä½¿ç”¨åŒ…è£…å™¨
                    results = self._precompute_signals_multiprocess(
                        strategy, stock_data
                    )
                    for ok, stock_code, err in results:
                        if ok:
                            success_count += 1
                        elif err:
                            logger.warning(
                                f"ç­–ç•¥ {strategy.name} å¯¹è‚¡ç¥¨ {stock_code} é¢„è®¡ç®—ä¿¡å·å¤±è´¥: {err}"
                            )
                except Exception as e:
                    logger.warning(f"å¤šè¿›ç¨‹é¢„è®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°å¤šçº¿ç¨‹: {e}")
                    use_multiprocessing = False

            if not use_multiprocessing:
                # å¤šçº¿ç¨‹æ¨¡å¼ï¼šå— GIL é™åˆ¶ï¼Œä½†åºåˆ—åŒ–å¼€é”€å°
                with ThreadPoolExecutor(max_workers=self.max_workers) as ex:
                    futures = [ex.submit(_work_one, it) for it in stock_data.items()]
                    for fu in as_completed(futures):
                        ok, stock_code, err = fu.result()
                        if ok:
                            success_count += 1
                        elif err:
                            logger.warning(
                                f"ç­–ç•¥ {strategy.name} å¯¹è‚¡ç¥¨ {stock_code} é¢„è®¡ç®—ä¿¡å·å¤±è´¥: {err}"
                            )
        else:
            for it in stock_data.items():
                ok, stock_code, err = _work_one(it)
                if ok:
                    success_count += 1
                elif err:
                    logger.warning(
                        f"ç­–ç•¥ {strategy.name} å¯¹è‚¡ç¥¨ {stock_code} é¢„è®¡ç®—ä¿¡å·å¤±è´¥: {err}"
                    )

        if success_count > 0:
            logger.info(
                f"âœ… ç­–ç•¥ {strategy.name} å‘é‡åŒ–é¢„è®¡ç®—å®Œæˆ: {success_count}/{total_stocks} åªè‚¡ç¥¨"
            )

    def _extract_precomputed_signals_to_dict(
        self,
        strategy: BaseStrategy,
        stock_data: Dict[str, pd.DataFrame],
    ) -> Dict[Tuple[str, datetime], Any]:
        """
        [æ€§èƒ½ä¼˜åŒ–] å°†é¢„è®¡ç®—çš„ä¿¡å·ä» DataFrame.attrs æå–åˆ°æ‰å¹³å­—å…¸ã€‚
        
        è¿™æ ·åœ¨å›æµ‹å¾ªç¯ä¸­å¯ä»¥ç›´æ¥ç”¨ (stock_code, date) æŸ¥æ‰¾ä¿¡å·ï¼Œ
        é¿å…æ¯æ¬¡éƒ½è®¿é—® attrs å­—å…¸å’Œ id(strategy) æŸ¥æ‰¾ã€‚
        
        Returns:
            Dict[(stock_code, date), signal]: æ‰å¹³çš„ä¿¡å·å­—å…¸
        """
        signal_dict = {}
        
        try:
            from ..core.strategy_portfolio import StrategyPortfolio
            from ..models import TradingSignal
            
            if isinstance(strategy, StrategyPortfolio):
                logger.info(f"ğŸ”„ Portfolioç­–ç•¥ä¿¡å·æ•´åˆå¼€å§‹: {len(strategy.strategies)} ä¸ªå­ç­–ç•¥")
                
                # 1. é€’å½’æå–æ‰€æœ‰å­ç­–ç•¥çš„ä¿¡å·
                all_sub_signals: Dict[Tuple[str, datetime], Any] = {}
                for sub in strategy.strategies:
                    sub_signals = self._extract_precomputed_signals_to_dict(sub, stock_data)
                    all_sub_signals.update(sub_signals)
                
                logger.info(f"ğŸ“Š å­ç­–ç•¥ä¿¡å·æ€»æ•°: {len(all_sub_signals)}")
                
                # 2. æŒ‰æ—¥æœŸåˆ†ç»„å­ç­–ç•¥ä¿¡å·
                from collections import defaultdict
                signals_by_date: Dict[datetime, List[TradingSignal]] = defaultdict(list)
                
                for (stock_code, date), signal_type in all_sub_signals.items():
                    # æ„é€  TradingSignal å¯¹è±¡
                    from ..models import SignalType
                    if signal_type == SignalType.BUY or signal_type == SignalType.SELL:
                        # è·å–ä»·æ ¼
                        try:
                            df = stock_data.get(stock_code)
                            if df is not None and date in df.index:
                                price = float(df.loc[date, 'close'])
                                signal = TradingSignal(
                                    timestamp=date,
                                    stock_code=stock_code,
                                    signal_type=signal_type,
                                    strength=1.0,
                                    price=price,
                                    reason="precomputed",
                                    metadata={}
                                )
                                signals_by_date[date].append(signal)
                        except Exception as e:
                            logger.warning(f"æ„é€ ä¿¡å·å¤±è´¥ {stock_code} @ {date}: {e}")
                
                # 3. å¯¹æ¯ä¸ªæ—¥æœŸçš„ä¿¡å·è¿›è¡Œæ•´åˆ
                integrated_count = 0
                for date, signals in signals_by_date.items():
                    if signals:
                        # è°ƒç”¨ Portfolio çš„ä¿¡å·æ•´åˆå™¨
                        integrated = strategy.integrator.integrate(
                            signals, 
                            strategy.weights,
                            consistency_threshold=0.6
                        )
                        
                        # å°†æ•´åˆåçš„ä¿¡å·æ·»åŠ åˆ°å­—å…¸
                        for sig in integrated:
                            signal_dict[(sig.stock_code, sig.timestamp)] = sig.signal_type
                            integrated_count += 1
                
                logger.info(f"âœ… Portfolioç­–ç•¥ä¿¡å·æ•´åˆå®Œæˆ: {integrated_count} ä¸ªæ•´åˆä¿¡å·")
                return signal_dict
                
        except Exception as e:
            logger.warning(f"Portfolioç­–ç•¥ä¿¡å·æå–å¤±è´¥: {e}")
            import traceback
            logger.warning(traceback.format_exc())
        
        # æå–å•ä¸ªç­–ç•¥çš„ä¿¡å·
        # ä½¿ç”¨ strategy.name ä½œä¸ºç¨³å®šçš„ keyï¼Œé¿å…å¤šè¿›ç¨‹ç¯å¢ƒä¸‹ id() å˜åŒ–
        strategy_key = strategy.name
        extracted_count = 0
        
        for stock_code, data in stock_data.items():
            try:
                precomputed = data.attrs.get("_precomputed_signals", {})
                signals = precomputed.get(strategy_key)
                
                if signals is not None:
                    # signals å¯èƒ½æ˜¯ pd.Series æˆ– dict
                    if isinstance(signals, pd.Series):
                        for date, signal in signals.items():
                            if signal is not None:
                                signal_dict[(stock_code, date)] = signal
                                extracted_count += 1
                    elif isinstance(signals, dict):
                        for date, signal in signals.items():
                            if signal is not None:
                                signal_dict[(stock_code, date)] = signal
                                extracted_count += 1
            except Exception as e:
                logger.warning(f"æå–è‚¡ç¥¨ {stock_code} çš„ä¿¡å·å¤±è´¥: {e}")
        
        if extracted_count > 0:
            logger.info(
                f"âœ… ç­–ç•¥ {strategy.name} ä¿¡å·æå–å®Œæˆ: {extracted_count} ä¸ªä¿¡å·"
            )
        
        return signal_dict

    def _build_aligned_arrays(
        self,
        strategy: BaseStrategy,
        stock_data: Dict[str, pd.DataFrame],
        trading_dates: List[datetime],
    ) -> Dict[str, Any]:
        """[Phase3] å°†æ•°æ®/ä¿¡å·å¯¹é½åˆ° ndarrayï¼Œå‡å°‘ä¸»å¾ªç¯ DataFrame/å­—å…¸è®¿é—®ã€‚
        
        ä¼˜åŒ–ç‚¹ï¼š
        1. ä½¿ç”¨ numpy çš„ searchsorted åŠ é€Ÿæ—¥æœŸæŸ¥æ‰¾
        2. æ‰¹é‡å¡«å……æ•°ç»„ï¼Œå‡å°‘å¾ªç¯
        3. ä½¿ç”¨ .values é¿å… pandas å¼€é”€

        Returns:
            {
              'stock_codes': [...],
              'dates': np.ndarray[datetime64],
              'close': float64[N,T] (nan=missing),
              'open':  float64[N,T] (nan=missing),
              'valid': bool[N,T],
              'signal': int8[N,T] (1=BUY, -1=SELL, 0=NONE)
            }
        """
        stock_codes = list(stock_data.keys())
        T = len(trading_dates)
        N = len(stock_codes)

        dates64 = np.array(trading_dates, dtype='datetime64[ns]')

        # é¢„åˆ†é…æ•°ç»„ï¼ˆPhase 3 ä¼˜åŒ–ï¼šä½¿ç”¨è¿ç»­å†…å­˜ï¼‰
        close = np.full((N, T), np.nan, dtype=np.float64, order='C')
        open_ = np.full((N, T), np.nan, dtype=np.float64, order='C')
        valid = np.zeros((N, T), dtype=bool, order='C')
        signal = np.zeros((N, T), dtype=np.int8, order='C')

        # å¦‚æœå·²åšå‘é‡åŒ–é¢„è®¡ç®—ï¿½ï¿½å·ï¼Œå°½é‡ç›´æ¥è¯»å– per-stock Series å¹¶å¯¹é½åˆ° trading_dates
        strategy_key = strategy.name  # ä½¿ç”¨ strategy.name ä½œä¸ºç¨³å®šçš„ key

        for i, code in enumerate(stock_codes):
            df = stock_data[code]

            # Phase 3 ä¼˜åŒ–ï¼šä½¿ç”¨ reindex æ‰¹é‡å¯¹é½ï¼ˆæ¯”é€ä¸ªæŸ¥æ‰¾å¿«ï¼‰
            try:
                # ä»·æ ¼å¯¹é½ï¼ˆä½¿ç”¨ reindex ä¸€æ¬¡æ€§å®Œæˆï¼‰
                s_close = df['close'].reindex(trading_dates)
                close_values = s_close.values  # ç›´æ¥è·å– numpy æ•°ç»„
                close[i, :] = close_values
                
                if 'open' in df.columns:
                    s_open = df['open'].reindex(trading_dates)
                    open_[i, :] = s_open.values
                
                # ä½¿ç”¨å‘é‡åŒ–æ“ä½œåˆ¤æ–­æœ‰æ•ˆæ€§
                valid[i, :] = ~np.isnan(close_values)
                
            except Exception as e:
                # fallback: per-date fill (slow path, should be rare)
                logger.warning(f"è‚¡ç¥¨ {code} æ•°ç»„å¯¹é½å¤±è´¥ï¼Œä½¿ç”¨æ…¢é€Ÿè·¯å¾„: {e}")
                idx_map = df.attrs.get('_date_to_idx') if hasattr(df, 'attrs') else None
                for t, d in enumerate(trading_dates):
                    try:
                        if idx_map and d in idx_map:
                            k = int(idx_map[d])
                            close[i, t] = float(df['close'].iloc[k])
                            if 'open' in df.columns:
                                open_[i, t] = float(df['open'].iloc[k])
                            valid[i, t] = True
                        elif d in df.index:
                            k = df.index.get_loc(d)
                            close[i, t] = float(df['close'].values[k])
                            if 'open' in df.columns:
                                open_[i, t] = float(df['open'].values[k])
                            valid[i, t] = True
                    except Exception:
                        pass

            # ä¿¡å·å¯¹é½ï¼ˆPhase 3 ä¼˜åŒ–ï¼šä½¿ç”¨ reindex æ‰¹é‡å¯¹é½ï¼‰
            try:
                pre = df.attrs.get('_precomputed_signals', {}) if hasattr(df, 'attrs') else {}
                sig_ser = pre.get(strategy_key)
                if isinstance(sig_ser, pd.Series):
                    # ä½¿ç”¨ reindex æ‰¹é‡å¯¹é½
                    s = sig_ser.reindex(trading_dates)
                    vals = s.values  # ç›´æ¥è·å– numpy æ•°ç»„
                    # å‘é‡åŒ–æ˜ å°„ SignalType to int8
                    for t, v in enumerate(vals):
                        if v == SignalType.BUY:
                            signal[i, t] = 1
                        elif v == SignalType.SELL:
                            signal[i, t] = -1
                elif isinstance(sig_ser, dict):
                    # dict è·¯å¾„ï¼šé€ä¸ªå¡«å……
                    for t, d in enumerate(trading_dates):
                        v = sig_ser.get(d)
                        if v == SignalType.BUY:
                            signal[i, t] = 1
                        elif v == SignalType.SELL:
                            signal[i, t] = -1
            except Exception as e:
                logger.warning(f"è‚¡ç¥¨ {code} ä¿¡å·å¯¹é½å¤±è´¥: {e}")

        return {
            'stock_codes': stock_codes,
            'code_to_i': {c: idx for idx, c in enumerate(stock_codes)},
            'dates': dates64,
            'close': close,
            'open': open_,
            'valid': valid,
            'signal': signal,
        }


    def _precompute_signals_multiprocess(
        self,
        strategy: BaseStrategy,
        stock_data: Dict[str, pd.DataFrame],
    ) -> List[Tuple[bool, str, Optional[str]]]:
        """
        [æ€§èƒ½ä¼˜åŒ–] ä½¿ç”¨å¤šè¿›ç¨‹è¿›è¡Œä¿¡å·é¢„è®¡ç®—ï¼Œçªç ´ GIL é™åˆ¶ã€‚

        æ³¨æ„ï¼šå¤šè¿›ç¨‹éœ€è¦åºåˆ—åŒ–æ•°æ®ï¼Œå› æ­¤ï¼š
        1. å°† DataFrame è½¬æ¢ä¸ºå¯åºåˆ—åŒ–æ ¼å¼
        2. åœ¨å­è¿›ç¨‹ä¸­é‡å»ºç­–ç•¥å¯¹è±¡
        3. è®¡ç®—å®Œæˆåå°†ç»“æœè¿”å›ä¸»è¿›ç¨‹
        """
        from concurrent.futures import ProcessPoolExecutor
        import pickle

        results = []

        # å‡†å¤‡å¯åºåˆ—åŒ–çš„ä»»åŠ¡æ•°æ®
        tasks = []
        for stock_code, data in stock_data.items():
            try:
                # åºåˆ—åŒ–ç­–ç•¥é…ç½®ï¼ˆè€Œéç­–ç•¥å¯¹è±¡æœ¬èº«ï¼‰
                strategy_info = {
                    'name': strategy.name,
                    'class_name': strategy.__class__.__name__,
                    'config': getattr(strategy, 'config', {}),
                }
                # å°† DataFrame è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ï¼ˆå¯åºåˆ—åŒ–ï¼‰
                data_dict = {
                    'values': data.to_dict('list'),
                    'index': list(data.index),
                    'columns': list(data.columns),
                    'stock_code': data.attrs.get('stock_code', stock_code),
                }
                tasks.append((stock_code, data_dict, strategy_info))
            except Exception as e:
                logger.warning(f"å‡†å¤‡è‚¡ç¥¨ {stock_code} æ•°æ®å¤±è´¥: {e}")
                results.append((False, stock_code, str(e)))

        if not tasks:
            return results

        # ä½¿ç”¨è¿›ç¨‹æ± å¹¶è¡Œè®¡ç®—
        try:
            with ProcessPoolExecutor(max_workers=self.max_workers) as executor:
                futures = {
                    executor.submit(
                        _multiprocess_precompute_worker, task
                    ): task[0] for task in tasks
                }

                for future in as_completed(futures):
                    stock_code = futures[future]
                    try:
                        ok, code, signals_dict, err = future.result(timeout=60)
                        if ok and signals_dict is not None:
                            # å°†ç»“æœå†™å›åŸå§‹ DataFrame çš„ attrs
                            original_data = stock_data[code]
                            # é‡å»º Series
                            signals = pd.Series(
                                signals_dict['values'],
                                index=pd.to_datetime(signals_dict['index']),
                                dtype=object
                            )
                            cache = original_data.attrs.setdefault("_precomputed_signals", {})
                            cache[strategy.name] = signals  # ä½¿ç”¨ strategy.name ä½œä¸ºç¨³å®šçš„ key
                            results.append((True, code, None))
                        else:
                            results.append((False, code, err))
                    except Exception as e:
                        results.append((False, stock_code, str(e)))
        except Exception as e:
            logger.error(f"å¤šè¿›ç¨‹é¢„è®¡ç®—æ‰§è¡Œå¤±è´¥: {e}")
            # è¿”å›æ‰€æœ‰ä»»åŠ¡å¤±è´¥
            for stock_code, _, _ in tasks:
                if not any(r[1] == stock_code for r in results):
                    results.append((False, stock_code, str(e)))

        return results

    async def _execute_backtest_loop(
        self,
        strategy: BaseStrategy,
        portfolio_manager: PortfolioManager,
        stock_data: Dict[str, pd.DataFrame],
        trading_dates: List[datetime],
        strategy_config: Optional[Dict[str, Any]] = None,
        task_id: str = None,
        backtest_id: str = None,
        precomputed_signals: Optional[Dict[Tuple[str, datetime], Any]] = None,
        aligned_arrays: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå›æµ‹ä¸»å¾ªç¯"""
        total_signals = 0
        executed_trades = 0

        # æ€§èƒ½ç»Ÿè®¡ï¼šä¿¡å·ç”Ÿæˆæ—¶é—´
        signal_generation_times = []
        trade_execution_times = []

        # è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        def _is_task_running(status) -> bool:
            if status is None:
                return False
            # æ”¯æŒå­—ç¬¦ä¸²æˆ–Enum
            try:
                return (
                    status == TaskStatus.RUNNING or status == TaskStatus.RUNNING.value
                )
            except Exception:
                return status == TaskStatus.RUNNING.value

        def check_task_status():
            """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦ä»ç„¶å­˜åœ¨ä¸”å¤„äºè¿è¡ŒçŠ¶æ€"""
            if not task_id:
                return True
            try:
                from app.core.database import SessionLocal
                from app.models.task_models import TaskStatus
                from app.repositories.task_repository import TaskRepository

                session = SessionLocal()
                try:
                    task_repo = TaskRepository(session)
                    task = task_repo.get_task_by_id(task_id)
                    if not task:
                        logger.warning(f"ä»»åŠ¡ä¸å­˜åœ¨ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ: {task_id}")
                        return False
                    if not _is_task_running(task.status):
                        logger.warning(f"ä»»åŠ¡çŠ¶æ€ä¸º {task.status}ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ: {task_id}")
                        return False
                    return True
                finally:
                    session.close()
            except Exception as e:
                logger.warning(f"æ£€æŸ¥ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}ï¼Œç»§ç»­æ‰§è¡Œ")
                return True  # æ£€æŸ¥å¤±è´¥æ—¶ç»§ç»­æ‰§è¡Œï¼Œé¿å…å› æ£€æŸ¥é”™è¯¯è€Œä¸­æ–­

        # ========== PERFä¼˜åŒ–ï¼šæ‰¹é‡æ”¶é›†æ•°æ®åº“æ“ä½œï¼Œå¾ªç¯ç»“æŸåä¸€æ¬¡æ€§å†™å…¥ ==========
        # é¿å…åœ¨730å¤©å¾ªç¯å†…æ¯å¤©éƒ½åšæ•°æ®åº“æ“ä½œï¼ˆåŸæ¥æ˜¯72ç§’çš„ä¸»è¦ç“¶é¢ˆï¼‰
        _batch_signals_data: List[dict] = []  # æ”¶é›†æ‰€æœ‰ä¿¡å·è®°å½•
        _batch_executed_signals: List[dict] = []  # æ”¶é›†å·²æ‰§è¡Œçš„ä¿¡å·
        _batch_unexecuted_signals: List[dict] = []  # æ”¶é›†æœªæ‰§è¡Œçš„ä¿¡å·
        _current_backtest_id: str | None = None  # ç¼“å­˜ backtest_id
        # ========== END PERFä¼˜åŒ– ==========

        for i, current_date in enumerate(trading_dates):
            # PERF/BUGFIX: ç»Ÿä¸€åˆå§‹åŒ–è®¡æ—¶å˜é‡ï¼Œé¿å…æŸäº›åˆ†æ”¯/å¼‚å¸¸è·¯å¾„å¼•ç”¨æœªèµ‹å€¼å¯¼è‡´ UnboundLocalError
            slice_time_total = 0.0
            gen_time_total = 0.0
            gen_time_max = 0.0

            # åœ¨å¾ªç¯å¼€å§‹æ—¶æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ï¼ˆæ¯50ä¸ªäº¤æ˜“æ—¥æ£€æŸ¥ä¸€æ¬¡ï¼Œé¿å…é¢‘ç¹æ£€æŸ¥ï¼‰
            if task_id and i % 50 == 0 and i > 0:
                if not check_task_status():
                    logger.info(f"ä»»åŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ: {task_id}")
                    raise TaskError(
                        message=f"ä»»åŠ¡ {task_id} å·²è¢«åˆ é™¤æˆ–çŠ¶æ€å·²æ”¹å˜ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ",
                        severity=ErrorSeverity.LOW,
                    )
            try:
                # è·å–å½“å‰ä»·æ ¼ï¼ˆPhase3ï¼šä½¿ç”¨å‘é‡åŒ–ä¼˜åŒ–ï¼‰
                current_prices: Dict[str, float] = {}

                if aligned_arrays is not None:
                    # Phase 3 ä¼˜åŒ–ï¼šä½¿ç”¨å‘é‡åŒ–ä»·æ ¼æŸ¥æ‰¾
                    from .vectorized_loop import vectorized_price_lookup, get_portfolio_stocks
                    
                    codes = aligned_arrays.get("stock_codes")
                    code_to_i = aligned_arrays.get("code_to_i")
                    close_mat = aligned_arrays.get("close")
                    valid_mat = aligned_arrays.get("valid")
                    sig_mat = aligned_arrays.get("signal")

                    # æ”¶é›†éœ€è¦ä»·æ ¼çš„è‚¡ç¥¨ï¼ˆæŒä»“ + æœ‰ä¿¡å·çš„è‚¡ç¥¨ï¼‰
                    need_codes = set(get_portfolio_stocks(portfolio_manager))
                    
                    if isinstance(sig_mat, np.ndarray):
                        sig_idx = np.nonzero(sig_mat[:, i])[0]
                        for j in sig_idx.tolist():
                            need_codes.add(codes[j])

                    if need_codes:
                        # æ‰¹é‡æŸ¥æ‰¾ä»·æ ¼ï¼ˆå‘é‡åŒ–ï¼‰
                        for c in need_codes:
                            j = code_to_i.get(c) if isinstance(code_to_i, dict) else None
                            if j is not None and bool(valid_mat[j, i]):
                                current_prices[c] = float(close_mat[j, i])

                else:
                    # [ä¼˜åŒ– 1] é¿å… DataFrame æ‹·è´ï¼šä½¿ç”¨ .values å’Œç¼“å­˜çš„ç´¢å¼•
                    for stock_code, data in stock_data.items():
                        try:
                            # ä¼˜å…ˆä½¿ç”¨ç¼“å­˜çš„ date_to_idx æ˜ å°„
                            date_to_idx = data.attrs.get("_date_to_idx")
                            if date_to_idx is not None and current_date in date_to_idx:
                                idx = date_to_idx[current_date]
                                # ä½¿ç”¨ .values ç›´æ¥è®¿é—®åº•å±‚æ•°ç»„
                                current_prices[stock_code] = float(data['close'].values[idx])
                            elif current_date in data.index:
                                # Fallback: ä½¿ç”¨ ilocï¼ˆæ¯” loc å¿«ï¼‰
                                idx = data.index.get_loc(current_date)
                                current_prices[stock_code] = float(data['close'].values[idx])
                        except Exception:
                            pass

                if not current_prices:
                    continue

                # ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼ˆPhase1ï¼šä¼˜å…ˆç”¨ ndarray signal matrixï¼‰
                all_signals: List[TradingSignal] = []

                if aligned_arrays is not None:
                    sig_mat = aligned_arrays.get("signal")
                    codes = aligned_arrays.get("stock_codes")
                    close_mat = aligned_arrays.get("close")
                    valid_mat = aligned_arrays.get("valid")
                    if isinstance(sig_mat, np.ndarray):
                        sig_idx = np.nonzero(sig_mat[:, i])[0]
                        if sig_idx.size > 0:
                            for j in sig_idx.tolist():
                                if not bool(valid_mat[j, i]):
                                    continue
                                st = int(sig_mat[j, i])
                                if st == 1:
                                    stype = SignalType.BUY
                                elif st == -1:
                                    stype = SignalType.SELL
                                else:
                                    continue
                                code = codes[j]
                                price = float(close_mat[j, i])
                                all_signals.append(
                                    TradingSignal(
                                        timestamp=current_date,
                                        stock_code=code,
                                        signal_type=stype,
                                        strength=1.0,
                                        price=price,
                                        reason="[aligned] precomputed",
                                        metadata=None,
                                    )
                                )

                # è‹¥å¯¹é½æ•°ç»„æœªç”Ÿæˆä¿¡å·ï¼Œå†èµ°åŸæœ‰è·¯å¾„ï¼ˆå…¼å®¹å…¶å®ƒç­–ç•¥ï¼‰
                if not all_signals:
                    # ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼ˆæ”¯æŒå¹¶è¡Œç”Ÿæˆå¤šè‚¡ç¥¨ä¿¡å·ï¼‰
                    all_signals = []

                # æ€§èƒ½ç›‘æ§ï¼šè®°å½•ä¿¡å·ç”Ÿæˆæ—¶é—´
                signal_start_time = (
                    time.perf_counter() if self.enable_performance_profiling else None
                )

                # ï¿½ï¿½åˆ† profilingï¼šæŠŠ"åˆ‡ç‰‡"å’Œ"ç”Ÿæˆä¿¡å·"æ‹†å¼€è®¡æ—¶ï¼ˆå˜é‡å·²åœ¨å¾ªç¯å¼€å¤´åˆå§‹åŒ–ï¼‰

                
                # è¾…åŠ©å‡½æ•°ï¼šå¿«é€ŸæŸ¥æ‰¾é¢„è®¡ç®—ä¿¡å·
                def get_precomputed_signal_fast(stock_code: str, date: datetime):
                    """
                    [ä¼˜åŒ– 1] ä»é¢„è®¡ç®—å­—å…¸ä¸­å¿«é€ŸæŸ¥æ‰¾ä¿¡å·ï¼Œé¿å… DataFrame æ‹·è´
                    
                    ä¼˜åŒ–ç‚¹ï¼š
                    1. ä¼˜å…ˆä½¿ç”¨ aligned_arrays çš„ numpy æ•°ç»„ï¼ˆO(1) æŸ¥æ‰¾ï¼‰
                    2. ä½¿ç”¨ .values ç›´æ¥è®¿é—®åº•å±‚æ•°ç»„ï¼Œé¿å…åˆ›å»º Series å¯¹è±¡
                    3. ç¼“å­˜ date_to_idx æ˜ å°„ï¼Œé¿å…é‡å¤ get_loc() è°ƒç”¨
                    """
                    if precomputed_signals:
                        signal = precomputed_signals.get((stock_code, date))
                        if signal is not None:
                            # å°†ä¿¡å·ç±»å‹è½¬æ¢ä¸º TradingSignal å¯¹è±¡
                            from ..models import TradingSignal, SignalType
                            if isinstance(signal, SignalType):
                                # [ä¼˜åŒ– 1] è·å–å½“å‰ä»·æ ¼ - é¿å… DataFrame æ‹·è´
                                current_price = 0.0
                                
                                try:
                                    # æ–¹æ³• 1: ä¼˜å…ˆä½¿ç”¨ aligned_arraysï¼ˆæœ€å¿«ï¼ŒO(1) æŸ¥æ‰¾ï¼‰
                                    if aligned_arrays is not None:
                                        code_to_i = aligned_arrays.get("code_to_i")
                                        close_mat = aligned_arrays.get("close")
                                        dates = aligned_arrays.get("dates")
                                        
                                        if code_to_i is not None and close_mat is not None and dates is not None:
                                            stock_idx = code_to_i.get(stock_code)
                                            if stock_idx is not None:
                                                # æ‰¾åˆ°æ—¥æœŸç´¢å¼•
                                                date_idx = None
                                                date_np = np.datetime64(date)
                                                # ä½¿ç”¨ numpy çš„å‘é‡åŒ–æŸ¥æ‰¾
                                                matches = np.where(dates == date_np)[0]
                                                if len(matches) > 0:
                                                    date_idx = int(matches[0])
                                                    # ç›´æ¥ä» numpy æ•°ç»„è¯»å–ï¼Œæ—  pandas å¼€é”€
                                                    price_val = close_mat[stock_idx, date_idx]
                                                    if not np.isnan(price_val):
                                                        current_price = float(price_val)
                                    
                                    # æ–¹æ³• 2: å¦‚æœ aligned_arrays ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼˜åŒ–çš„ DataFrame è®¿é—®
                                    if current_price == 0.0:
                                        data = stock_data.get(stock_code)
                                        if data is not None:
                                            # ä½¿ç”¨ç¼“å­˜çš„ date_to_idx æ˜ å°„ï¼ˆé¿å…é‡å¤ get_locï¼‰
                                            date_to_idx = data.attrs.get("_date_to_idx")
                                            if date_to_idx is not None and date in date_to_idx:
                                                idx = date_to_idx[date]
                                                # ä½¿ç”¨ .values ç›´æ¥è®¿é—®åº•å±‚æ•°ç»„ï¼Œé¿å…åˆ›å»º Series
                                                close_values = data['close'].values
                                                current_price = float(close_values[idx])
                                            elif date in data.index:
                                                # Fallback: ä½¿ç”¨ ilocï¼ˆæ¯” loc å¿«ï¼Œä½†ä»ä¼šè§¦å‘ä¸€äº›å¼€é”€ï¼‰
                                                idx = data.index.get_loc(date)
                                                current_price = float(data['close'].values[idx])
                                
                                except Exception as e:
                                    # é™é»˜å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä»·æ ¼ 0.0
                                    pass
                                
                                return [TradingSignal(
                                    signal_type=signal,
                                    stock_code=stock_code,
                                    timestamp=date,
                                    price=current_price,
                                    strength=1.0,
                                    reason=f"Precomputed signal"
                                )]
                            return [signal] if not isinstance(signal, list) else signal
                    return None

                # PERF OPTIMIZATION: ç¦ç”¨per-dayå¹¶è¡Œï¼Œå› ä¸ºä¿¡å·å·²ç»é¢„è®¡ç®—ï¼Œä¸²è¡Œæ›´å¿«
                if False and self.enable_parallel and len(stock_data) > 3:
                    # å¹¶è¡Œç”Ÿæˆå¤šè‚¡ç¥¨ä¿¡å·
                    # PERF: avoid per-day ThreadPoolExecutor creation and avoid per-stock futures.
                    # We batch stocks into coarse tasks to reduce scheduling overhead.

                    # PERF: switch from "per-day submit many tasks" to "persistent workers".
                    # This dramatically reduces thread scheduling overhead when stock_count is large.
                    import threading

                    # Initialize worker context once (first trading day)
                    if not hasattr(self, "_signal_worker_ctx") or self._signal_worker_ctx is None:
                        items = list(stock_data.items())

                        # Greedy balance chunks by estimated per-stock compute cost.
                        # Cost proxy: number of trading days the stock participates (after warmup) with
                        # a small penalty for missing days.
                        scored = []
                        total_days = len(trading_dates) if trading_dates else 0

                        for code, df in items:
                            try:
                                # count how many trading_dates exist in this df
                                # (O(T) per stock; ok for init and much better load balance than len(df))
                                avail = df.index
                                avail_days = 0
                                for _d in trading_dates:
                                    if _d in avail:
                                        avail_days += 1
                                missing_ratio = (
                                    1.0 - (avail_days / total_days)
                                    if total_days > 0
                                    else 0.0
                                )
                                # warmup skip (executor only calls strategy when idx>=20)
                                effective_days = max(0, avail_days - 20)
                                cost = float(effective_days) * (1.0 + 0.10 * missing_ratio)
                                scored.append((cost, code, df))
                            except Exception:
                                scored.append((0.0, code, df))

                        scored.sort(reverse=True)

                        worker_n = max(1, int(self.max_workers or 1))
                        buckets = [([], 0.0) for _ in range(worker_n)]  # ([(code,df)], total_cost)
                        for cost, code, df in scored:
                            # pick bucket with smallest total_cost
                            bi = min(range(worker_n), key=lambda x: buckets[x][1])
                            buckets[bi][0].append((code, df))
                            buckets[bi] = (buckets[bi][0], buckets[bi][1] + float(cost))

                        chunks: List[List[Tuple[str, pd.DataFrame]]] = [b[0] for b in buckets]

                        shared = {"date": None, "error": None}
                        results: List[Tuple[List[TradingSignal], float, float, float]] = [
                            ([], 0.0, 0.0, 0.0) for _ in range(worker_n)
                        ]

                        barrier_start = threading.Barrier(worker_n + 1)
                        barrier_end = threading.Barrier(worker_n + 1)

                        def _worker(idx: int):
                            nonlocal chunks, shared, results
                            while True:
                                try:
                                    barrier_start.wait()
                                except Exception:
                                    return

                                cd = shared.get("date")
                                if cd is None:
                                    # shutdown signal
                                    try:
                                        barrier_end.wait()
                                    except Exception:
                                        pass
                                    return

                                batch_signals: List[TradingSignal] = []
                                slice_sum = 0.0
                                gen_sum = 0.0
                                gen_max = 0.0

                                try:
                                    for stock_code, data in chunks[idx]:
                                        if cd not in data.index:
                                            continue

                                        t0 = time.perf_counter()
                                        idx_map = None
                                        try:
                                            idx_map = data.attrs.get("_date_to_idx")
                                        except Exception:
                                            idx_map = None
                                        current_idx = (
                                            int(idx_map.get(cd))
                                            if isinstance(idx_map, dict) and cd in idx_map
                                            else int(data.index.get_loc(cd))
                                        )
                                        try:
                                            data.attrs["_current_date"] = cd
                                            data.attrs["_current_idx"] = current_idx
                                        except Exception:
                                            pass
                                        slice_dur = time.perf_counter() - t0
                                        slice_sum += float(slice_dur)

                                        if current_idx < 20:
                                            continue

                                        t1 = time.perf_counter()
                                        # ä¼˜å…ˆä½¿ç”¨é¢„è®¡ç®—ä¿¡å·
                                        sigs = get_precomputed_signal_fast(stock_code, cd)
                                        if sigs is None:
                                            # Fallback: è°ƒç”¨ç­–ç•¥ç”Ÿæˆ
                                            sigs = strategy.generate_signals(data, cd)
                                        gen_dur = time.perf_counter() - t1
                                        gen_sum += float(gen_dur)
                                        if gen_dur > gen_max:
                                            gen_max = float(gen_dur)

                                        if sigs:
                                            try:
                                                md = getattr(sigs[0], "metadata", None)
                                                if md is None:
                                                    sigs[0].metadata = {}
                                                    md = sigs[0].metadata
                                                if isinstance(md, dict):
                                                    md["_perf"] = {
                                                        "gen_wall": float(gen_dur),
                                                        "slice_wall": float(slice_dur),
                                                    }
                                            except Exception:
                                                pass

                                        batch_signals.extend(sigs)

                                    results[idx] = (batch_signals, slice_sum, gen_sum, gen_max)
                                except Exception as e:
                                    shared["error"] = e
                                    results[idx] = ([], slice_sum, gen_sum, gen_max)

                                try:
                                    barrier_end.wait()
                                except Exception:
                                    return

                        threads = []
                        for wi in range(worker_n):
                            t = threading.Thread(target=_worker, args=(wi,), daemon=True)
                            t.start()
                            threads.append(t)

                        self._signal_worker_ctx = {
                            "worker_n": worker_n,
                            "shared": shared,
                            "results": results,
                            "barrier_start": barrier_start,
                            "barrier_end": barrier_end,
                            "threads": threads,
                        }

                    ctx = self._signal_worker_ctx

                    sequential_start = (
                        time.perf_counter() if self.enable_performance_profiling else None
                    )

                    gen_time_max = 0.0

                    # Broadcast date to workers and collect
                    ctx["shared"]["date"] = current_date
                    ctx["shared"]["error"] = None

                    try:
                        ctx["barrier_start"].wait()
                        ctx["barrier_end"].wait()
                    except Exception as e:
                        logger.error(f"å¹¶è¡Œç”Ÿæˆä¿¡å·åŒæ­¥å¤±è´¥: {e}")

                    err = ctx["shared"].get("error")
                    if err is not None:
                        raise err

                    for (signals, slice_sum, gen_sum, gen_max) in ctx["results"]:
                        all_signals.extend(signals)
                        slice_time_total += float(slice_sum)
                        gen_time_total += float(gen_sum)
                        if gen_max and gen_max > gen_time_max:
                            gen_time_max = float(gen_max)

                    # è®°å½•å¹¶è¡ŒåŒ–æ•ˆç‡ï¼ˆä¼°ç®—é¡ºåºæ‰§è¡Œæ—¶é—´ï¼‰
                    if self.enable_performance_profiling and sequential_start:
                        parallel_time = time.perf_counter() - sequential_start
                        estimated_sequential_time = parallel_time * len(stock_data) / max(1, self.max_workers)
                        if i == 0:
                            self.performance_profiler.record_parallel_efficiency(
                                operation_name="signal_generation",
                                sequential_time=estimated_sequential_time,
                                parallel_time=parallel_time,
                                worker_count=self.max_workers,
                            )
                else:
                    gen_time_max = 0.0
                    # é¡ºåºç”Ÿæˆä¿¡å·ï¼ˆè‚¡ç¥¨æ•°é‡å°‘æˆ–ç¦ç”¨å¹¶è¡Œï¼‰
                    for stock_code, data in stock_data.items():
                        if current_date in data.index:
                            # è·å–åˆ°å½“å‰æ—¥æœŸçš„å†å²æ•°æ®
                            t0 = time.perf_counter()
                            # same rationale as parallel path: avoid daily slicing copies
                            idx_map = None
                            try:
                                idx_map = data.attrs.get("_date_to_idx")
                            except Exception:
                                idx_map = None
                            current_idx = (
                                int(idx_map.get(current_date))
                                if isinstance(idx_map, dict) and current_date in idx_map
                                else int(data.index.get_loc(current_date))
                                if current_date in data.index
                                else -1
                            )
                            # Provide fast-path hint for strategies (avoid repeated get_loc)
                            try:
                                data.attrs["_current_date"] = current_date
                                data.attrs["_current_idx"] = current_idx
                            except Exception:
                                pass
                            slice_time_total += time.perf_counter() - t0

                            if current_idx >= 20:
                                try:
                                    t1 = time.perf_counter()
                                    # ä¼˜å…ˆä½¿ç”¨é¢„è®¡ç®—ä¿¡å·
                                    signals = get_precomputed_signal_fast(stock_code, current_date)
                                    
                                    # è°ƒè¯•æ—¥å¿—
                                    if current_idx == 20:  # åªåœ¨ç¬¬ä¸€æ¬¡æ‰“å°
                                        logger.info(f"ğŸ” è°ƒè¯•: stock={stock_code}, date={current_date}, precomputed_signals={'æœ‰' if signals else 'æ— '}")
                                    
                                    if signals is None:
                                        # Fallback: è°ƒç”¨ç­–ç•¥ç”Ÿæˆ
                                        signals = strategy.generate_signals(data, current_date)
                                    
                                    # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•ä¿¡å·å†…å®¹
                                    if signals and current_idx == 20:
                                        logger.info(f"ğŸ” ä¿¡å·å†…å®¹: {signals}")
                                    
                                    _dur = time.perf_counter() - t1
                                    gen_time_total += _dur
                                    if _dur > gen_time_max:
                                        gen_time_max = float(_dur)
                                    all_signals.extend(signals)
                                except Exception as e:
                                    logger.warning(f"ç”Ÿæˆä¿¡å·å¤±è´¥ {stock_code}: {e}")
                                    continue

                # è®°å½•ä¿¡å·ç”Ÿæˆæ—¶é—´
                if self.enable_performance_profiling and signal_start_time and self.performance_profiler:
                    signal_duration = time.perf_counter() - signal_start_time
                    signal_generation_times.append(signal_duration)

                    # åŸæœ‰å£å¾„ï¼šæ•´æ®µä¿¡å·ç”Ÿæˆï¼ˆå«åˆ‡ç‰‡ã€è®¡ç®—æŒ‡æ ‡ã€èåˆç­‰ï¼‰
                    self.performance_profiler.record_function_call(
                        "generate_signals", signal_duration
                    )

                    # æ–°å£å¾„ï¼šæ‹†å¼€çœ‹"åˆ‡ç‰‡"ä¸"ç­–ç•¥ä¿¡å·ç”Ÿæˆ"çš„æ¯”ä¾‹
                    # æ³¨æ„ï¼šå¹¶è¡Œæ¨¡å¼ä¸‹ slice_time_total / gen_time_total æ˜¯"å„çº¿ç¨‹è€—æ—¶æ±‚å’Œ"(work)ï¼Œ
                    # ä¸æ˜¯ wall-clockï¼›ç”¨äºåˆ¤æ–­ CPU work æ„æˆï¼Œä½†ä¸èƒ½ç›´æ¥å½“æˆæ•´ä½“è€—æ—¶ç™¾åˆ†æ¯”ã€‚
                    if slice_time_total > 0:
                        self.performance_profiler.record_function_call(
                            "slice_historical_data_work", float(slice_time_total)
                        )
                    if gen_time_total > 0:
                        self.performance_profiler.record_function_call(
                            "generate_signals_core_work", float(gen_time_total)
                        )

                    # é¢å¤–è®°å½• wall-clock å£å¾„ï¼ˆåŒ generate_signalsï¼Œä½†åå­—æ›´æ˜ç¡®ï¼Œä¾¿äºæŠ¥è¡¨é˜…è¯»ï¼‰
                    self.performance_profiler.record_function_call(
                        "generate_signals_wall", signal_duration
                    )

                    # å¹¶è¡Œè·¯å¾„ä¸‹ critical path è¿‘ä¼¼ï¼šå•æ—¥æœ€æ…¢è‚¡ç¥¨çš„ generate_signals wall
                    if gen_time_max > 0:
                        self.performance_profiler.record_function_call(
                            "generate_signals_core_wall_max", float(gen_time_max)
                        )

                        # çº¿ç¨‹/è°ƒåº¦å¼€é”€ï¼ˆç²—ç•¥ï¼‰ï¼šæ•´æ®µ wall - å•æ—¥æœ€æ…¢å•è‚¡ wall
                        overhead = float(signal_duration) - float(gen_time_max)
                        if overhead > 0:
                            self.performance_profiler.record_function_call(
                                "signal_generation_overhead_wall", overhead
                            )

                    # If StrategyPortfolio attached per-strategy timings, record them once per day.
                    try:
                        perf_sig = None
                        for _s in all_signals:
                            md = getattr(_s, "metadata", None) or {}
                            if isinstance(md, dict) and "portfolio_perf" in md:
                                perf_sig = _s
                                break
                        if perf_sig is not None:
                            md = perf_sig.metadata or {}
                            pp = md.get("portfolio_perf") if isinstance(md, dict) else None
                            if isinstance(pp, dict):
                                sub = pp.get("sub_strategy_times")
                                if isinstance(sub, dict):
                                    for k, v in sub.items():
                                        self.performance_profiler.record_function_call(
                                            f"portfolio_substrategy__{k}", float(v)
                                        )
                                it = pp.get("integrate_time")
                                if it is not None:
                                    self.performance_profiler.record_function_call(
                                        "portfolio_integrate", float(it)
                                    )
                    except Exception:
                        pass

                total_signals += len(all_signals)

                # PERFä¼˜åŒ–ï¼šæ”¶é›†ä¿¡å·è®°å½•åˆ°å†…å­˜ï¼Œå¾ªç¯ç»“æŸåæ‰¹é‡å†™å…¥æ•°æ®åº“
                if task_id and all_signals:
                    try:
                        import uuid

                        # ä½¿ç”¨ä¼ å…¥çš„backtest_idæˆ–ç”Ÿæˆä¸€ä¸ªï¼ˆåªç”Ÿæˆä¸€æ¬¡ï¼‰
                        if _current_backtest_id is None:
                            _current_backtest_id = backtest_id or (
                                f"bt_{task_id[:8]}"
                                if task_id
                                else f"bt_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                            )

                        # æ”¶é›†ä¿¡å·è®°å½•åˆ°å†…å­˜åˆ—è¡¨ï¼ˆä¸å†æ¯å¤©å†™æ•°æ®åº“ï¼‰
                        for signal in all_signals:
                            signal_data = {
                                "signal_id": f"sig_{uuid.uuid4().hex[:12]}",
                                "stock_code": signal.stock_code,
                                "stock_name": None,
                                "signal_type": signal.signal_type.name,
                                "timestamp": signal.timestamp,
                                "price": signal.price,
                                "strength": signal.strength,
                                "reason": signal.reason,
                                "metadata": signal.metadata,
                                "executed": False,
                            }
                            _batch_signals_data.append(signal_data)
                    except Exception as e:
                        logger.warning(f"ä¿å­˜ä¿¡å·è®°å½•æ—¶å‡ºé”™: {e}")

                # æ‰§è¡Œäº¤æ˜“ä¿¡å·ï¼ˆæ€§èƒ½ç›‘æ§ï¼‰
                trade_start_time = (
                    time.perf_counter() if self.enable_performance_profiling else None
                )
                trades_this_day = 0
                executed_trade_signals = []  # è®°å½•å·²æ‰§è¡Œçš„äº¤æ˜“å¯¹åº”çš„ä¿¡å·
                unexecuted_signals = []  # è®°å½•æœªæ‰§è¡Œçš„ä¿¡å·åŠåŸå› 

                # ===== trade execution mode =====
                trade_mode = None
                topk_limit: int | None = None  # for post-trade sanity checks
                try:
                    trade_mode = (strategy_config or {}).get("trade_mode")
                except Exception:
                    trade_mode = None

                # --- debug aid: log which trade path is used (only when needed) ---
                try:
                    if current_date.strftime("%Y-%m-%d") in ("2023-05-19", "2023-05-22", "2023-05-23"):
                        logger.info(
                            f"[trade_path] date={current_date.strftime('%Y-%m-%d')} trade_mode={trade_mode} "
                            f"signals={len(all_signals)} strategy_config_keys={list((strategy_config or {}).keys())}"
                        )
                except Exception:
                    pass

                if trade_mode == "topk_buffer":
                    # Daily TopK selection + buffer zone + max changes/day
                    k = int((strategy_config or {}).get("topk", 10))
                    topk_limit = k
                    buffer_n = int((strategy_config or {}).get("buffer", 20))
                    max_changes = int((strategy_config or {}).get("max_changes_per_day", 2))
                    trades_limit = max_changes

                    # Build ranking scores from signals (BUY strength positive, SELL negative)
                    scores: Dict[str, float] = {code: 0.0 for code in stock_data.keys()}
                    for sig in all_signals:
                        s = float(sig.strength or 0.0)
                        if sig.signal_type == SignalType.BUY:
                            scores[sig.stock_code] = max(scores.get(sig.stock_code, 0.0), s)
                        elif sig.signal_type == SignalType.SELL:
                            scores[sig.stock_code] = min(scores.get(sig.stock_code, 0.0), -s)

                    # Rebalance according to TopK+buffer rules
                    executed_trade_signals, unexecuted_signals, trades_this_day = self._rebalance_topk_buffer(
                        portfolio_manager=portfolio_manager,
                        current_prices=current_prices,
                        current_date=current_date,
                        scores=scores,
                        topk=k,
                        buffer_n=buffer_n,
                        max_changes=trades_limit,
                        strategy=strategy,
                        debug=bool((strategy_config or {}).get("debug_topk_buffer", False)),
                    )

                    # Debug: show what was executed on key dates / when trades happen
                    try:
                        if trades_this_day > 0 or current_date.strftime("%Y-%m-%d") in ("2023-05-22",):
                            logger.info(
                                f"[trade_exec][topk_buffer] date={current_date.strftime('%Y-%m-%d')} trades_this_day={trades_this_day} "
                                f"executed={len(executed_trade_signals)} unexecuted={len(unexecuted_signals)} holdings_after={len(portfolio_manager.positions)}"
                            )
                    except Exception:
                        pass

                else:
                    for signal in all_signals:
                        # éªŒè¯ä¿¡å·
                        is_valid, validation_reason = strategy.validate_signal(
                            signal,
                            portfolio_manager.get_portfolio_value(current_prices),
                            portfolio_manager.positions,
                        )

                        if not is_valid:
                            # éªŒè¯å¤±è´¥ï¼Œè®°å½•æœªæ‰§è¡ŒåŸå› 
                            unexecuted_signals.append(
                                {
                                    "stock_code": signal.stock_code,
                                    "timestamp": signal.timestamp,
                                    "signal_type": signal.signal_type.name,
                                    "execution_reason": validation_reason or "ä¿¡å·éªŒè¯å¤±è´¥",
                                }
                            )
                            continue

                        # éªŒè¯é€šè¿‡ï¼Œå°è¯•æ‰§è¡Œ
                        trade_exec_start = (
                            time.perf_counter()
                            if self.enable_performance_profiling
                            else None
                        )
                        trade, failure_reason = portfolio_manager.execute_signal(
                            signal, current_prices
                        )
                        if self.enable_performance_profiling and trade_exec_start:
                            trade_exec_duration = time.perf_counter() - trade_exec_start
                            trade_execution_times.append(trade_exec_duration)
                            self.performance_profiler.record_function_call(
                                "execute_signal", trade_exec_duration
                            )

                        if trade:
                            executed_trades += 1
                            trades_this_day += 1
                            # è®°å½•å·²æ‰§è¡Œçš„ä¿¡å·ï¼Œç”¨äºåç»­æ ‡è®°
                            executed_trade_signals.append(
                                {
                                    "stock_code": signal.stock_code,
                                    "timestamp": signal.timestamp,
                                    "signal_type": signal.signal_type.name,
                                }
                            )
                        else:
                            # æ‰§è¡Œå¤±è´¥ï¼Œè®°å½•æœªæ‰§è¡ŒåŸå› ï¼ˆä» execute_signal ç›´æ¥è·å–ï¼‰
                            unexecuted_signals.append(
                                {
                                    "stock_code": signal.stock_code,
                                    "timestamp": signal.timestamp,
                                    "signal_type": signal.signal_type.name,
                                    "execution_reason": failure_reason or "æ‰§è¡Œå¤±è´¥ï¼ˆæœªçŸ¥åŸå› ï¼‰",
                                }
                            )

                # è®°å½•äº¤æ˜“æ‰§è¡Œæ€»æ—¶é—´
                if self.enable_performance_profiling and trade_start_time:
                    trade_duration = time.perf_counter() - trade_start_time
                    self.performance_profiler.record_function_call(
                        "execute_trades_batch", trade_duration
                    )

                # PERFä¼˜åŒ–ï¼šæ”¶é›†æœªæ‰§è¡Œå’Œå·²æ‰§è¡Œä¿¡å·åˆ°å†…å­˜ï¼Œå¾ªç¯ç»“æŸåæ‰¹é‡å†™å…¥
                if task_id and unexecuted_signals:
                    _batch_unexecuted_signals.extend(unexecuted_signals)

                if task_id and executed_trade_signals:
                    _batch_executed_signals.extend(executed_trade_signals)

                # è®°å½•ç»„åˆå¿«ç…§
                portfolio_manager.record_portfolio_snapshot(
                    current_date, current_prices
                )

                # --- Sanity check (debug): topk_buffer must never exceed topk holdings ---
                # è¿™æ¡åªåšå‘Šè­¦ï¼Œä¸æ”¹å˜äº¤æ˜“è¡Œä¸ºï¼Œç”¨äºå®šä½"æŒä»“æ•°ä¸ºä½•ä¼š>topk"ã€‚
                try:
                    tm = None
                    k_limit = None
                    try:
                        tm = (strategy_config or {}).get("trade_mode")
                        k_limit = int((strategy_config or {}).get("topk", 10))
                    except Exception:
                        tm = None
                        k_limit = None

                    if tm == "topk_buffer" and k_limit is not None:
                        current_holdings = list(portfolio_manager.positions.keys())
                        if len(current_holdings) > int(k_limit):
                            logger.error(
                                f"[topk_buffer][sanity] positions_count={len(current_holdings)} > topk={k_limit} "
                                f"date={current_date.strftime('%Y-%m-%d')} holdings={sorted(current_holdings)}"
                            )
                except Exception as e:
                    logger.warning(f"[topk_buffer][sanity] check failed: {e}")

                # æ›´æ–°è¿›åº¦ç›‘æ§ï¼ˆåŒæ—¶æ›´æ–°æ•°æ®åº“ï¼‰
                if task_id and i % 5 == 0:  # æ¯5å¤©æ›´æ–°ä¸€æ¬¡è¿›åº¦
                    portfolio_value = portfolio_manager.get_portfolio_value(
                        current_prices
                    )
                    logger.debug(
                        f"å‡†å¤‡æ›´æ–°è¿›åº¦: task_id={task_id}, i={i}, total_days={len(trading_dates)}, signals={len(all_signals)}, trades={trades_this_day}, total_signals={total_signals}, total_trades={executed_trades}"
                    )

                    # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”ï¼ˆå›æµ‹æ‰§è¡Œé˜¶æ®µå 30-90%ï¼Œå³60%çš„è¿›åº¦èŒƒå›´ï¼‰
                    execution_progress = (i + 1) / len(trading_dates) * 100
                    overall_progress = 30 + (execution_progress / 100) * 60  # 30%åˆ°90%

                    # æ›´æ–°æ•°æ®åº“ä¸­çš„ä»»åŠ¡è¿›åº¦ï¼ˆåŒ…å«è¯¦ç»†æ•°æ®ï¼‰
                    try:
                        from datetime import datetime

                        from app.core.database import SessionLocal
                        from app.models.task_models import TaskStatus
                        from app.repositories.task_repository import TaskRepository

                        session = SessionLocal()
                        try:
                            task_repo = TaskRepository(session)

                            # è¯»å–ç°æœ‰çš„ result æ•°æ®
                            existing_task = task_repo.get_task_by_id(task_id)
                            if not existing_task:
                                logger.warning(f"ä»»åŠ¡ä¸å­˜åœ¨ï¼Œæ— æ³•æ›´æ–°è¿›åº¦: {task_id}")
                                # ä»»åŠ¡å·²è¢«åˆ é™¤ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ
                                raise TaskError(
                                    message=f"ä»»åŠ¡ {task_id} å·²è¢«åˆ é™¤ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ",
                                    severity=ErrorSeverity.LOW,
                                )
                            # æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ï¼Œå¦‚æœä¸æ˜¯è¿è¡Œä¸­ï¼Œåˆ™åœæ­¢æ‰§è¡Œ
                            elif not _is_task_running(existing_task.status):
                                logger.warning(
                                    f"ä»»åŠ¡çŠ¶æ€ä¸º {existing_task.status}ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ: {task_id}"
                                )
                                raise TaskError(
                                    message=f"ä»»åŠ¡ {task_id} çŠ¶æ€ä¸º {existing_task.status}ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ",
                                    severity=ErrorSeverity.LOW,
                                )
                            else:
                                result_data = existing_task.result or {}
                                if not isinstance(result_data, dict):
                                    result_data = {}
                                progress_data = result_data.get("progress_data", {})
                                if not isinstance(progress_data, dict):
                                    progress_data = {}

                                # æ›´æ–°è¿›åº¦æ•°æ®
                                progress_data.update(
                                    {
                                        "processed_days": i + 1,
                                        "total_days": len(trading_dates),
                                        "current_date": current_date.strftime(
                                            "%Y-%m-%d"
                                        ),
                                        "signals_generated": len(all_signals),
                                        "trades_executed": trades_this_day,
                                        "total_signals": total_signals,
                                        "total_trades": executed_trades,
                                        "portfolio_value": portfolio_value,
                                        "last_updated": datetime.utcnow().isoformat(),
                                    }
                                )

                                result_data["progress_data"] = progress_data

                                # è®°å½•æ—¥å¿—ä»¥ä¾¿è°ƒè¯•
                                logger.info(
                                    f"æ›´æ–°å›æµ‹è¿›åº¦æ•°æ®: task_id={task_id}, processed_days={i+1}, total_days={len(trading_dates)}, signals={total_signals}, trades={executed_trades}, portfolio={portfolio_value:.2f}, progress_data_keys={list(progress_data.keys())}"
                                )

                                task_repo.update_task_status(
                                    task_id=task_id,
                                    status=TaskStatus.RUNNING,
                                    progress=overall_progress,
                                    result=result_data,  # åŒ…å«è¯¦ç»†è¿›åº¦æ•°æ®
                                )

                                # ç¡®ä¿ result å­—æ®µè¢«æ ‡è®°ä¸ºå·²ä¿®æ”¹å¹¶æäº¤
                                session.commit()
                                logger.info(
                                    f"è¿›åº¦æ•°æ®å·²æäº¤åˆ°æ•°æ®åº“: task_id={task_id}, result_data_keys={list(result_data.keys())}, progress_data={progress_data}"
                                )
                        except Exception as inner_error:
                            session.rollback()
                            logger.error(
                                f"æ›´æ–°ä»»åŠ¡è¿›åº¦åˆ°æ•°æ®åº“å¤±è´¥ï¼ˆå†…éƒ¨é”™è¯¯ï¼‰: {inner_error}", exc_info=True
                            )
                            raise
                        finally:
                            session.close()
                    except Exception as db_error:
                        logger.error(f"æ›´æ–°ä»»åŠ¡è¿›åº¦åˆ°æ•°æ®åº“å¤±è´¥: {db_error}", exc_info=True)

                    # æ›´æ–°è¿›ç¨‹å†…çš„è¿›åº¦ç›‘æ§ï¼ˆè™½ç„¶ä¸»è¿›ç¨‹çœ‹ä¸åˆ°ï¼Œä½†ä¿æŒä¸€è‡´æ€§ï¼‰
                    await backtest_progress_monitor.update_execution_progress(
                        task_id=task_id,
                        processed_days=i + 1,
                        current_date=current_date.strftime("%Y-%m-%d"),
                        signals_generated=len(all_signals),
                        trades_executed=trades_this_day,
                        portfolio_value=portfolio_value,
                    )

                # å®šæœŸè¾“å‡ºè¿›åº¦æ—¥å¿—
                if i % 50 == 0:
                    progress = (i + 1) / len(trading_dates) * 100
                    portfolio_value = portfolio_manager.get_portfolio_value(
                        current_prices
                    )
                    logger.debug(f"å›æµ‹è¿›åº¦: {progress:.1f}%, ç»„åˆä»·å€¼: {portfolio_value:.2f}")

            except Exception as e:
                error_msg = f"å›æµ‹å¾ªç¯é”™è¯¯ï¼Œæ—¥æœŸ: {current_date}, é”™è¯¯: {e}"
                logger.error(error_msg)

                # æ·»åŠ è­¦å‘Šåˆ°è¿›åº¦ç›‘æ§
                if task_id:
                    await backtest_progress_monitor.add_warning(task_id, error_msg)

                continue

        # ========== PERFä¼˜åŒ–ï¼šå¾ªç¯ç»“æŸåæ‰¹é‡å†™å…¥æ•°æ®åº“ ==========
        # å°†å¾ªç¯å†…æ”¶é›†çš„æ‰€æœ‰æ•°æ®ä¸€æ¬¡æ€§å†™å…¥ï¼Œé¿å…730æ¬¡æ•°æ®åº“æ“ä½œ
        if task_id:
            logger.info(f"ğŸ”„ å¼€å§‹æ‰¹é‡å†™å…¥æ•°æ®åº“: ä¿¡å·={len(_batch_signals_data)}, å·²æ‰§è¡Œ={len(_batch_executed_signals)}, æœªæ‰§è¡Œ={len(_batch_unexecuted_signals)}")
            
            try:
                from app.core.database import get_async_session_context
                from app.repositories.backtest_detailed_repository import (
                    BacktestDetailedRepository,
                )

                async with get_async_session_context() as session:
                    try:
                        repository = BacktestDetailedRepository(session)
                        
                        # 1. æ‰¹é‡ä¿å­˜æ‰€æœ‰ä¿¡å·è®°å½•
                        if _batch_signals_data:
                            await repository.batch_save_signal_records(
                                task_id=task_id,
                                backtest_id=_current_backtest_id,
                                signals_data=_batch_signals_data,
                            )
                            logger.info(f"âœ… æ‰¹é‡ä¿å­˜ä¿¡å·è®°å½•å®Œæˆ: {len(_batch_signals_data)} æ¡")
                        
                        # 2. æ‰¹é‡æ›´æ–°æœªæ‰§è¡Œä¿¡å·çš„åŸå› 
                        if _batch_unexecuted_signals:
                            for unexecuted_signal in _batch_unexecuted_signals:
                                await repository.update_signal_execution_reason(
                                    task_id=task_id,
                                    stock_code=unexecuted_signal["stock_code"],
                                    timestamp=unexecuted_signal["timestamp"],
                                    signal_type=unexecuted_signal["signal_type"],
                                    execution_reason=unexecuted_signal["execution_reason"],
                                )
                            logger.info(f"âœ… æ‰¹é‡æ›´æ–°æœªæ‰§è¡ŒåŸå› å®Œæˆ: {len(_batch_unexecuted_signals)} æ¡")
                        
                        # 3. æ‰¹é‡æ ‡è®°å·²æ‰§è¡Œçš„ä¿¡å·
                        if _batch_executed_signals:
                            for executed_signal in _batch_executed_signals:
                                await repository.mark_signal_as_executed(
                                    task_id=task_id,
                                    stock_code=executed_signal["stock_code"],
                                    timestamp=executed_signal["timestamp"],
                                    signal_type=executed_signal["signal_type"],
                                )
                            logger.info(f"âœ… æ‰¹é‡æ ‡è®°å·²æ‰§è¡Œå®Œæˆ: {len(_batch_executed_signals)} æ¡")
                        
                        await session.commit()
                        logger.info("âœ… æ‰€æœ‰æ•°æ®åº“æ“ä½œæ‰¹é‡æäº¤æˆåŠŸ")
                        
                    except Exception as e:
                        await session.rollback()
                        logger.warning(f"æ‰¹é‡å†™å…¥æ•°æ®åº“å¤±è´¥: {e}")
            except Exception as e:
                logger.warning(f"æ‰¹é‡å†™å…¥æ•°æ®åº“æ—¶å‡ºé”™: {e}")
        # ========== END PERFä¼˜åŒ– ==========

        # æœ€ç»ˆè¿›åº¦æ›´æ–°
        if task_id:
            final_portfolio_value = portfolio_manager.get_portfolio_value({})
            await backtest_progress_monitor.update_execution_progress(
                task_id=task_id,
                processed_days=len(trading_dates),
                current_date=trading_dates[-1].strftime("%Y-%m-%d")
                if trading_dates
                else None,
                signals_generated=0,
                trades_executed=0,
                portfolio_value=final_portfolio_value,
            )

        # è®°å½•æ€§èƒ½ç»Ÿè®¡åˆ°æ€§èƒ½åˆ†æå™¨
        if self.enable_performance_profiling and self.performance_profiler:
            if signal_generation_times:
                avg_signal_time = sum(signal_generation_times) / len(
                    signal_generation_times
                )
                self.performance_profiler.end_stage(
                    "backtest_execution",
                    {
                        "avg_signal_generation_time": avg_signal_time,
                        "total_signal_generation_calls": len(signal_generation_times),
                    },
                )
            if trade_execution_times:
                avg_trade_time = sum(trade_execution_times) / len(trade_execution_times)
                self.performance_profiler.end_stage(
                    "backtest_execution",
                    {
                        "avg_trade_execution_time": avg_trade_time,
                        "total_trade_execution_calls": len(trade_execution_times),
                    },
                )

        return {
            "total_signals": total_signals,
            "executed_trades": executed_trades,
            "trading_days": len(trading_dates),
        }

    def _generate_backtest_report(
        self,
        strategy_name: str,
        stock_codes: List[str],
        start_date: datetime,
        end_date: datetime,
        config: BacktestConfig,
        portfolio_manager: PortfolioManager,
        performance_metrics: Dict[str, float],
        strategy_config: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå›æµ‹æŠ¥å‘Š"""

        # åŸºç¡€ä¿¡æ¯
        report = {
            "strategy_name": strategy_name,
            "stock_codes": stock_codes,
            "start_date": start_date.isoformat(),
            "end_date": end_date.isoformat(),
            "initial_cash": config.initial_cash,
            # NOTE: Do NOT call get_portfolio_value({}) here - passing an empty price map
            # will value all positions at 0 and return cash-only, which makes final_value
            # inconsistent with total_return/portfolio_history.
            # Use the last recorded portfolio value (already computed with prices) when available.
            "final_value": (
                portfolio_manager.portfolio_history[-1]["portfolio_value"]
                if getattr(portfolio_manager, "portfolio_history", None)
                else portfolio_manager.get_portfolio_value({})
            ),
            # æ”¶ç›ŠæŒ‡æ ‡
            "total_return": performance_metrics.get("total_return", 0),
            "annualized_return": performance_metrics.get("annualized_return", 0),
            # é£é™©æŒ‡æ ‡
            "volatility": performance_metrics.get("volatility", 0),
            "sharpe_ratio": performance_metrics.get("sharpe_ratio", 0),
            "max_drawdown": performance_metrics.get("max_drawdown", 0),
            # äº¤æ˜“ç»Ÿè®¡
            "total_trades": performance_metrics.get("total_trades", 0),
            "win_rate": performance_metrics.get("win_rate", 0),
            "profit_factor": performance_metrics.get("profit_factor", 0),
            "winning_trades": performance_metrics.get("winning_trades", 0),
            "losing_trades": performance_metrics.get("losing_trades", 0),
            # å°†æŒ‡æ ‡ä¹Ÿæ”¾åœ¨ metrics å­—æ®µä¸­ï¼Œæ–¹ä¾¿ä¼˜åŒ–å™¨ä½¿ç”¨
            "metrics": {
                "sharpe_ratio": performance_metrics.get("sharpe_ratio", 0),
                "total_return": performance_metrics.get("total_return", 0),
                "annualized_return": performance_metrics.get("annualized_return", 0),
                "max_drawdown": performance_metrics.get("max_drawdown", 0),
                "volatility": performance_metrics.get("volatility", 0),
                "win_rate": performance_metrics.get("win_rate", 0),
                "profit_factor": performance_metrics.get("profit_factor", 0),
                "total_trades": performance_metrics.get("total_trades", 0),
            },
            # é…ç½®ä¿¡æ¯
            "backtest_config": {
                "strategy_name": strategy_name,  # æ·»åŠ ç­–ç•¥åç§°ï¼Œæ–¹ä¾¿å‰ç«¯è·å–
                "start_date": start_date.isoformat(),  # æ·»åŠ å¼€å§‹æ—¥æœŸ
                "end_date": end_date.isoformat(),  # æ·»åŠ ç»“æŸæ—¥æœŸ
                "initial_cash": config.initial_cash,  # æ·»åŠ åˆå§‹èµ„é‡‘
                "commission_rate": config.commission_rate,
                "slippage_rate": config.slippage_rate,
                "max_position_size": config.max_position_size,
                **(
                    {"strategy_config": strategy_config}
                    if strategy_config
                    and isinstance(strategy_config, dict)
                    and len(strategy_config) > 0
                    else {}
                ),
            },
            # äº¤æ˜“è®°å½•
            "trade_history": [
                {
                    "trade_id": trade.trade_id if hasattr(trade, 'trade_id') else trade['trade_id'],
                    "stock_code": trade.stock_code if hasattr(trade, 'stock_code') else trade['stock_code'],
                    "action": trade.action if hasattr(trade, 'action') else trade['action'],
                    "quantity": trade.quantity if hasattr(trade, 'quantity') else trade['quantity'],
                    "price": trade.price if hasattr(trade, 'price') else trade['price'],
                    "timestamp": (trade.timestamp if hasattr(trade, 'timestamp') else trade['timestamp']).isoformat(),
                    "commission": trade.commission if hasattr(trade, 'commission') else trade['commission'],
                    "slippage_cost": getattr(trade, "slippage_cost", 0.0) if hasattr(trade, 'slippage_cost') else trade.get('slippage_cost', 0.0),
                    "pnl": trade.pnl if hasattr(trade, 'pnl') else trade['pnl'],
                }
                for trade in portfolio_manager.trades
            ],
            # ç»„åˆå†å²ï¼ˆåŒ…å«å®Œæ•´çš„positionsä¿¡æ¯ï¼‰
            "portfolio_history": [
                {
                    "date": snapshot["date"].isoformat(),
                    "portfolio_value": snapshot["portfolio_value"],
                    "portfolio_value_without_cost": snapshot.get(
                        "portfolio_value_without_cost", snapshot["portfolio_value"]
                    ),
                    "cash": snapshot["cash"],
                    "positions_count": len(snapshot.get("positions", {})),
                    "positions": snapshot.get("positions", {}),  # åŒ…å«å®Œæ•´çš„æŒä»“ä¿¡æ¯
                    "total_return": (snapshot["portfolio_value"] - config.initial_cash)
                    / config.initial_cash
                    if config.initial_cash > 0
                    else 0,
                    "total_return_without_cost": (
                        snapshot.get(
                            "portfolio_value_without_cost", snapshot["portfolio_value"]
                        )
                        - config.initial_cash
                    )
                    / config.initial_cash
                    if config.initial_cash > 0
                    else 0,
                }
                for snapshot in portfolio_manager.portfolio_history
            ],
            # äº¤æ˜“æˆæœ¬ç»Ÿè®¡
            "cost_statistics": {
                "total_commission": portfolio_manager.total_commission,
                "total_slippage": portfolio_manager.total_slippage,
                "total_cost": portfolio_manager.total_commission
                + portfolio_manager.total_slippage,
                "cost_ratio": (
                    portfolio_manager.total_commission
                    + portfolio_manager.total_slippage
                )
                / config.initial_cash
                if config.initial_cash > 0
                else 0,
            },
        }

        # æ·»åŠ æ— æˆæœ¬æŒ‡æ ‡åˆ°æŠ¥å‘Š
        metrics_without_cost = portfolio_manager.get_performance_metrics_without_cost()
        report["excess_return_without_cost"] = {
            "mean": metrics_without_cost.get("mean", 0),
            "std": metrics_without_cost.get("std", 0),
            "annualized_return": metrics_without_cost.get("annualized_return", 0),
            "information_ratio": metrics_without_cost.get("information_ratio", 0),
            "max_drawdown": metrics_without_cost.get("max_drawdown", 0),
        }

        report["excess_return_with_cost"] = {
            "mean": performance_metrics.get("volatility", 0) / np.sqrt(252)
            if performance_metrics.get("volatility", 0) > 0
            else 0,
            "std": performance_metrics.get("volatility", 0),
            "annualized_return": performance_metrics.get("annualized_return", 0),
            "information_ratio": performance_metrics.get(
                "sharpe_ratio", 0
            ),  # ä½¿ç”¨å¤æ™®æ¯”ç‡ä½œä¸ºè¿‘ä¼¼
            "max_drawdown": performance_metrics.get("max_drawdown", 0),
        }

        # è®¡ç®—é¢å¤–çš„åˆ†ææŒ‡æ ‡
        report.update(self._calculate_additional_metrics(portfolio_manager))

        return report

    def _rebalance_topk_buffer(
        self,
        portfolio_manager: PortfolioManager,
        current_prices: Dict[str, float],
        current_date: datetime,
        scores: Dict[str, float],
        topk: int = 10,
        buffer_n: int = 20,
        max_changes: int = 2,
        strategy: Optional[BaseStrategy] = None,
        debug: bool = False,
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]], int]:
        """æ¯æ—¥ TopK é€‰è‚¡ + buffer æ¢ä»“ + æ¯å¤©æœ€å¤šæ¢ max_changes åªã€‚

        è§„åˆ™ï¼ˆå®ç›˜å¯¹é½ç‰ˆï¼‰ï¼š
        - ç›®æ ‡æŒä»“æ•°é‡=topk
        - è‹¥æŒä»“ä»åœ¨ Top(topk+buffer_n) å†…ï¼Œåˆ™å°½é‡ä¿ç•™ï¼ˆå‡å°‘æ¢æ‰‹ï¼‰
        - æ¯å¤©æœ€å¤šåš max_changes ä¸ª "å–å‡º+ä¹°å…¥" çš„æ›¿æ¢

        Returns:
            executed_trade_signals, unexecuted_signals, trades_this_day
        """
        executed_trade_signals: List[Dict[str, Any]] = []
        unexecuted_signals: List[Dict[str, Any]] = []
        trades_this_day = 0

        if topk <= 0:
            return executed_trade_signals, unexecuted_signals, trades_this_day

        # rank by score desc, tie-break by stock_code for determinism
        ranked = sorted(scores.items(), key=lambda kv: (kv[1], kv[0]), reverse=True)
        topk_list = [c for c, _ in ranked[:topk]]
        buffer_list = [c for c, _ in ranked[: max(topk, topk + buffer_n)]]
        buffer_set = set(buffer_list)

        holdings = list(portfolio_manager.positions.keys())
        holdings_set = set(holdings)

        # Keep holdings inside buffer zone
        kept = [c for c in holdings if c in buffer_set]

        # If kept > topk, trim lowest-ranked among kept
        rank_index = {c: i for i, (c, _) in enumerate(ranked)}
        if len(kept) > topk:
            kept_sorted = sorted(kept, key=lambda c: rank_index.get(c, 10**9))
            kept = kept_sorted[:topk]

        kept_set = set(kept)

        # Sell candidates: holdings outside buffer OR trimmed
        to_sell = [c for c in holdings if c not in kept_set]

        # Buy candidates: topk names not already kept
        to_buy = [c for c in topk_list if c not in kept_set]

        # Decide actions under max_changes
        # - If current holdings < topk: allow buys even without sells (build initial positions)
        # - Otherwise: do replacement pairs (sell+buy) up to max_changes
        current_n = len(holdings)
        if current_n < topk:
            # how many new names to buy today
            buy_quota = min(max_changes, topk - current_n, len(to_buy))
            to_sell = []
            to_buy = to_buy[:buy_quota]
        else:
            # replacement pairs
            n_pairs = min(max_changes, len(to_sell), len(to_buy))
            to_sell = to_sell[:n_pairs]
            to_buy = to_buy[:n_pairs]

        if debug:
            try:
                nonzero = sum(1 for _, s in scores.items() if isinstance(s, (int, float)) and s != 0)
                logger.info(
                    f"[topk_buffer] {current_date.date()} holdings={len(holdings)} nonzero_scores={nonzero} "
                    f"topk={topk} buffer={buffer_n} max_changes={max_changes} "
                    f"to_sell={len(to_sell)} to_buy={len(to_buy)}"
                )
                logger.info(
                    f"[topk_buffer] topk_list(head)={topk_list[:min(5,len(topk_list))]} "
                    f"holdings(head)={holdings[:min(5,len(holdings))]}"
                )
            except Exception:
                pass

        # Execute sells first
        successful_sells = 0
        for code in to_sell:
            sig = TradingSignal(
                timestamp=current_date,
                stock_code=code,
                signal_type=SignalType.SELL,
                strength=1.0,
                price=float(current_prices.get(code, 0.0) or 0.0),
                reason=f"topk_buffer rebalance sell (out of buffer/topk)",
                metadata={"trade_mode": "topk_buffer"},
            )
            if strategy is not None:
                is_valid, validation_reason = strategy.validate_signal(
                    sig,
                    portfolio_manager.get_portfolio_value(current_prices),
                    portfolio_manager.positions,
                )
                if not is_valid:
                    unexecuted_signals.append(
                        {
                            "stock_code": code,
                            "timestamp": current_date,
                            "signal_type": sig.signal_type.name,
                            "execution_reason": validation_reason or "ä¿¡å·éªŒè¯å¤±è´¥",
                        }
                    )
                    continue

            trade, failure_reason = portfolio_manager.execute_signal(sig, current_prices)
            if trade:
                successful_sells += 1
                trades_this_day += 1
                executed_trade_signals.append(
                    {"stock_code": code, "timestamp": current_date, "signal_type": sig.signal_type.name}
                )
            else:
                unexecuted_signals.append(
                    {
                        "stock_code": code,
                        "timestamp": current_date,
                        "signal_type": sig.signal_type.name,
                        "execution_reason": failure_reason or "æ‰§è¡Œå¤±è´¥ï¼ˆæœªçŸ¥åŸå› ï¼‰",
                    }
                )

        # Execute buys
        # Guardrails:
        # 1) replacement æ¨¡å¼ä¸‹ï¼šåªå…è®¸ç”¨ã€ŒæˆåŠŸå–å‡ºã€æ¢å…¥ï¼Œé¿å…å–å¤±è´¥ä»ä¹°å¯¼è‡´æŒä»“è†¨èƒ€
        # 2) ä»»ä½•æƒ…å†µä¸‹éƒ½ä¸å…è®¸æŒä»“æ•°è¶…è¿‡ topk
        current_positions_n = len(portfolio_manager.positions)
        remaining_capacity = max(0, topk - current_positions_n)

        if current_n >= topk:
            # replacement mode: buys must be backed by successful sells
            buy_quota = min(len(to_buy), successful_sells, remaining_capacity)
        else:
            # build mode: still respect capacity
            buy_quota = min(len(to_buy), remaining_capacity)

        to_buy = to_buy[:buy_quota]

        for code in to_buy:
            # Hard cap: never allow positions to exceed topk (even if earlier logic misbehaves)
            if len(portfolio_manager.positions) >= topk:
                unexecuted_signals.append(
                    {
                        "stock_code": code,
                        "timestamp": current_date,
                        "signal_type": SignalType.BUY.name,
                        "execution_reason": f"è¶…è¿‡topkæŒä»“ä¸Šé™(topk={topk})ï¼Œè·³è¿‡ä¹°å…¥",
                    }
                )
                break

            sig = TradingSignal(
                timestamp=current_date,
                stock_code=code,
                signal_type=SignalType.BUY,
                strength=1.0,
                price=float(current_prices.get(code, 0.0) or 0.0),
                reason=f"topk_buffer rebalance buy (enter top{topk})",
                metadata={"trade_mode": "topk_buffer"},
            )
            if strategy is not None:
                is_valid, validation_reason = strategy.validate_signal(
                    sig,
                    portfolio_manager.get_portfolio_value(current_prices),
                    portfolio_manager.positions,
                )
                if not is_valid:
                    unexecuted_signals.append(
                        {
                            "stock_code": code,
                            "timestamp": current_date,
                            "signal_type": sig.signal_type.name,
                            "execution_reason": validation_reason or "ä¿¡å·éªŒè¯å¤±è´¥",
                        }
                    )
                    continue

            trade, failure_reason = portfolio_manager.execute_signal(sig, current_prices)
            if trade:
                trades_this_day += 1
                executed_trade_signals.append(
                    {"stock_code": code, "timestamp": current_date, "signal_type": sig.signal_type.name}
                )
            else:
                unexecuted_signals.append(
                    {
                        "stock_code": code,
                        "timestamp": current_date,
                        "signal_type": sig.signal_type.name,
                        "execution_reason": failure_reason or "æ‰§è¡Œå¤±è´¥ï¼ˆæœªçŸ¥åŸå› ï¼‰",
                    }
                )

        return executed_trade_signals, unexecuted_signals, trades_this_day

    def _calculate_additional_metrics(
        self, portfolio_manager: PortfolioManager
    ) -> Dict[str, Any]:
        """è®¡ç®—é¢å¤–çš„åˆ†ææŒ‡æ ‡ï¼ˆæ—¶é—´åˆ†æ®µè¡¨ç°ã€ä¸ªè‚¡è¡¨ç°ç­‰ï¼‰"""
        additional_metrics: Dict[str, Any] = {}

        try:
            if not portfolio_manager.portfolio_history:
                return additional_metrics

            # --- æ—¶é—´åˆ†æ®µè¡¨ç°ï¼šæŒ‰æœˆ / æŒ‰å¹´æ”¶ç›Š ---
            portfolio_values = pd.Series(
                [
                    snapshot["portfolio_value"]
                    for snapshot in portfolio_manager.portfolio_history
                ],
                index=[
                    snapshot["date"] for snapshot in portfolio_manager.portfolio_history
                ],
            ).sort_index()

            # æœˆåº¦æ”¶ç›Šï¼ˆæœˆæœ«æƒç›Šï¼‰
            # pandas>=3.0: 'M' deprecated, use month-end 'ME'
            monthly_values = portfolio_values.resample("ME").last()
            monthly_returns = monthly_values.pct_change().dropna()

            if len(monthly_returns) > 0:
                additional_metrics.update(
                    {
                        "monthly_return_mean": float(monthly_returns.mean()),
                        "monthly_return_std": float(monthly_returns.std()),
                        "best_month": float(monthly_returns.max()),
                        "worst_month": float(monthly_returns.min()),
                        "positive_months": int((monthly_returns > 0).sum()),
                        "negative_months": int((monthly_returns < 0).sum()),
                        "monthly_returns_detail": [
                            {
                                "month": period.strftime("%Y-%m"),
                                "return": float(ret),
                            }
                            for period, ret in monthly_returns.items()
                        ],
                    }
                )

            # å¹´åº¦æ”¶ç›Šï¼ˆå¹´æœ«æƒç›Šï¼‰
            yearly_values = portfolio_values.resample("Y").last()
            yearly_returns = yearly_values.pct_change().dropna()

            if len(yearly_returns) > 0:
                additional_metrics["yearly_returns_detail"] = [
                    {
                        "year": period.year,
                        "return": float(ret),
                    }
                    for period, ret in yearly_returns.items()
                ]

            # --- äº¤æ˜“è¡Œä¸ºä¸ä¸ªè‚¡è¡¨ç° ---
            if portfolio_manager.trades:
                stock_performance: Dict[str, Dict[str, Any]] = {}

                # è¾…åŠ©å‡½æ•°ï¼šç»Ÿä¸€è®¿é—® trade å±æ€§ï¼ˆæ”¯æŒ Trade å¯¹è±¡å’Œå­—å…¸ï¼‰
                def get_trade_attr(trade, attr: str):
                    if isinstance(trade, dict):
                        return trade.get(attr)
                    return getattr(trade, attr, None)

                for trade in portfolio_manager.trades:
                    stock_code = get_trade_attr(trade, 'stock_code')
                    action = get_trade_attr(trade, 'action')
                    pnl = get_trade_attr(trade, 'pnl') or 0.0

                    stock_stats = stock_performance.setdefault(
                        stock_code,
                        {
                            "stock_code": stock_code,
                            "total_pnl": 0.0,
                            "trade_count": 0,
                        },
                    )
                    stock_stats["trade_count"] += 1
                    # åªæœ‰å–å‡ºäº¤æ˜“æ‰æœ‰å®ç°ç›ˆäº
                    if action == "SELL":
                        stock_stats["total_pnl"] += float(pnl)

                # è®¡ç®—æ¯åªè‚¡ç¥¨çš„å¹³å‡å•ç¬”ç›ˆäº
                for stats in stock_performance.values():
                    trades = max(stats["trade_count"], 1)
                    stats["avg_pnl_per_trade"] = float(stats["total_pnl"]) / trades

                # ä¸ªè‚¡è¡¨ç°æ±‡æ€»
                stock_perf_list = list(stock_performance.values())
                additional_metrics.update(
                    {
                        "stock_performance_detail": stock_perf_list,
                        "best_performing_stock": max(
                            stock_perf_list, key=lambda x: x["total_pnl"]
                        )
                        if stock_perf_list
                        else None,
                        "worst_performing_stock": min(
                            stock_perf_list, key=lambda x: x["total_pnl"]
                        )
                        if stock_perf_list
                        else None,
                        "stocks_traded": len(stock_perf_list),
                    }
                )

                # å•ç¬”äº¤æ˜“åˆ†å¸ƒçš„æ•´ä½“ç‰¹å¾ï¼ˆä¾¿äºå‰ç«¯ç”»ç›´æ–¹å›¾/ç»Ÿè®¡ï¼‰
                pnls = [float(get_trade_attr(t, 'pnl') or 0.0) for t in portfolio_manager.trades]
                if pnls:
                    pnl_series = pd.Series(pnls)
                    additional_metrics.update(
                        {
                            "trade_pnl_mean": float(pnl_series.mean()),
                            "trade_pnl_median": float(pnl_series.median()),
                            "trade_pnl_std": float(pnl_series.std()),
                        }
                    )

        except Exception as exc:
            logger.error(f"è®¡ç®—é¢å¤–æŒ‡æ ‡å¤±è´¥: {exc}")

        return additional_metrics

    def validate_backtest_parameters(
        self,
        strategy_name: str,
        stock_codes: List[str],
        start_date: datetime,
        end_date: datetime,
        strategy_config: Dict[str, Any],
    ) -> bool:
        """éªŒè¯å›æµ‹å‚æ•°"""
        try:
            # éªŒè¯ç­–ç•¥åç§°
            available_strategies = StrategyFactory.get_available_strategies()
            if strategy_name.lower() not in available_strategies:
                raise TaskError(
                    message=f"ä¸æ”¯æŒçš„ç­–ç•¥: {strategy_name}ï¼Œå¯ç”¨ç­–ç•¥: {available_strategies}",
                    severity=ErrorSeverity.MEDIUM,
                )

            # éªŒè¯è‚¡ç¥¨ä»£ç 
            if not stock_codes or len(stock_codes) == 0:
                raise TaskError(message="è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º", severity=ErrorSeverity.MEDIUM)

            if len(stock_codes) > 1000:
                raise TaskError(
                    message=f"è‚¡ç¥¨æ•°é‡è¿‡å¤š: {len(stock_codes)}ï¼Œæœ€å¤šæ”¯æŒ1000åªè‚¡ç¥¨",
                    severity=ErrorSeverity.MEDIUM,
                )

            # éªŒè¯æ—¥æœŸèŒƒå›´
            if start_date >= end_date:
                raise TaskError(message="å¼€å§‹æ—¥æœŸå¿…é¡»æ—©äºç»“æŸæ—¥æœŸ", severity=ErrorSeverity.MEDIUM)

            date_range = (end_date - start_date).days
            if date_range < 30:
                raise TaskError(
                    message=f"å›æµ‹æœŸé—´å¤ªçŸ­: {date_range}å¤©ï¼Œè‡³å°‘éœ€è¦30å¤©",
                    severity=ErrorSeverity.MEDIUM,
                )

            if date_range > 3650:  # 10å¹´
                raise TaskError(
                    message=f"å›æµ‹æœŸé—´å¤ªé•¿: {date_range}å¤©ï¼Œæœ€å¤šæ”¯æŒ10å¹´",
                    severity=ErrorSeverity.MEDIUM,
                )

            # éªŒè¯ç­–ç•¥é…ç½®
            if not isinstance(strategy_config, dict):
                raise TaskError(message="ç­–ç•¥é…ç½®å¿…é¡»æ˜¯å­—å…¸æ ¼å¼", severity=ErrorSeverity.MEDIUM)

            return True

        except TaskError:
            raise
        except Exception as e:
            raise TaskError(
                message=f"å‚æ•°éªŒè¯å¤±è´¥: {str(e)}",
                severity=ErrorSeverity.MEDIUM,
                original_exception=e,
            )

    def get_execution_statistics(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        return {
            **self.execution_stats,
            "success_rate": (
                self.execution_stats["successful_backtests"]
                / max(self.execution_stats["total_backtests"], 1)
            ),
            "available_strategies": StrategyFactory.get_available_strategies(),
        }

    def _get_execution_failure_reason(
        self,
        signal: TradingSignal,
        portfolio_manager: PortfolioManager,
        current_prices: Dict[str, float],
    ) -> str:
        """
        è·å–æ‰§è¡Œå¤±è´¥çš„åŸå› 

        Args:
            signal: äº¤æ˜“ä¿¡å·
            portfolio_manager: ç»„åˆç®¡ç†å™¨
            current_prices: å½“å‰ä»·æ ¼

        Returns:
            å¤±è´¥åŸå› å­—ç¬¦ä¸²
        """
        try:
            stock_code = signal.stock_code
            current_price = current_prices.get(stock_code, signal.price)

            if signal.signal_type == SignalType.BUY:
                # ä¹°å…¥å¤±è´¥çš„å¯èƒ½åŸå› ï¼ˆé€»è¾‘ä¸ _execute_buy ä¿æŒä¸€è‡´ï¼‰
                # è®¡ç®—ç»„åˆä»·å€¼ï¼ˆä½¿ç”¨ä¸ _execute_buy ç›¸åŒçš„é€»è¾‘ï¼‰
                portfolio_value = portfolio_manager.get_portfolio_value(
                    {stock_code: current_price}
                )
                max_position_value = (
                    portfolio_value * portfolio_manager.config.max_position_size
                )

                current_position = portfolio_manager.positions.get(stock_code)
                current_position_value = (
                    current_position.market_value if current_position else 0
                )

                available_cash_for_stock = max_position_value - current_position_value
                available_cash_for_stock = min(
                    available_cash_for_stock, portfolio_manager.cash * 0.95
                )  # ä¿ç•™5%ç°é‡‘

                if available_cash_for_stock <= 0:
                    if (
                        current_position_value > 0
                        and current_position_value >= max_position_value
                    ):
                        return f"å·²è¾¾åˆ°æœ€å¤§æŒä»“é™åˆ¶: å½“å‰æŒä»“ {current_position_value:.2f} >= æœ€å¤§æŒä»“ {max_position_value:.2f}"
                    else:
                        return f"å¯ç”¨èµ„é‡‘ä¸è¶³: éœ€è¦ä¿ç•™5%ç°é‡‘ï¼Œå¯ç”¨èµ„é‡‘ {portfolio_manager.cash:.2f}"

                # è®¡ç®—è´­ä¹°æ•°é‡ï¼ˆæœ€å°äº¤æ˜“å•ä½ä¸º100è‚¡ï¼‰
                quantity = int(available_cash_for_stock / current_price / 100) * 100
                if quantity <= 0:
                    return f"å¯ä¹°æ•°é‡ä¸è¶³: å¯ç”¨èµ„é‡‘ {available_cash_for_stock:.2f}ï¼Œä»·æ ¼ {current_price:.2f}ï¼Œæ— æ³•ä¹°å…¥100è‚¡"

                # è®¡ç®—å®é™…æˆæœ¬ï¼ˆåŒ…å«æ‰‹ç»­è´¹å’Œæ»‘ç‚¹ï¼‰
                # åº”ç”¨æ»‘ç‚¹ï¼ˆä¹°å…¥æ—¶ä»·æ ¼ä¸Šæ¶¨ï¼‰
                execution_price = current_price * (
                    1 + portfolio_manager.config.slippage_rate
                )
                slippage_cost_per_share = (
                    current_price * portfolio_manager.config.slippage_rate
                )

                total_cost = quantity * execution_price
                commission = total_cost * portfolio_manager.config.commission_rate
                slippage_cost = quantity * slippage_cost_per_share
                total_cost_with_all_fees = total_cost + commission

                if total_cost_with_all_fees > portfolio_manager.cash:
                    return f"èµ„é‡‘ä¸è¶³: éœ€è¦ {total_cost_with_all_fees:.2f}ï¼ˆå«æ‰‹ç»­è´¹ {commission:.2f}ï¼‰ï¼Œå¯ç”¨ {portfolio_manager.cash:.2f}"

                # å¦‚æœæ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡ä½†è¿˜æ˜¯å¤±è´¥äº†ï¼Œå¯èƒ½æ˜¯å…¶ä»–åŸå› 
                return f"æ‰§è¡Œå¤±è´¥: å¯èƒ½å› æ»‘ç‚¹æˆæœ¬ {slippage_cost:.2f} æˆ–å…¶ä»–é™åˆ¶"

            elif signal.signal_type == SignalType.SELL:
                # å–å‡ºå¤±è´¥çš„å¯èƒ½åŸå› 
                if stock_code not in portfolio_manager.positions:
                    return "æ— æŒä»“"

                position = portfolio_manager.positions[stock_code]
                if position.quantity <= 0:
                    return "æŒä»“æ•°é‡ä¸º0"

                # å¦‚æœæ‰€æœ‰æ£€æŸ¥éƒ½é€šè¿‡ä½†è¿˜æ˜¯å¤±è´¥äº†ï¼Œå¯èƒ½æ˜¯å…¶ä»–åŸå› 
                return "æ‰§è¡Œå¤±è´¥ï¼ˆæœªçŸ¥åŸå› ï¼‰"

            return "æœªçŸ¥ä¿¡å·ç±»å‹"

        except Exception as e:
            logger.warning(f"è·å–æ‰§è¡Œå¤±è´¥åŸå› æ—¶å‡ºé”™: {e}")
            return f"æ‰§è¡Œå¼‚å¸¸: {str(e)}"

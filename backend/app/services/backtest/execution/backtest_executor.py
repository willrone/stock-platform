"""
å›æµ‹æ‰§è¡Œå™¨ - å®Œæ•´çš„å›æµ‹æµç¨‹æ‰§è¡Œå’Œç»“æœåˆ†æï¼ˆé‡æ„ç‰ˆï¼‰
"""

import time
import uuid
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional

from loguru import logger

from app.core.error_handler import ErrorSeverity, TaskError

from ..core.portfolio_manager import PortfolioManager
from ..core.portfolio_manager_array import PortfolioManagerArray
from ..models import BacktestConfig
from ..strategies.strategy_factory import AdvancedStrategyFactory, StrategyFactory
from .backtest_loop_executor import BacktestLoopExecutor

# from .backtest_progress_monitor import backtest_progress_monitor
from .data_loader import DataLoader

# å¯¼å…¥æ–°æ¨¡å—
from .data_preprocessor import DataPreprocessor
from .performance_tracker import PerformanceTracker
from .report_generator import BacktestReportGenerator
from .validators import get_execution_statistics, validate_backtest_parameters


class BacktestExecutor:
    """å›æµ‹æ‰§è¡Œå™¨ï¼ˆé‡æ„ç‰ˆï¼‰- åè°ƒå„æ¨¡å—å®Œæˆå›æµ‹"""

    def __init__(
        self,
        data_dir: str = "data",
        enable_parallel: bool = True,
        max_workers: Optional[int] = None,
        enable_performance_profiling: bool = False,
        use_multiprocessing: bool = True,
        persistence=None,
    ):
        """
        åˆå§‹åŒ–å›æµ‹æ‰§è¡Œå™¨

        Args:
            data_dir: æ•°æ®ç›®å½•
            enable_parallel: æ˜¯å¦å¯ç”¨å¹¶è¡ŒåŒ–ï¼ˆé»˜è®¤Trueï¼‰
            max_workers: æœ€å¤§å·¥ä½œçº¿ç¨‹æ•°ï¼Œé»˜è®¤ä½¿ç”¨CPUæ ¸å¿ƒæ•°
            enable_performance_profiling: æ˜¯å¦å¯ç”¨æ€§èƒ½åˆ†æï¼ˆé»˜è®¤Falseï¼‰
            use_multiprocessing: æ˜¯å¦ä½¿ç”¨å¤šè¿›ç¨‹ï¼ˆçªç ´GILé™åˆ¶ï¼Œé»˜è®¤Trueï¼‰
        """
        import os

        if max_workers is None:
            max_workers = min(os.cpu_count() or 4, 8)

        self.enable_parallel = enable_parallel
        self.max_workers = max_workers
        self.use_multiprocessing = use_multiprocessing
        self.use_array_portfolio = True

        # æŒä¹…åŒ–æœåŠ¡ï¼ˆå¯é€‰ï¼Œå‘åå…¼å®¹ï¼‰
        self._persistence = persistence

        # æ•°æ®åŠ è½½å™¨
        self.data_loader = DataLoader(
            data_dir, max_workers=max_workers if enable_parallel else None
        )

        # æ‰§è¡Œç»Ÿè®¡
        self.execution_stats = {
            "total_backtests": 0,
            "successful_backtests": 0,
            "failed_backtests": 0,
        }

        # åˆå§‹åŒ–å„æ¨¡å—
        self.data_preprocessor = DataPreprocessor(
            enable_parallel=enable_parallel,
            max_workers=max_workers,
            use_multiprocessing=use_multiprocessing,
        )
        self.loop_executor = BacktestLoopExecutor()
        self.report_generator = BacktestReportGenerator()
        self.performance_tracker = PerformanceTracker(
            enable_profiling=enable_performance_profiling
        )

        # æ˜¾å¼å¯¼å…¥è¿›åº¦ç›‘æ§å™¨ï¼ˆé¿å…æ½œåœ¨çš„å¾ªç¯å¯¼å…¥æˆ–æœªå®šä¹‰é—®é¢˜ï¼‰
        from .backtest_progress_monitor import backtest_progress_monitor

        self.progress_monitor = backtest_progress_monitor

        if enable_parallel:
            mode = "å¤šè¿›ç¨‹" if use_multiprocessing else "å¤šçº¿ç¨‹"
            logger.info(f"å›æµ‹æ‰§è¡Œå™¨å·²å¯ç”¨å¹¶è¡ŒåŒ–ï¼ˆ{mode}ï¼‰ï¼Œæœ€å¤§å·¥ä½œè¿›ç¨‹/çº¿ç¨‹æ•°: {max_workers}")

        if enable_performance_profiling:
            logger.info("å›æµ‹æ‰§è¡Œå™¨å·²å¯ç”¨æ€§èƒ½åˆ†æ")

    async def run_backtest(
        self,
        strategy_name: str,
        stock_codes: List[str],
        start_date: datetime,
        end_date: datetime,
        strategy_config: Dict[str, Any],
        backtest_config: Optional[BacktestConfig] = None,
        task_id: str = None,
        preloaded_stock_data: Optional[Dict[str, Any]] = None,
        precomputed_context: Optional[Dict[str, Any]] = None,
    ) -> Dict[str, Any]:
        """
        è¿è¡Œå›æµ‹

        Args:
            strategy_name: ç­–ç•¥åç§°
            stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
            start_date: å¼€å§‹æ—¥æœŸ
            end_date: ç»“æŸæ—¥æœŸ
            strategy_config: ç­–ç•¥é…ç½®
            backtest_config: å›æµ‹é…ç½®
            task_id: ä»»åŠ¡ID
            preloaded_stock_data: é¢„åŠ è½½çš„è‚¡ç¥¨æ•°æ®ï¼ˆä¼˜åŒ–åœºæ™¯ä¸‹è·³è¿‡é‡å¤ç£ç›˜è¯»å–ï¼‰
            precomputed_context: é¢„è®¡ç®—çš„ä¸Šä¸‹æ–‡ï¼ˆtrading_dates ç­‰ï¼Œä¼˜åŒ–åœºæ™¯ä¸‹è·³è¿‡é‡å¤è®¡ç®—ï¼‰

        Returns:
            å›æµ‹æŠ¥å‘Šå­—å…¸
        """
        # è½»é‡åˆ†æ®µè®¡æ—¶
        perf_breakdown: Dict[str, float] = {}
        _t_total0 = time.perf_counter()

        # å¯åŠ¨æ€§èƒ½è¿½è¸ª
        self.performance_tracker.start_backtest()

        try:
            self.execution_stats["total_backtests"] += 1

            # ç”Ÿæˆå›æµ‹ID å¹¶åˆ›å»ºå ä½è¡Œ
            # ä¼˜å…ˆä½¿ç”¨ persistence æœåŠ¡ï¼Œå‘åå…¼å®¹æ—§è·¯å¾„
            if task_id and self._persistence is not None:
                backtest_id = self._persistence.create_backtest_session(
                    task_id=task_id,
                    strategy_name=strategy_name,
                    start_date=start_date,
                    end_date=end_date,
                )
            else:
                backtest_id = str(uuid.uuid4())
                if task_id:
                    self._create_placeholder_backtest_result(
                        task_id=task_id,
                        backtest_id=backtest_id,
                        strategy_name=strategy_name,
                        start_date=start_date,
                        end_date=end_date,
                    )

            # ä½¿ç”¨é»˜è®¤é…ç½®
            if backtest_config is None:
                backtest_config = BacktestConfig()

            # å¤§è§„æ¨¡å›æµ‹è‡ªåŠ¨ä¼˜åŒ–å†…å­˜ï¼šè‚¡ç¥¨æ•°Ã—å¤©æ•° > 20000 æ—¶å…³é—­æŒä»“æ˜ç»†è®°å½•
            num_days = (end_date - start_date).days
            if len(stock_codes) * num_days > 20000:
                backtest_config.record_positions_in_history = False
                backtest_config.portfolio_history_stride = max(backtest_config.portfolio_history_stride, 10)
                logger.info(
                    f"å¤§è§„æ¨¡å›æµ‹å†…å­˜ä¼˜åŒ–: {len(stock_codes)}è‚¡Ã—{num_days}å¤©, "
                    f"å…³é—­æŒä»“æ˜ç»†, stride={backtest_config.portfolio_history_stride}"
                )

            # ML ç­–ç•¥è‡ªåŠ¨å¯ç”¨ topk_buffer äº¤æ˜“æ¨¡å¼ï¼ˆæˆªé¢æ’åé€‰è‚¡ï¼‰
            if strategy_name == "ml_ensemble_lgb_xgb_riskctl" and strategy_config:
                if "trade_mode" not in strategy_config:
                    _top_n = strategy_config.get("top_n", 10)
                    strategy_config.setdefault("trade_mode", "topk_buffer")
                    strategy_config.setdefault("topk", _top_n)
                    strategy_config.setdefault("buffer", _top_n * 2)
                    strategy_config.setdefault("max_changes_per_day", 3)
                    strategy_config.setdefault("min_buy_score", 0.0)
                    logger.info(
                        f"MLç­–ç•¥è‡ªåŠ¨å¯ç”¨ topk_buffer æ¨¡å¼: topk={_top_n}, "
                        f"buffer={strategy_config['buffer']}, max_changes={strategy_config['max_changes_per_day']}"
                    )

            # å¼€å§‹è¿›åº¦ç›‘æ§
            if task_id:
                await self.progress_monitor.start_backtest_monitoring(
                    task_id=task_id, backtest_id=backtest_id
                )
                await self.progress_monitor.update_stage(
                    task_id, "initialization", progress=100, status="completed"
                )

            # ========== é˜¶æ®µ 1: åˆ›å»ºç­–ç•¥ ==========
            _t0 = time.perf_counter()
            self.performance_tracker.start_stage(
                "strategy_setup",
                {"strategy_name": strategy_name, "stock_count": len(stock_codes)},
            )

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "strategy_setup", status="running"
                )

            # ä¼˜å…ˆä½¿ç”¨é«˜çº§ç­–ç•¥å·¥å‚
            try:
                strategy = AdvancedStrategyFactory.create_strategy(
                    strategy_name, strategy_config
                )
            except Exception:
                strategy = StrategyFactory.create_strategy(
                    strategy_name, strategy_config
                )

            self.performance_tracker.end_stage("strategy_setup")
            perf_breakdown["strategy_setup_s"] = time.perf_counter() - _t0

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "strategy_setup", progress=100, status="completed"
                )

            # ========== é˜¶æ®µ 2: åŠ è½½æ•°æ® ==========
            _t0 = time.perf_counter()
            self.performance_tracker.start_stage(
                "data_loading",
                {
                    "stock_codes": stock_codes,
                    "start_date": start_date.isoformat(),
                    "end_date": end_date.isoformat(),
                },
            )

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "data_loading", status="running"
                )

            logger.info(
                f"å¼€å§‹å›æµ‹: {strategy_name}, è‚¡ç¥¨: {stock_codes}, æœŸé—´: {start_date} - {end_date}"
            )

            # perf: ä¼˜åŒ–åœºæ™¯ä¸‹ä½¿ç”¨é¢„åŠ è½½æ•°æ®ï¼Œè·³è¿‡é‡å¤ç£ç›˜ I/O
            if preloaded_stock_data is not None:
                stock_data = preloaded_stock_data
                logger.info(f"ä½¿ç”¨é¢„åŠ è½½æ•°æ®: {len(stock_data)} åªè‚¡ç¥¨ï¼ˆè·³è¿‡ç£ç›˜è¯»å–ï¼‰")
            else:
                stock_data = self.data_loader.load_multiple_stocks(
                    stock_codes, start_date, end_date
                )

            self.performance_tracker.end_stage(
                "data_loading",
                {
                    "loaded_stocks": len(stock_data),
                    "total_records": sum(len(df) for df in stock_data.values()),
                },
            )
            self.performance_tracker.take_memory_snapshot("after_data_loading")
            perf_breakdown["data_loading_s"] = time.perf_counter() - _t0

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "data_loading", progress=100, status="completed"
                )

            # ========== é˜¶æ®µ 3: åˆ›å»ºç»„åˆç®¡ç†å™¨ ==========
            actual_stock_codes = list(stock_data.keys())
            if self.use_array_portfolio:
                portfolio_manager = PortfolioManagerArray(
                    backtest_config, actual_stock_codes
                )
                logger.info(f"âœ… ä½¿ç”¨æ•°ç»„åŒ–æŒä»“ç®¡ç†å™¨ (stocks={len(actual_stock_codes)})")
            else:
                portfolio_manager = PortfolioManager(backtest_config)
                logger.info(f"ä½¿ç”¨ä¼ ç»ŸæŒä»“ç®¡ç†å™¨ (stocks={len(actual_stock_codes)})")

            # ========== é˜¶æ®µ 4: æ•°æ®é¢„å¤„ç† ==========
            _t0 = time.perf_counter()

            # perf: P0-2 ä¼˜åŒ–åœºæ™¯ä¸‹å¤ç”¨é¢„è®¡ç®—çš„ trading_datesï¼Œé¿å…æ¯ä¸ª trial ï¿½ï¿½å¤è®¡ç®—
            if precomputed_context and "trading_dates" in precomputed_context:
                trading_dates = precomputed_context["trading_dates"]
                logger.debug(f"ä½¿ç”¨é¢„è®¡ç®—çš„ trading_dates: {len(trading_dates)} å¤©")
            else:
                # è·å–äº¤æ˜“æ—¥å†
                trading_dates = self.data_preprocessor.get_trading_calendar(
                    stock_data, start_date, end_date
                )

            # æ„å»ºæ—¥æœŸç´¢å¼•
            self.data_preprocessor.build_date_index(stock_data)

            # é¢„è®¡ç®—ä¿¡å·
            self.data_preprocessor.precompute_strategy_signals(strategy, stock_data)

            # æå–é¢„è®¡ç®—ä¿¡å·
            precomputed_signals = (
                self.data_preprocessor.extract_precomputed_signals_to_dict(
                    strategy, stock_data
                )
            )

            logger.info(f"ğŸ” é¢„è®¡ç®—ä¿¡å·å­—å…¸å¤§å°: {len(precomputed_signals)}")

            perf_breakdown["precompute_signals_s"] = time.perf_counter() - _t0

            # éªŒè¯äº¤æ˜“æ—¥ï¿½ï¿½ï¿½é‡
            if len(trading_dates) < 20:
                error_msg = f"äº¤æ˜“æ—¥æ•°é‡ä¸è¶³: {len(trading_dates)}ï¼Œè‡³å°‘éœ€è¦20ä¸ªäº¤æ˜“æ—¥"
                if task_id:
                    await self.progress_monitor.set_error(task_id, error_msg)
                raise TaskError(message=error_msg, severity=ErrorSeverity.MEDIUM)

            # æ›´æ–°æ€»äº¤æ˜“æ—¥æ•°
            if task_id:
                progress_data = self.progress_monitor.get_progress_data(task_id)
                if progress_data:
                    progress_data.total_trading_days = len(trading_dates)

                # å†™å…¥æ•°æ®åº“
                try:
                    from app.core.database import SessionLocal
                    from app.models.task_models import TaskStatus
                    from app.repositories.task_repository import TaskRepository

                    session = SessionLocal()
                    try:
                        task_repo = TaskRepository(session)
                        existing_task = task_repo.get_task_by_id(task_id)
                        if existing_task:
                            result_data = existing_task.result or {}
                            progress_data_db = result_data.get("progress_data", {})
                            progress_data_db["total_days"] = len(trading_dates)
                            result_data["progress_data"] = progress_data_db

                            task_repo.update_task_status(
                                task_id=task_id,
                                status=TaskStatus.RUNNING,
                                result=result_data,
                            )
                    finally:
                        session.close()
                except Exception as e:
                    logger.warning(f"æ›´æ–°æ€»äº¤æ˜“æ—¥æ•°å¤±è´¥: {e}")

            # ========== é˜¶æ®µ 5: æ„å»ºå¯¹é½æ•°ç»„ ==========
            _t1 = time.perf_counter()
            aligned_arrays = self.data_preprocessor.build_aligned_arrays(
                strategy, stock_data, trading_dates
            )
            perf_breakdown["align_arrays_s"] = time.perf_counter() - _t1

            # ========== å†…å­˜ä¼˜åŒ–ï¼šé‡Šæ”¾ attrs ä¸­çš„ _precomputed_signals ==========
            # aligned_arrays å·²åŒ…å«ä¿¡å·æ•°æ®ï¼Œattrs ç¼“å­˜å¯ä»¥é‡Šæ”¾
            # ä½†ä¿ç•™ precomputed_signals å­—å…¸ä½œä¸º fallbackï¼ˆloop executor å¯èƒ½éœ€è¦ï¼‰
            import gc
            for _df in stock_data.values():
                try:
                    if hasattr(_df, 'attrs') and '_precomputed_signals' in _df.attrs:
                        del _df.attrs['_precomputed_signals']
                except Exception:
                    pass
            gc.collect()
            logger.info("âœ… å†…å­˜ä¼˜åŒ–ï¼šå·²é‡Šæ”¾ attrs é¢„è®¡ç®—ä¿¡å·ç¼“å­˜ï¼ˆä¿ç•™ precomputed_signals å­—å…¸ï¼‰")

            # ========== é˜¶æ®µ 6: æ‰§è¡Œå›æµ‹å¾ªç¯ ==========
            self.performance_tracker.start_stage(
                "backtest_execution",
                {
                    "total_trading_days": len(trading_dates),
                    "stock_count": len(stock_data),
                },
            )

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "backtest_execution", status="running"
                )

            # åˆ›å»ºä¿¡å·å†™å…¥å™¨ï¼ˆä¼˜å…ˆä½¿ç”¨ persistence æœåŠ¡ï¼‰
            _signal_writer = None
            if task_id and self._persistence is not None:
                _signal_writer = self._persistence.create_signal_writer(backtest_id)

            _t0 = time.perf_counter()
            backtest_results = await self.loop_executor.execute_backtest_loop(
                strategy=strategy,
                portfolio_manager=portfolio_manager,
                stock_data=stock_data,
                trading_dates=trading_dates,
                strategy_config=strategy_config,
                task_id=task_id,
                backtest_id=backtest_id,
                precomputed_signals=precomputed_signals,
                aligned_arrays=aligned_arrays,
                signal_writer=_signal_writer,
            )
            perf_breakdown["main_loop_s"] = time.perf_counter() - _t0

            # ========== å†…å­˜ä¼˜åŒ–ï¼šå›æµ‹å¾ªç¯ç»“æŸåé‡Šæ”¾å¤§å¯¹è±¡ ==========
            del aligned_arrays
            precomputed_signals.clear()
            # ä»…æ¸…ç©ºå†…éƒ¨åŠ è½½çš„æ•°æ®ï¼Œä¸ç ´åå¤–éƒ¨ä¼ å…¥çš„ preloaded_stock_data
            if preloaded_stock_data is None:
                stock_data.clear()
            gc.collect()

            self.performance_tracker.end_stage(
                "backtest_execution",
                {
                    "total_signals": backtest_results.get("total_signals", 0),
                    "executed_trades": backtest_results.get("executed_trades", 0),
                    "trading_days": backtest_results.get("trading_days", 0),
                },
            )
            self.performance_tracker.take_memory_snapshot("after_backtest_execution")

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "backtest_execution", progress=100, status="completed"
                )

            # ========== é˜¶æ®µ 7: è®¡ç®—ç»©æ•ˆæŒ‡æ ‡ ==========
            self.performance_tracker.start_stage("metrics_calculation")

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "metrics_calculation", status="running"
                )

            _t0 = time.perf_counter()
            performance_metrics = portfolio_manager.get_performance_metrics()
            perf_breakdown["metrics_s"] = time.perf_counter() - _t0

            self.performance_tracker.end_stage("metrics_calculation")

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "metrics_calculation", progress=100, status="completed"
                )

            # ========== é˜¶æ®µ 8: ç”Ÿæˆå›æµ‹æŠ¥å‘Š ==========
            self.performance_tracker.start_stage("report_generation")

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "report_generation", status="running"
                )

            if (
                strategy_config
                and isinstance(strategy_config, dict)
                and len(strategy_config) > 0
            ):
                logger.info(f"ç”Ÿæˆå›æµ‹æŠ¥å‘Šï¼Œç­–ç•¥é…ç½®: {strategy_config}")
            else:
                logger.warning(f"ç­–ç•¥é…ç½®ä¸ºç©ºæˆ–æ— æ•ˆ: {strategy_config}")

            _t0 = time.perf_counter()
            backtest_report = self.report_generator.generate_backtest_report(
                strategy_name=strategy_name,
                stock_codes=stock_codes,
                start_date=start_date,
                end_date=end_date,
                config=backtest_config,
                portfolio_manager=portfolio_manager,
                performance_metrics=performance_metrics,
                strategy_config=strategy_config,
            )
            # å°† backtest_id å†™å…¥æŠ¥å‘Šï¼Œä¾›ä¸‹æ¸¸ï¼ˆdependencies.pyï¼‰å¤ç”¨ï¼Œ
            # ç¡®ä¿ä¿¡å·è®°å½•ä¸äº¤æ˜“è®°å½•ç­‰ä½¿ç”¨åŒä¸€ä¸ª backtest_id
            backtest_report["backtest_id"] = backtest_id
            perf_breakdown["report_generation_s"] = time.perf_counter() - _t0

            # æ·»åŠ  backtest_id åˆ°æŠ¥å‘Šï¼ˆä¾› trade_records å†™å…¥æ—¶ä½¿ç”¨ï¼Œä¿æŒä¸ signal_records ä¸€è‡´ï¼‰
            backtest_report["backtest_id"] = backtest_id

            # æ·»åŠ å›æµ‹å¾ªç¯ç»Ÿè®¡
            backtest_report["total_signals"] = backtest_results.get("total_signals", 0)
            backtest_report["trading_days"] = backtest_results.get("trading_days", 0)

            # P0: æ·»åŠ åŠ¨æ€æŒä»“ä¿¡æ¯åˆ°æŠ¥å‘Š
            backtest_report["auto_position_sizing"] = getattr(backtest_config, 'auto_position_sizing', None)
            backtest_report["unlimited_buying"] = getattr(backtest_config, 'unlimited_buying', None)
            backtest_report["effective_max_position_size"] = getattr(portfolio_manager, 'effective_max_position_size', None)
            backtest_report["configured_max_position_size"] = backtest_config.max_position_size
            backtest_report["n_stocks"] = len(actual_stock_codes)

            # P0: æ·»åŠ ç†”æ–­ç»Ÿè®¡åˆ°æŠ¥å‘Š
            cb_summary = backtest_results.get("circuit_breaker_summary")
            if cb_summary:
                backtest_report["circuit_breaker"] = cb_summary

            self.performance_tracker.end_stage(
                "report_generation", {"report_size": len(str(backtest_report))}
            )

            if task_id:
                await self.progress_monitor.update_stage(
                    task_id, "report_generation", progress=100, status="completed"
                )
                await self.progress_monitor.update_stage(
                    task_id, "data_storage", progress=100, status="completed"
                )

            self.execution_stats["successful_backtests"] += 1
            logger.info(
                f"å›æµ‹å®Œæˆ: {strategy_name}, æ€»æ”¶ç›Š: {performance_metrics.get('total_return', 0):.2%}"
            )

            # å®Œæˆç›‘æ§
            if task_id:
                await self.progress_monitor.complete_backtest(
                    task_id,
                    {"total_return": performance_metrics.get("total_return", 0)},
                )

            # ========== é˜¶æ®µ 9: ç”Ÿæˆæ€§èƒ½æŠ¥å‘Š ==========
            self.performance_tracker.end_backtest()
            self.performance_tracker.take_memory_snapshot("backtest_end")

            # å°†æ€§èƒ½æŠ¥å‘Šæ·»åŠ åˆ°å›æµ‹æŠ¥å‘Šä¸­
            performance_report = self.performance_tracker.generate_report()
            if performance_report:
                backtest_report["performance_analysis"] = performance_report
                self.performance_tracker.print_summary()

                # ä¿å­˜æ€§èƒ½æŠ¥å‘Š
                if task_id:
                    try:
                        performance_dir = Path("backend/data/performance_reports")
                        performance_dir.mkdir(parents=True, exist_ok=True)
                        performance_file = (
                            performance_dir / f"backtest_{task_id}_performance.json"
                        )
                        self.performance_tracker.save_report(str(performance_file))
                        logger.info(f"æ€§èƒ½æŠ¥å‘Šå·²ä¿å­˜åˆ°: {performance_file}")
                    except Exception as e:
                        logger.warning(f"ä¿å­˜æ€§èƒ½æŠ¥å‘Šå¤±è´¥: {e}")

            # æ·»åŠ åˆ†æ®µè®¡æ—¶ç»“æœ
            perf_breakdown["total_wall_s"] = time.perf_counter() - _t_total0
            backtest_report["perf_breakdown"] = perf_breakdown

            return backtest_report

        except Exception as e:
            self.execution_stats["failed_backtests"] += 1
            error_msg = f"å›æµ‹æ‰§è¡Œå¤±è´¥: {str(e)}"

            # ç»“æŸæ€§èƒ½åˆ†æ
            try:
                self.performance_tracker.end_backtest()
                logger.warning("å›æµ‹å¤±è´¥ï¼Œä½†æ€§èƒ½åˆ†æå·²å®Œæˆ")
            except Exception as perf_error:
                logger.warning(f"ç»“æŸæ€§èƒ½åˆ†ææ—¶å‡ºé”™: {perf_error}")

            if task_id:
                await self.progress_monitor.set_error(task_id, error_msg)

            raise TaskError(
                message=error_msg, severity=ErrorSeverity.HIGH, original_exception=e
            )

    def validate_backtest_parameters(
        self,
        strategy_name: str,
        stock_codes: List[str],
        start_date: datetime,
        end_date: datetime,
        strategy_config: Dict[str, Any],
    ) -> Dict[str, Any]:
        """éªŒè¯å›æµ‹å‚æ•°"""
        return validate_backtest_parameters(
            strategy_name, stock_codes, start_date, end_date, strategy_config
        )

    def get_execution_statistics(self) -> Dict[str, Any]:
        """è·å–æ‰§è¡Œç»Ÿè®¡ä¿¡æ¯"""
        return get_execution_statistics(self.execution_stats)

    @staticmethod
    def _create_placeholder_backtest_result(
        task_id: str,
        backtest_id: str,
        strategy_name: str,
        start_date: datetime,
        end_date: datetime,
    ) -> None:
        """åœ¨å›æµ‹å¾ªç¯å¼€å§‹å‰ï¼Œé€šè¿‡ psycopg2 æ’å…¥ä¸€æ¡å ä½ backtest_results è¡Œã€‚

        è¿™æ ·å›æµ‹å¾ªç¯ä¸­ _flush_signals_to_db å†™å…¥ signal_records æ—¶ï¼Œ
        å¤–é”®çº¦æŸ (signal_records.backtest_id â†’ backtest_results.backtest_id) ä¸ä¼šå¤±è´¥ã€‚
        å›æµ‹ç»“æŸå dependencies.py ä¼š UPDATE è¿™è¡Œå¡«å…¥å®Œæ•´æ•°æ®ã€‚
        """
        import psycopg2

        from app.core.config import settings

        sql = """
            INSERT INTO backtest_results
                (task_id, backtest_id, strategy_name, start_date, end_date,
                 initial_cash, final_value, total_return, annualized_return,
                 volatility, sharpe_ratio, max_drawdown, win_rate,
                 profit_factor, total_trades)
            VALUES (%s, %s, %s, %s, %s,
                    %s, %s, %s, %s,
                    %s, %s, %s, %s,
                    %s, %s)
            ON CONFLICT (backtest_id) DO NOTHING
        """
        try:
            conn = psycopg2.connect(settings.database_url_sync)
            try:
                cur = conn.cursor()
                cur.execute(sql, (
                    task_id, backtest_id, strategy_name,
                    start_date.isoformat(), end_date.isoformat(),
                    0, 0, 0, 0,   # initial_cash, final_value, total_return, annualized_return
                    0, 0, 0, 0,   # volatility, sharpe_ratio, max_drawdown, win_rate
                    0, 0,         # profit_factor, total_trades
                ))
                conn.commit()
                cur.close()
                logger.info(f"å ä½ backtest_results è¡Œå·²åˆ›å»º: backtest_id={backtest_id}")
            finally:
                conn.close()
        except Exception as e:
            logger.warning(f"åˆ›å»ºå ä½ backtest_results è¡Œå¤±è´¥ï¼ˆä¿¡å·å†™å…¥å¯èƒ½å—å½±å“ï¼‰: {e}")

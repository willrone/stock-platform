"""
å›æµ‹å¾ªç¯æ‰§è¡Œæ¨¡å—
è´Ÿè´£æ ¸å¿ƒå›æµ‹å¾ªç¯çš„æ‰§è¡Œ
"""

import time
import uuid
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from loguru import logger

from app.core.error_handler import ErrorSeverity, TaskError

from ..core.base_strategy import BaseStrategy
from ..core.portfolio_manager import PortfolioManager
from ..core.risk_manager import PositionPriceInfo, RiskManager
from ..models import SignalType, TradingSignal

# å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
# from .backtest_progress_monitor import backtest_progress_monitor


def _check_and_execute_stop_loss_take_profit(
    risk_manager: RiskManager,
    portfolio_manager: PortfolioManager,
    current_prices: Dict[str, float],
    current_date: datetime,
) -> int:
    """
    æ£€æŸ¥å¹¶æ‰§è¡Œæ­¢æŸæ­¢ç›ˆä¿¡å·ï¼ˆä¼˜å…ˆçº§é«˜äºç­–ç•¥ä¿¡å·ï¼‰

    Returns:
        æ‰§è¡Œçš„äº¤æ˜“æ•°é‡
    """
    # æ„å»ºæŒä»“ä»·æ ¼ä¿¡æ¯
    positions = portfolio_manager.positions
    if not positions:
        return 0

    positions_info: Dict[str, PositionPriceInfo] = {}
    for code, pos in positions.items():
        price = current_prices.get(code)
        if price is not None and price > 0:
            positions_info[code] = PositionPriceInfo(
                stock_code=code,
                quantity=pos.quantity,
                avg_cost=pos.avg_cost,
                current_price=price,
                timestamp=current_date,
            )

    sl_tp_signals = risk_manager.check_stop_loss_take_profit(positions_info)
    if not sl_tp_signals:
        return 0

    trades_count = 0
    for signal in sl_tp_signals:
        trade, _ = portfolio_manager.execute_signal(signal, current_prices)
        if trade:
            trades_count += 1

    return trades_count


class BacktestLoopExecutor:
    """å›æµ‹å¾ªç¯æ‰§è¡Œå™¨"""

    def __init__(self):
        """åˆå§‹åŒ–å›æµ‹å¾ªç¯æ‰§è¡Œå™¨"""
        self.enable_performance_profiling = False
        self.performance_profiler = None

    async def execute_backtest_loop(
        self,
        strategy: BaseStrategy,
        portfolio_manager: PortfolioManager,
        stock_data: Dict[str, pd.DataFrame],
        trading_dates: List[datetime],
        strategy_config: Optional[Dict[str, Any]] = None,
        task_id: str = None,
        backtest_id: str = None,
        precomputed_signals: Optional[Dict[Tuple[str, datetime], Any]] = None,
        aligned_arrays: Optional[Dict[str, Any]] = None,
        signal_writer=None,
    ) -> Dict[str, Any]:
        """æ‰§è¡Œå›æµ‹ä¸»å¾ªç¯"""
        # å»¶è¿Ÿå¯¼å…¥ä»¥é¿å…å¾ªç¯ä¾èµ–
        from .backtest_progress_monitor import backtest_progress_monitor

        total_signals = 0
        executed_trades = 0

        # P0: åˆå§‹åŒ–é£é™©ç®¡ç†å™¨ï¼ˆæ­¢æŸæ­¢ç›ˆ + æœ€å¤§å›æ’¤ç†”æ–­ï¼‰
        risk_manager = RiskManager(portfolio_manager.config)

        # æ€§èƒ½ç»Ÿè®¡ï¼šä¿¡å·ç”Ÿæˆæ—¶é—´
        signal_generation_times = []
        trade_execution_times = []

        # è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥ä»»åŠ¡çŠ¶æ€
        def _is_task_running(status) -> bool:
            if status is None:
                return False
            # æ”¯æŒå­—ç¬¦ä¸²æˆ–Enum
            try:
                return (
                    status == TaskStatus.RUNNING or status == TaskStatus.RUNNING.value
                )
            except Exception:
                return status == TaskStatus.RUNNING.value

        def check_task_status():
            """æ£€æŸ¥ä»»åŠ¡æ˜¯å¦ä»ç„¶å­˜åœ¨ä¸”å¤„äºè¿è¡ŒçŠ¶æ€"""
            if not task_id:
                return True
            try:
                from app.core.database import SessionLocal
                from app.repositories.task_repository import TaskRepository

                session = SessionLocal()
                try:
                    task_repo = TaskRepository(session)
                    task = task_repo.get_task_by_id(task_id)
                    if not task:
                        logger.warning(f"ä»»åŠ¡ä¸å­˜åœ¨ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ: {task_id}")
                        return False
                    if not _is_task_running(task.status):
                        logger.warning(f"ä»»åŠ¡çŠ¶æ€ä¸º {task.status}ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ: {task_id}")
                        return False
                    return True
                finally:
                    session.close()
            except Exception as e:
                logger.warning(f"æ£€æŸ¥ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}ï¼Œç»§ç»­æ‰§è¡Œ")
                return True  # æ£€æŸ¥å¤±è´¥æ—¶ç»§ç»­æ‰§è¡Œï¼Œé¿å…å› æ£€æŸ¥é”™è¯¯è€Œä¸­æ–­

        # ========== PERFä¼˜åŒ–ï¼šæ‰¹é‡æ”¶é›†æ•°æ®åº“æ“ä½œï¼Œåˆ†æ‰¹å†™å…¥ ==========
        # é¿å…åœ¨730å¤©å¾ªç¯å†…æ¯å¤©éƒ½åšæ•°æ®åº“æ“ä½œï¼ˆåŸæ¥æ˜¯72ç§’çš„ä¸»è¦ç“¶é¢ˆï¼‰
        # å†…å­˜ä¼˜åŒ–ï¼šæ¯ç§¯ç´¯ _SIGNAL_FLUSH_THRESHOLD æ¡ä¿¡å·å°±å†™å…¥ä¸€æ¬¡DBå¹¶é‡Šæ”¾å†…å­˜
        _batch_signals_data: List[dict] = []  # æ”¶é›†ä¿¡å·è®°å½•ï¼ˆå« executed/execution_reasonï¼‰
        _current_backtest_id: str | None = None  # ç¼“å­˜ backtest_id
        _SIGNAL_FLUSH_THRESHOLD = 3000  # æ¯ 3000 æ¡ä¿¡å·åˆ·ä¸€æ¬¡DBï¼ˆå†…å­˜ä¼˜åŒ–ï¼‰
        _total_flushed_signals = 0  # å·²åˆ·å…¥DBçš„ä¿¡å·æ€»æ•°
        # ========== END PERFä¼˜åŒ– ==========

        for i, current_date in enumerate(trading_dates):
            # PERF/BUGFIX: ç»Ÿä¸€åˆå§‹åŒ–è®¡æ—¶å˜é‡ï¼Œé¿å…æŸäº›åˆ†æ”¯/å¼‚å¸¸è·¯å¾„å¼•ç”¨æœªèµ‹å€¼å¯¼è‡´ UnboundLocalError
            slice_time_total = 0.0
            gen_time_total = 0.0
            gen_time_max = 0.0

            # åœ¨å¾ªç¯å¼€å§‹æ—¶æ£€æŸ¥ä»»åŠ¡çŠ¶æ€ï¼ˆæ¯10ä¸ªäº¤æ˜“æ—¥æ£€æŸ¥ä¸€æ¬¡ï¼Œé¿å…é¢‘ç¹æ£€æŸ¥ï¼‰
            if task_id and i % 10 == 0 and i > 0:
                if not check_task_status():
                    logger.info(f"ä»»åŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ: {task_id}")
                    raise TaskError(
                        message=f"ä»»åŠ¡ {task_id} å·²è¢«åˆ é™¤æˆ–çŠ¶æ€å·²æ”¹å˜ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ",
                        severity=ErrorSeverity.LOW,
                    )
            try:
                # è·å–å½“å‰ä»·æ ¼ï¼ˆPhase3ï¼šä½¿ç”¨å‘é‡åŒ–ä¼˜åŒ–ï¼‰
                current_prices: Dict[str, float] = {}

                if aligned_arrays is not None:
                    # Phase 3 ä¼˜åŒ–ï¼šä½¿ç”¨å‘é‡åŒ–ä»·æ ¼æŸ¥æ‰¾
                    from .vectorized_loop import get_portfolio_stocks

                    codes = aligned_arrays.get("stock_codes")
                    code_to_i = aligned_arrays.get("code_to_i")
                    close_mat = aligned_arrays.get("close")
                    valid_mat = aligned_arrays.get("valid")
                    sig_mat = aligned_arrays.get("signal")

                    # ä¼˜åŒ– #5ï¼šç¼“å­˜ portfolio stocks setï¼Œé¿å…é‡å¤è°ƒç”¨
                    portfolio_stocks = set(get_portfolio_stocks(portfolio_manager))
                    need_codes = portfolio_stocks.copy()

                    if isinstance(sig_mat, np.ndarray):
                        # ä¼˜åŒ– #5ï¼šä½¿ç”¨å‘é‡åŒ–æ“ä½œè·å–æœ‰ä¿¡å·çš„è‚¡ç¥¨
                        sig_idx = np.nonzero(sig_mat[:, i])[0]
                        if len(sig_idx) > 0:
                            need_codes.update(codes[j] for j in sig_idx)

                    # BUGFIX: å¦‚æœæ²¡æœ‰é¢„è®¡ç®—ä¿¡å·ä¸”æŒä»“ä¸ºç©ºï¼Œéœ€è¦ä¸ºæ‰€æœ‰è‚¡ç¥¨è·å–ä»·æ ¼
                    # å¦åˆ™æ— æ³•ç”Ÿæˆä¿¡å·ï¼ˆå› ä¸º generate_signals éœ€è¦å½“å‰ä»·æ ¼ï¼‰
                    if not need_codes:
                        need_codes = set(codes)

                    if need_codes:
                        # æ‰¹é‡æŸ¥æ‰¾ä»·æ ¼ï¼ˆå‘é‡åŒ–ï¼‰
                        for c in need_codes:
                            j = (
                                code_to_i.get(c)
                                if isinstance(code_to_i, dict)
                                else None
                            )
                            if j is not None and bool(valid_mat[j, i]):
                                current_prices[c] = float(close_mat[j, i])

                    # BUGFIX: å¯¹äºæŒä»“è‚¡ç¥¨ï¼Œå¦‚æœå½“å¤© valid_mat ä¸º Falseï¼ˆåœç‰Œç­‰ï¼‰ï¼Œ
                    # ä½¿ç”¨æœ€è¿‘ä¸€ä¸ªæœ‰æ•ˆäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·ï¼Œé¿å…æŒä»“å¸‚å€¼è¢«è®¡ä¸º0å¯¼è‡´
                    # ç»„åˆä»·å€¼å‰§çƒˆè·³å˜ï¼Œä»è€Œä¸¥é‡æ”¾å¤§æ³¢åŠ¨ç‡ï¼ˆ80-130% â†’ æ­£å¸¸åº”<30%ï¼‰
                    for c in portfolio_stocks:
                        if c not in current_prices:
                            j = (
                                code_to_i.get(c)
                                if isinstance(code_to_i, dict)
                                else None
                            )
                            if j is not None:
                                # å‘å‰æœç´¢æœ€è¿‘çš„æœ‰æ•ˆä»·æ ¼
                                for k in range(i - 1, -1, -1):
                                    if bool(valid_mat[j, k]):
                                        current_prices[c] = float(close_mat[j, k])
                                        break

                else:
                    # [ä¼˜åŒ– 1] é¿å… DataFrame æ‹·è´ï¼šä½¿ç”¨ .values å’Œç¼“å­˜çš„ç´¢å¼•
                    for stock_code, data in stock_data.items():
                        try:
                            # ä¼˜å…ˆä½¿ç”¨ç¼“å­˜çš„ date_to_idx æ˜ å°„
                            date_to_idx = data.attrs.get("_date_to_idx")
                            if date_to_idx is not None and current_date in date_to_idx:
                                idx = date_to_idx[current_date]
                                # ä½¿ç”¨ .values ç›´æ¥è®¿é—®åº•å±‚æ•°ç»„
                                current_prices[stock_code] = float(
                                    data["close"].values[idx]
                                )
                            elif current_date in data.index:
                                # Fallback: ä½¿ç”¨ ilocï¼ˆæ¯” loc å¿«ï¼‰
                                idx = data.index.get_loc(current_date)
                                current_prices[stock_code] = float(
                                    data["close"].values[idx]
                                )
                        except Exception:
                            pass

                    # BUGFIX: å¯¹äºæŒä»“è‚¡ç¥¨ï¼Œå¦‚æœå½“å¤©æ²¡æœ‰æ•°æ®ï¼ˆåœç‰Œç­‰ï¼‰ï¼Œ
                    # ä½¿ç”¨æœ€è¿‘ä¸€ä¸ªæœ‰æ•ˆäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·ï¼Œé¿å…æŒä»“å¸‚å€¼è¢«è®¡ä¸º0
                    if hasattr(portfolio_manager, 'positions'):
                        for stock_code in list(portfolio_manager.positions.keys()):
                            if stock_code not in current_prices:
                                data = stock_data.get(stock_code)
                                if data is not None and len(data) > 0:
                                    # æ‰¾åˆ° current_date ä¹‹å‰æœ€è¿‘çš„æœ‰æ•ˆä»·æ ¼
                                    valid_dates = data.index[data.index <= current_date]
                                    if len(valid_dates) > 0:
                                        last_valid_idx = len(valid_dates) - 1
                                        current_prices[stock_code] = float(
                                            data["close"].values[last_valid_idx]
                                        )

                if not current_prices:
                    continue

                # [P2 ä¼˜åŒ–] æ‰¹é‡è®¾ç½®å½“å‰ä»·æ ¼åˆ°æ•°ç»„ï¼Œåç»­çš„ get_portfolio_value ç­‰æ–¹æ³•
                # å¯ä»¥ç›´æ¥ä½¿ç”¨å‘é‡åŒ–è®¡ç®—ï¼Œé¿å…é‡å¤çš„å­—å…¸æŸ¥æ‰¾
                if hasattr(portfolio_manager, "set_current_prices"):
                    portfolio_manager.set_current_prices(current_prices)

                # ===== P0: æ­¢æŸæ­¢ç›ˆæ£€æŸ¥ï¼ˆä¼˜å…ˆçº§é«˜äºç­–ç•¥ä¿¡å·ï¼‰ =====
                sl_tp_signals = _check_and_execute_stop_loss_take_profit(
                    risk_manager,
                    portfolio_manager,
                    current_prices,
                    current_date,
                )
                executed_trades += sl_tp_signals

                # ===== P0: æœ€å¤§å›æ’¤ç†”æ–­æ›´æ–° =====
                portfolio_value_for_cb = portfolio_manager.get_portfolio_value(
                    current_prices
                )
                risk_manager.update_circuit_breaker(
                    portfolio_value_for_cb,
                    current_date,
                )

                # ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼ˆPhase1ï¼šä¼˜å…ˆç”¨ ndarray signal matrixï¼‰
                all_signals: List[TradingSignal] = []

                if aligned_arrays is not None:
                    sig_mat = aligned_arrays.get("signal")
                    codes = aligned_arrays.get("stock_codes")
                    close_mat = aligned_arrays.get("close")
                    valid_mat = aligned_arrays.get("valid")
                    strength_mat = aligned_arrays.get("strength")
                    if isinstance(sig_mat, np.ndarray):
                        sig_idx = np.nonzero(sig_mat[:, i])[0]
                        if sig_idx.size > 0:
                            for j in sig_idx.tolist():
                                if not bool(valid_mat[j, i]):
                                    continue
                                st = int(sig_mat[j, i])
                                if st == 1:
                                    stype = SignalType.BUY
                                elif st == -1:
                                    stype = SignalType.SELL
                                else:
                                    continue
                                code = codes[j]
                                price = float(close_mat[j, i])
                                sig_strength = (
                                    float(strength_mat[j, i])
                                    if strength_mat is not None
                                    and strength_mat[j, i] > 0
                                    else 1.0
                                )
                                all_signals.append(
                                    TradingSignal(
                                        timestamp=current_date,
                                        stock_code=code,
                                        signal_type=stype,
                                        strength=sig_strength,
                                        price=price,
                                        reason="[aligned] precomputed",
                                        metadata=None,
                                    )
                                )

                # è‹¥å¯¹é½æ•°ç»„å·²ç”Ÿæˆä¿¡å·ï¼Œè·³è¿‡é€è‚¡ç¥¨å›é€€è·¯å¾„
                _skip_per_stock_fallback = len(all_signals) > 0

                if not all_signals:
                    # ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼ˆæ”¯æŒå¹¶è¡Œç”Ÿæˆå¤šè‚¡ç¥¨ä¿¡å·ï¼‰
                    all_signals = []

                # æ€§èƒ½ç›‘æ§ï¼šè®°å½•ä¿¡å·ç”Ÿæˆæ—¶é—´
                signal_start_time = (
                    time.perf_counter() if self.enable_performance_profiling else None
                )

                # ï¿½ï¿½åˆ† profilingï¼šæŠŠ"åˆ‡ç‰‡"å’Œ"ç”Ÿæˆä¿¡å·"æ‹†å¼€è®¡æ—¶ï¼ˆå˜é‡å·²åœ¨å¾ªç¯å¼€å¤´åˆå§‹åŒ–ï¼‰

                # è¾…åŠ©å‡½æ•°ï¼šå¿«é€ŸæŸ¥æ‰¾é¢„è®¡ç®—ä¿¡å·
                def get_precomputed_signal_fast(stock_code: str, date: datetime):
                    """
                    [ä¼˜åŒ– 1] ä»é¢„è®¡ç®—å­—å…¸ä¸­å¿«é€ŸæŸ¥æ‰¾ä¿¡å·ï¼Œé¿å… DataFrame æ‹·è´

                    ä¼˜åŒ–ç‚¹ï¼š
                    1. ä¼˜å…ˆä½¿ç”¨ aligned_arrays çš„ numpy æ•°ç»„ï¼ˆO(1) æŸ¥æ‰¾ï¼‰
                    2. ä½¿ç”¨ .values ç›´æ¥è®¿é—®åº•å±‚æ•°ç»„ï¼Œé¿å…åˆ›å»º Series å¯¹è±¡
                    3. ç¼“å­˜ date_to_idx æ˜ å°„ï¼Œé¿å…é‡å¤ get_loc() è°ƒç”¨
                    """
                    if precomputed_signals:
                        signal = precomputed_signals.get((stock_code, date))
                        if signal is not None:
                            # å°†ä¿¡å·ç±»å‹è½¬æ¢ä¸º TradingSignal å¯¹è±¡
                            if isinstance(signal, SignalType):
                                # [ä¼˜åŒ– 1] è·å–å½“å‰ä»·æ ¼ - é¿å… DataFrame æ‹·è´
                                current_price = 0.0
                                sig_strength = 1.0

                                try:
                                    # æ–¹æ³• 1: ä¼˜å…ˆä½¿ç”¨ aligned_arraysï¼ˆæœ€å¿«ï¼ŒO(1) æŸ¥æ‰¾ï¼‰
                                    if aligned_arrays is not None:
                                        code_to_i = aligned_arrays.get("code_to_i")
                                        close_mat = aligned_arrays.get("close")
                                        dates = aligned_arrays.get("dates")
                                        _strength_mat = aligned_arrays.get("strength")

                                        if (
                                            code_to_i is not None
                                            and close_mat is not None
                                            and dates is not None
                                        ):
                                            stock_idx = code_to_i.get(stock_code)
                                            if stock_idx is not None:
                                                # [P1 ä¼˜åŒ–] ä½¿ç”¨ O(1) å­—å…¸æŸ¥æ‰¾æ›¿ä»£ O(n) çš„ np.where
                                                date_to_i = aligned_arrays.get(
                                                    "date_to_i"
                                                )
                                                date_idx = (
                                                    date_to_i.get(date)
                                                    if date_to_i
                                                    else None
                                                )

                                                if date_idx is not None:
                                                    # ç›´æ¥ä» numpy æ•°ç»„è¯»å–ï¼Œæ—  pandas å¼€é”€
                                                    price_val = close_mat[
                                                        stock_idx, date_idx
                                                    ]
                                                    if not np.isnan(price_val):
                                                        current_price = float(price_val)
                                                    # è¯»å–ä¿¡å·å¼ºåº¦
                                                    if (
                                                        _strength_mat is not None
                                                        and _strength_mat[
                                                            stock_idx, date_idx
                                                        ]
                                                        > 0
                                                    ):
                                                        sig_strength = float(
                                                            _strength_mat[
                                                                stock_idx, date_idx
                                                            ]
                                                        )

                                    # æ–¹æ³• 2: å¦‚æœ aligned_arrays ä¸å¯ç”¨ï¼Œä½¿ç”¨ä¼˜åŒ–çš„ DataFrame è®¿é—®
                                    if current_price == 0.0:
                                        data = stock_data.get(stock_code)
                                        if data is not None:
                                            # ä½¿ç”¨ç¼“å­˜çš„ date_to_idx æ˜ å°„ï¼ˆé¿å…é‡å¤ get_locï¼‰
                                            date_to_idx = data.attrs.get("_date_to_idx")
                                            if (
                                                date_to_idx is not None
                                                and date in date_to_idx
                                            ):
                                                idx = date_to_idx[date]
                                                # ä½¿ç”¨ .values ç›´æ¥è®¿é—®åº•å±‚æ•°ç»„ï¼Œé¿å…åˆ›å»º Series
                                                close_values = data["close"].values
                                                current_price = float(close_values[idx])
                                            elif date in data.index:
                                                # Fallback: ä½¿ç”¨ ilocï¼ˆæ¯” loc å¿«ï¼Œä½†ä»ä¼šè§¦å‘ä¸€äº›å¼€é”€ï¼‰
                                                idx = data.index.get_loc(date)
                                                current_price = float(
                                                    data["close"].values[idx]
                                                )

                                except Exception:
                                    # é™é»˜å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä»·æ ¼ 0.0
                                    pass

                                return [
                                    TradingSignal(
                                        signal_type=signal,
                                        stock_code=stock_code,
                                        timestamp=date,
                                        price=current_price,
                                        strength=sig_strength,
                                        reason="Precomputed signal",
                                    )
                                ]
                            return [signal] if not isinstance(signal, list) else signal
                    return None

                # PERF OPTIMIZATION: ç¦ç”¨per-dayå¹¶è¡Œï¼Œå› ä¸ºä¿¡å·å·²ç»é¢„è®¡ç®—ï¼Œä¸²è¡Œæ›´å¿«
                if _skip_per_stock_fallback:
                    pass  # aligned_arrays å·²ç”Ÿæˆä¿¡å·ï¼Œè·³è¿‡é€è‚¡ç¥¨å›é€€
                elif False and self.enable_parallel and len(stock_data) > 3:
                    # å¹¶è¡Œç”Ÿæˆå¤šè‚¡ç¥¨ä¿¡å·
                    # PERF: avoid per-day ThreadPoolExecutor creation and avoid per-stock futures.
                    # We batch stocks into coarse tasks to reduce scheduling overhead.

                    # PERF: switch from "per-day submit many tasks" to "persistent workers".
                    # This dramatically reduces thread scheduling overhead when stock_count is large.
                    import threading

                    # Initialize worker context once (first trading day)
                    if (
                        not hasattr(self, "_signal_worker_ctx")
                        or self._signal_worker_ctx is None
                    ):
                        items = list(stock_data.items())

                        # Greedy balance chunks by estimated per-stock compute cost.
                        # Cost proxy: number of trading days the stock participates (after warmup) with
                        # a small penalty for missing days.
                        scored = []
                        total_days = len(trading_dates) if trading_dates else 0

                        for code, df in items:
                            try:
                                # count how many trading_dates exist in this df
                                # (O(T) per stock; ok for init and much better load balance than len(df))
                                avail = df.index
                                avail_days = 0
                                for _d in trading_dates:
                                    if _d in avail:
                                        avail_days += 1
                                missing_ratio = (
                                    1.0 - (avail_days / total_days)
                                    if total_days > 0
                                    else 0.0
                                )
                                # warmup skip (executor only calls strategy when idx>=20)
                                effective_days = max(0, avail_days - 20)
                                cost = float(effective_days) * (
                                    1.0 + 0.10 * missing_ratio
                                )
                                scored.append((cost, code, df))
                            except Exception:
                                scored.append((0.0, code, df))

                        scored.sort(reverse=True)

                        worker_n = max(1, int(self.max_workers or 1))
                        buckets = [
                            ([], 0.0) for _ in range(worker_n)
                        ]  # ([(code,df)], total_cost)
                        for cost, code, df in scored:
                            # pick bucket with smallest total_cost
                            bi = min(range(worker_n), key=lambda x: buckets[x][1])
                            buckets[bi][0].append((code, df))
                            buckets[bi] = (buckets[bi][0], buckets[bi][1] + float(cost))

                        chunks: List[List[Tuple[str, pd.DataFrame]]] = [
                            b[0] for b in buckets
                        ]

                        shared = {"date": None, "error": None}
                        results: List[
                            Tuple[List[TradingSignal], float, float, float]
                        ] = [([], 0.0, 0.0, 0.0) for _ in range(worker_n)]

                        barrier_start = threading.Barrier(worker_n + 1)
                        barrier_end = threading.Barrier(worker_n + 1)

                        def _worker(idx: int):
                            nonlocal chunks, shared, results
                            while True:
                                try:
                                    barrier_start.wait()
                                except Exception:
                                    return

                                cd = shared.get("date")
                                if cd is None:
                                    # shutdown signal
                                    try:
                                        barrier_end.wait()
                                    except Exception:
                                        pass
                                    return

                                batch_signals: List[TradingSignal] = []
                                slice_sum = 0.0
                                gen_sum = 0.0
                                gen_max = 0.0

                                try:
                                    for stock_code, data in chunks[idx]:
                                        if cd not in data.index:
                                            continue

                                        t0 = time.perf_counter()
                                        idx_map = None
                                        try:
                                            idx_map = data.attrs.get("_date_to_idx")
                                        except Exception:
                                            idx_map = None
                                        current_idx = (
                                            int(idx_map.get(cd))
                                            if isinstance(idx_map, dict)
                                            and cd in idx_map
                                            else int(data.index.get_loc(cd))
                                        )
                                        try:
                                            data.attrs["_current_date"] = cd
                                            data.attrs["_current_idx"] = current_idx
                                        except Exception:
                                            pass
                                        slice_dur = time.perf_counter() - t0
                                        slice_sum += float(slice_dur)

                                        if current_idx < 20:
                                            continue

                                        t1 = time.perf_counter()
                                        # ä¼˜å…ˆä½¿ç”¨é¢„è®¡ç®—ä¿¡å·
                                        sigs = get_precomputed_signal_fast(
                                            stock_code, cd
                                        )
                                        if sigs is None:
                                            # Fallback: è°ƒç”¨ç­–ç•¥ç”Ÿæˆ
                                            sigs = strategy.generate_signals(data, cd)
                                        gen_dur = time.perf_counter() - t1
                                        gen_sum += float(gen_dur)
                                        if gen_dur > gen_max:
                                            gen_max = float(gen_dur)

                                        if sigs:
                                            try:
                                                md = getattr(sigs[0], "metadata", None)
                                                if md is None:
                                                    sigs[0].metadata = {}
                                                    md = sigs[0].metadata
                                                if isinstance(md, dict):
                                                    md["_perf"] = {
                                                        "gen_wall": float(gen_dur),
                                                        "slice_wall": float(slice_dur),
                                                    }
                                            except Exception:
                                                pass

                                        batch_signals.extend(sigs)

                                    results[idx] = (
                                        batch_signals,
                                        slice_sum,
                                        gen_sum,
                                        gen_max,
                                    )
                                except Exception as e:
                                    shared["error"] = e
                                    results[idx] = ([], slice_sum, gen_sum, gen_max)

                                try:
                                    barrier_end.wait()
                                except Exception:
                                    return

                        threads = []
                        for wi in range(worker_n):
                            t = threading.Thread(
                                target=_worker, args=(wi,), daemon=True
                            )
                            t.start()
                            threads.append(t)

                        self._signal_worker_ctx = {
                            "worker_n": worker_n,
                            "shared": shared,
                            "results": results,
                            "barrier_start": barrier_start,
                            "barrier_end": barrier_end,
                            "threads": threads,
                        }

                    ctx = self._signal_worker_ctx

                    sequential_start = (
                        time.perf_counter()
                        if self.enable_performance_profiling
                        else None
                    )

                    gen_time_max = 0.0

                    # Broadcast date to workers and collect
                    ctx["shared"]["date"] = current_date
                    ctx["shared"]["error"] = None

                    try:
                        ctx["barrier_start"].wait()
                        ctx["barrier_end"].wait()
                    except Exception as e:
                        logger.error(f"å¹¶è¡Œç”Ÿæˆä¿¡å·åŒæ­¥å¤±è´¥: {e}")

                    err = ctx["shared"].get("error")
                    if err is not None:
                        raise err

                    for signals, slice_sum, gen_sum, gen_max in ctx["results"]:
                        all_signals.extend(signals)
                        slice_time_total += float(slice_sum)
                        gen_time_total += float(gen_sum)
                        if gen_max and gen_max > gen_time_max:
                            gen_time_max = float(gen_max)

                    # è®°å½•å¹¶è¡ŒåŒ–æ•ˆç‡ï¼ˆä¼°ç®—é¡ºåºæ‰§è¡Œæ—¶é—´ï¼‰
                    if self.enable_performance_profiling and sequential_start:
                        parallel_time = time.perf_counter() - sequential_start
                        estimated_sequential_time = (
                            parallel_time * len(stock_data) / max(1, self.max_workers)
                        )
                        if i == 0:
                            self.performance_profiler.record_parallel_efficiency(
                                operation_name="signal_generation",
                                sequential_time=estimated_sequential_time,
                                parallel_time=parallel_time,
                                worker_count=self.max_workers,
                            )
                else:
                    gen_time_max = 0.0
                    # é¡ºåºç”Ÿæˆä¿¡å·ï¼ˆè‚¡ç¥¨æ•°é‡å°‘æˆ–ç¦ç”¨å¹¶è¡Œï¼‰
                    for stock_code, data in stock_data.items():
                        if current_date in data.index:
                            # è·å–åˆ°å½“å‰æ—¥æœŸçš„å†å²æ•°æ®
                            t0 = time.perf_counter()
                            # same rationale as parallel path: avoid daily slicing copies
                            idx_map = None
                            try:
                                idx_map = data.attrs.get("_date_to_idx")
                            except Exception:
                                idx_map = None
                            current_idx = (
                                int(idx_map.get(current_date))
                                if isinstance(idx_map, dict) and current_date in idx_map
                                else int(data.index.get_loc(current_date))
                                if current_date in data.index
                                else -1
                            )
                            # Provide fast-path hint for strategies (avoid repeated get_loc)
                            try:
                                data.attrs["_current_date"] = current_date
                                data.attrs["_current_idx"] = current_idx
                            except Exception:
                                pass
                            slice_time_total += time.perf_counter() - t0

                            if current_idx >= 20:
                                try:
                                    t1 = time.perf_counter()
                                    # ä¼˜å…ˆä½¿ç”¨é¢„è®¡ç®—ä¿¡å·
                                    signals = get_precomputed_signal_fast(
                                        stock_code, current_date
                                    )

                                    # è°ƒè¯•æ—¥å¿—
                                    if current_idx == 20:  # åªåœ¨ç¬¬ä¸€æ¬¡æ‰“å°
                                        logger.info(
                                            f"ğŸ” è°ƒè¯•: stock={stock_code}, date={current_date}, precomputed_signals={'æœ‰' if signals is not None else 'æ— '}"
                                        )

                                    if signals is None:
                                        # Fallback: è°ƒç”¨ç­–ç•¥ç”Ÿæˆ
                                        signals = strategy.generate_signals(
                                            data, current_date
                                        )

                                    # è°ƒè¯•æ—¥å¿—ï¼šè®°å½•ä¿¡å·å†…å®¹
                                    if signals is not None and current_idx == 20:
                                        logger.info(f"ğŸ” ä¿¡å·å†…å®¹: {signals}")

                                    _dur = time.perf_counter() - t1
                                    gen_time_total += _dur
                                    if _dur > gen_time_max:
                                        gen_time_max = float(_dur)
                                    all_signals.extend(signals)
                                except Exception as e:
                                    import traceback as _tb

                                    logger.warning(
                                        f"ç”Ÿæˆä¿¡å·å¤±è´¥ {stock_code}: {e}\n{_tb.format_exc()}"
                                    )
                                    continue

                # è®°å½•ä¿¡å·ç”Ÿæˆæ—¶é—´
                if (
                    self.enable_performance_profiling
                    and signal_start_time
                    and self.performance_profiler
                ):
                    signal_duration = time.perf_counter() - signal_start_time
                    signal_generation_times.append(signal_duration)

                    # åŸæœ‰å£å¾„ï¼šæ•´æ®µä¿¡å·ç”Ÿæˆï¼ˆå«åˆ‡ç‰‡ã€è®¡ç®—æŒ‡æ ‡ã€èåˆç­‰ï¼‰
                    self.performance_profiler.record_function_call(
                        "generate_signals", signal_duration
                    )

                    # æ–°å£å¾„ï¼šæ‹†å¼€çœ‹"åˆ‡ç‰‡"ä¸"ç­–ç•¥ä¿¡å·ç”Ÿæˆ"çš„æ¯”ä¾‹
                    # æ³¨æ„ï¼šå¹¶è¡Œæ¨¡å¼ä¸‹ slice_time_total / gen_time_total æ˜¯"å„çº¿ç¨‹è€—æ—¶æ±‚å’Œ"(work)ï¼Œ
                    # ä¸æ˜¯ wall-clockï¼›ç”¨äºåˆ¤æ–­ CPU work æ„æˆï¼Œä½†ä¸èƒ½ç›´æ¥å½“æˆæ•´ä½“è€—æ—¶ç™¾åˆ†æ¯”ã€‚
                    if slice_time_total > 0:
                        self.performance_profiler.record_function_call(
                            "slice_historical_data_work", float(slice_time_total)
                        )
                    if gen_time_total > 0:
                        self.performance_profiler.record_function_call(
                            "generate_signals_core_work", float(gen_time_total)
                        )

                    # é¢å¤–è®°å½• wall-clock å£å¾„ï¼ˆåŒ generate_signalsï¼Œä½†åå­—æ›´æ˜ç¡®ï¼Œä¾¿äºæŠ¥è¡¨é˜…è¯»ï¼‰
                    self.performance_profiler.record_function_call(
                        "generate_signals_wall", signal_duration
                    )

                    # å¹¶è¡Œè·¯å¾„ä¸‹ critical path è¿‘ä¼¼ï¼šå•æ—¥æœ€æ…¢è‚¡ç¥¨çš„ generate_signals wall
                    if gen_time_max > 0:
                        self.performance_profiler.record_function_call(
                            "generate_signals_core_wall_max", float(gen_time_max)
                        )

                        # çº¿ç¨‹/è°ƒåº¦å¼€é”€ï¼ˆç²—ç•¥ï¼‰ï¼šæ•´æ®µ wall - å•æ—¥æœ€æ…¢å•è‚¡ wall
                        overhead = float(signal_duration) - float(gen_time_max)
                        if overhead > 0:
                            self.performance_profiler.record_function_call(
                                "signal_generation_overhead_wall", overhead
                            )

                    # If StrategyPortfolio attached per-strategy timings, record them once per day.
                    try:
                        perf_sig = None
                        for _s in all_signals:
                            md = getattr(_s, "metadata", None) or {}
                            if isinstance(md, dict) and "portfolio_perf" in md:
                                perf_sig = _s
                                break
                        if perf_sig is not None:
                            md = perf_sig.metadata or {}
                            pp = (
                                md.get("portfolio_perf")
                                if isinstance(md, dict)
                                else None
                            )
                            if isinstance(pp, dict):
                                sub = pp.get("sub_strategy_times")
                                if isinstance(sub, dict):
                                    for k, v in sub.items():
                                        self.performance_profiler.record_function_call(
                                            f"portfolio_substrategy__{k}", float(v)
                                        )
                                it = pp.get("integrate_time")
                                if it is not None:
                                    self.performance_profiler.record_function_call(
                                        "portfolio_integrate", float(it)
                                    )
                    except Exception:
                        pass

                total_signals += len(all_signals)

                # PERFä¼˜åŒ–ï¼šæ”¶é›†ä¿¡å·è®°å½•åˆ°å†…å­˜ï¼Œå¾ªç¯ç»“æŸåæ‰¹é‡å†™å…¥æ•°æ®åº“
                if task_id and all_signals:
                    try:
                        import uuid

                        # ä½¿ç”¨ä¼ å…¥çš„backtest_idæˆ–ç”Ÿæˆä¸€ä¸ªï¼ˆåªç”Ÿæˆä¸€æ¬¡ï¼‰
                        if _current_backtest_id is None:
                            _current_backtest_id = backtest_id or str(uuid.uuid4())

                        # æ„å»ºä¿¡å· lookup key â†’ index æ˜ å°„ï¼Œç”¨äºåç»­æ ‡è®° executed/execution_reason
                        for signal in all_signals:
                            signal_data = {
                                "signal_id": f"sig_{uuid.uuid4().hex[:12]}",
                                "stock_code": signal.stock_code,
                                "stock_name": None,
                                "signal_type": signal.signal_type.name,
                                "timestamp": signal.timestamp,
                                "price": signal.price,
                                "strength": signal.strength,
                                "reason": signal.reason,
                                "metadata": signal.metadata,
                                "executed": False,
                                "execution_reason": None,
                            }
                            _batch_signals_data.append(signal_data)
                    except Exception as e:
                        logger.warning(f"ä¿å­˜ä¿¡å·è®°å½•æ—¶å‡ºé”™: {e}")

                # æ‰§è¡Œäº¤æ˜“ä¿¡å·ï¼ˆæ€§èƒ½ç›‘æ§ï¼‰
                trade_start_time = (
                    time.perf_counter() if self.enable_performance_profiling else None
                )
                trades_this_day = 0
                executed_trade_signals = []  # è®°å½•å·²æ‰§è¡Œçš„äº¤æ˜“å¯¹åº”çš„ä¿¡å·
                unexecuted_signals = []  # è®°å½•æœªæ‰§è¡Œçš„ä¿¡å·åŠåŸå› 

                # ===== P0: ç†”æ–­è¿‡æ»¤ï¼ˆé˜»æ­¢ BUY ä¿¡å·ï¼Œä¿ç•™ SELLï¼‰ =====
                all_signals = risk_manager.filter_signals_by_circuit_breaker(
                    all_signals
                )

                # ===== trade execution mode =====
                trade_mode = None
                _topk_limit: int | None = None  # for post-trade sanity checks
                try:
                    trade_mode = (strategy_config or {}).get("trade_mode")
                except Exception:
                    trade_mode = None

                # --- debug aid: log which trade path is used (only when needed) ---
                try:
                    if current_date.strftime("%Y-%m-%d") in (
                        "2023-05-19",
                        "2023-05-22",
                        "2023-05-23",
                    ):
                        logger.info(
                            f"[trade_path] date={current_date.strftime('%Y-%m-%d')} trade_mode={trade_mode} "
                            f"signals={len(all_signals)} strategy_config_keys={list((strategy_config or {}).keys())}"
                        )
                except Exception:
                    pass

                if trade_mode == "topk_buffer":
                    # Daily TopK selection + buffer zone + max changes/day
                    k = int((strategy_config or {}).get("topk", 10))
                    _topk_limit = k
                    buffer_n = int((strategy_config or {}).get("buffer", 20))
                    max_changes = int(
                        (strategy_config or {}).get("max_changes_per_day", 2)
                    )
                    trades_limit = max_changes

                    # Build ranking scores from signals (BUY strength positive, SELL negative)
                    scores: Dict[str, float] = {code: 0.0 for code in stock_data.keys()}
                    for sig in all_signals:
                        s = float(sig.strength or 0.0)
                        if sig.signal_type == SignalType.BUY:
                            scores[sig.stock_code] = max(
                                scores.get(sig.stock_code, 0.0), s
                            )
                        elif sig.signal_type == SignalType.SELL:
                            scores[sig.stock_code] = min(
                                scores.get(sig.stock_code, 0.0), -s
                            )

                    # Rebalance according to TopK+buffer rules
                    min_buy_score = float(
                        (strategy_config or {}).get("min_buy_score", 0.0)
                    )
                    (
                        executed_trade_signals,
                        unexecuted_signals,
                        trades_this_day,
                    ) = self._rebalance_topk_buffer(
                        portfolio_manager=portfolio_manager,
                        current_prices=current_prices,
                        current_date=current_date,
                        scores=scores,
                        topk=k,
                        buffer_n=buffer_n,
                        max_changes=trades_limit,
                        strategy=strategy,
                        debug=bool(
                            (strategy_config or {}).get("debug_topk_buffer", False)
                        ),
                        min_buy_score=min_buy_score,
                    )

                    # Debug: show what was executed on key dates / when trades happen
                    try:
                        if trades_this_day > 0 or current_date.strftime("%Y-%m-%d") in (
                            "2023-05-22",
                        ):
                            logger.info(
                                f"[trade_exec][topk_buffer] date={current_date.strftime('%Y-%m-%d')} trades_this_day={trades_this_day} "
                                f"executed={len(executed_trade_signals)} unexecuted={len(unexecuted_signals)} holdings_after={len(portfolio_manager.positions)}"
                            )
                    except Exception:
                        pass

                else:
                    # P1ä¼˜åŒ–ï¼šæ¯æ—¥ç¼“å­˜ portfolio_value å’Œ positionsï¼Œé¿å…å¾ªç¯å†…é‡å¤è®¡ç®—
                    daily_portfolio_value = portfolio_manager.get_portfolio_value(
                        current_prices
                    )
                    daily_positions = portfolio_manager.positions

                    for signal in all_signals:
                        # éªŒè¯ä¿¡å·
                        is_valid, validation_reason = strategy.validate_signal(
                            signal,
                            daily_portfolio_value,
                            daily_positions,
                            entry_dates=getattr(portfolio_manager, "entry_dates", None),
                        )

                        if not is_valid:
                            # éªŒè¯å¤±è´¥ï¼Œè®°å½•æœªæ‰§è¡ŒåŸå› 
                            unexecuted_signals.append(
                                {
                                    "stock_code": signal.stock_code,
                                    "timestamp": signal.timestamp,
                                    "signal_type": signal.signal_type.name,
                                    "execution_reason": validation_reason or "ä¿¡å·éªŒè¯å¤±è´¥",
                                }
                            )
                            continue

                        # éªŒè¯é€šè¿‡ï¼Œå°è¯•æ‰§è¡Œ
                        trade_exec_start = (
                            time.perf_counter()
                            if self.enable_performance_profiling
                            else None
                        )
                        trade, failure_reason = portfolio_manager.execute_signal(
                            signal, current_prices
                        )
                        if self.enable_performance_profiling and trade_exec_start:
                            trade_exec_duration = time.perf_counter() - trade_exec_start
                            trade_execution_times.append(trade_exec_duration)
                            self.performance_profiler.record_function_call(
                                "execute_signal", trade_exec_duration
                            )

                        if trade:
                            executed_trades += 1
                            trades_this_day += 1
                            # è®°å½•å·²æ‰§è¡Œçš„ä¿¡å·ï¼Œç”¨äºåç»­æ ‡è®°
                            executed_trade_signals.append(
                                {
                                    "stock_code": signal.stock_code,
                                    "timestamp": signal.timestamp,
                                    "signal_type": signal.signal_type.name,
                                }
                            )
                        else:
                            # æ‰§è¡Œå¤±è´¥ï¼Œè®°å½•æœªæ‰§è¡ŒåŸå› ï¼ˆä» execute_signal ç›´æ¥è·å–ï¼‰
                            unexecuted_signals.append(
                                {
                                    "stock_code": signal.stock_code,
                                    "timestamp": signal.timestamp,
                                    "signal_type": signal.signal_type.name,
                                    "execution_reason": failure_reason or "æ‰§è¡Œå¤±è´¥ï¼ˆæœªçŸ¥åŸå› ï¼‰",
                                }
                            )

                # è®°å½•äº¤æ˜“æ‰§è¡Œæ€»æ—¶é—´
                if self.enable_performance_profiling and trade_start_time:
                    trade_duration = time.perf_counter() - trade_start_time
                    self.performance_profiler.record_function_call(
                        "execute_trades_batch", trade_duration
                    )

                # PERFä¼˜åŒ–ï¼šç›´æ¥åœ¨ _batch_signals_data ä¸­æ›´æ–° executed/execution_reason
                # é¿å…åç»­ UPDATE æ“ä½œï¼Œæ‰€æœ‰çŠ¶æ€åœ¨å†…å­˜ä¸­ä¸€æ¬¡æ€§ç¡®å®š
                if task_id and (executed_trade_signals or unexecuted_signals):
                    # æ„å»ºå½“å¤©ä¿¡å·çš„å¿«é€ŸæŸ¥æ‰¾ç´¢å¼•ï¼ˆä» _batch_signals_data å°¾éƒ¨å›æº¯ï¼‰
                    # å½“å¤©æ–°å¢çš„ä¿¡å·æ•°é‡ = len(all_signals)ï¼ˆåˆšåˆš append çš„ï¼‰
                    _today_start_idx = len(_batch_signals_data) - len(all_signals)
                    _today_lookup: Dict[tuple, int] = {}
                    for _si in range(_today_start_idx, len(_batch_signals_data)):
                        _sd = _batch_signals_data[_si]
                        _key = (_sd["stock_code"], _sd["signal_type"])
                        _today_lookup[_key] = _si

                    # æ ‡è®°å·²æ‰§è¡Œçš„ä¿¡å·
                    for _exec_sig in executed_trade_signals:
                        _key = (_exec_sig["stock_code"], _exec_sig["signal_type"])
                        _idx = _today_lookup.get(_key)
                        if _idx is not None:
                            _batch_signals_data[_idx]["executed"] = True
                            _batch_signals_data[_idx]["execution_reason"] = None

                    # æ ‡è®°æœªæ‰§è¡Œçš„ä¿¡å·åŠåŸå› 
                    for _unexec_sig in unexecuted_signals:
                        _key = (_unexec_sig["stock_code"], _unexec_sig["signal_type"])
                        _idx = _today_lookup.get(_key)
                        if _idx is not None:
                            _batch_signals_data[_idx]["executed"] = False
                            _batch_signals_data[_idx][
                                "execution_reason"
                            ] = _unexec_sig.get("execution_reason", "æœªçŸ¥åŸå› ")

                # å†…å­˜ä¼˜åŒ–ï¼šå½“ä¿¡å·ç§¯ç´¯è¶…è¿‡é˜ˆå€¼æ—¶ï¼Œä¸­é—´åˆ·å…¥DBå¹¶é‡Šæ”¾å†…å­˜
                if task_id and len(_batch_signals_data) >= _SIGNAL_FLUSH_THRESHOLD:
                    if signal_writer is not None:
                        # ä½¿ç”¨ StreamSignalWriter
                        signal_writer.buffer_many(_batch_signals_data)
                        signal_writer.flush()
                        _total_flushed_signals = signal_writer.total_written
                    else:
                        # å‘åå…¼å®¹ï¼šä½¿ç”¨æ—§è·¯å¾„
                        _flushed = self._flush_signals_to_db(
                            _batch_signals_data, task_id, _current_backtest_id
                        )
                        _total_flushed_signals += _flushed
                    _batch_signals_data.clear()

                # è®°å½•ç»„åˆå¿«ç…§
                portfolio_manager.record_portfolio_snapshot(
                    current_date, current_prices
                )

                # --- Sanity check (debug): topk_buffer must never exceed topk holdings ---
                # è¿™æ¡åªåšå‘Šè­¦ï¼Œä¸æ”¹å˜äº¤æ˜“è¡Œä¸ºï¼Œç”¨äºå®šä½"æŒä»“æ•°ä¸ºä½•ä¼š>topk"ã€‚
                try:
                    tm = None
                    k_limit = None
                    try:
                        tm = (strategy_config or {}).get("trade_mode")
                        k_limit = int((strategy_config or {}).get("topk", 10))
                    except Exception:
                        tm = None
                        k_limit = None

                    if tm == "topk_buffer" and k_limit is not None:
                        current_holdings = list(portfolio_manager.positions.keys())
                        if len(current_holdings) > int(k_limit):
                            logger.error(
                                f"[topk_buffer][sanity] positions_count={len(current_holdings)} > topk={k_limit} "
                                f"date={current_date.strftime('%Y-%m-%d')} holdings={sorted(current_holdings)}"
                            )
                except Exception as e:
                    logger.warning(f"[topk_buffer][sanity] check failed: {e}")

                # æ›´æ–°è¿›åº¦ç›‘æ§ï¼ˆä½¿ç”¨å†…å­˜ç¼“å­˜ï¼Œåªåœ¨å…³é”®èŠ‚ç‚¹å†™å…¥æ•°æ®åº“ï¼‰
                # æ€§èƒ½ä¼˜åŒ–: æ¯ä¸ªäº¤æ˜“æ—¥æ›´æ–°å†…å­˜ç¼“å­˜ï¼Œç¼“å­˜åˆ¤æ–­æ˜¯å¦éœ€è¦å†™ DBï¼ˆæ¯ 10% è¿›åº¦ï¼‰
                if task_id:
                    # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”ï¼ˆå›æµ‹æ‰§è¡Œé˜¶æ®µå 30-90%ï¼Œå³60%çš„è¿›åº¦èŒƒå›´ï¼‰
                    execution_progress = (i + 1) / len(trading_dates) * 100
                    overall_progress = 30 + (execution_progress / 100) * 60  # 30%åˆ°90%

                    # æ„å»ºè¿›åº¦æ•°æ®ï¼ˆå†…å­˜ä¸­å§‹ç»ˆä¿æŒæœ€æ–°ï¼‰
                    portfolio_value = portfolio_manager.get_portfolio_value(
                        current_prices
                    )
                    progress_update_data = {
                        "processed_days": i + 1,
                        "total_days": len(trading_dates),
                        "current_date": current_date.strftime("%Y-%m-%d"),
                        "signals_generated": len(all_signals),
                        "trades_executed": trades_this_day,
                        "total_signals": total_signals,
                        "total_trades": executed_trades,
                        "portfolio_value": portfolio_value,
                        "last_updated": datetime.utcnow().isoformat(),
                    }

                    # æ›´æ–°å†…å­˜ç¼“å­˜ï¼Œç”±ç¼“å­˜åˆ¤æ–­æ˜¯å¦éœ€è¦å†™ DB
                    from app.utils.task_progress_cache import task_progress_cache

                    should_flush = task_progress_cache.update_progress(
                        task_id=task_id,
                        progress=overall_progress,
                        result_data={"progress_data": progress_update_data},
                    )

                    if should_flush:
                        logger.debug(
                            f"å‡†å¤‡å†™å…¥è¿›åº¦åˆ°DB: task_id={task_id}, i={i}, "
                            f"total_days={len(trading_dates)}, progress={overall_progress:.1f}%"
                        )
                        try:
                            from app.core.database import SessionLocal
                            from app.models.task_models import TaskStatus
                            from app.repositories.task_repository import TaskRepository

                            session = SessionLocal()
                            try:
                                task_repo = TaskRepository(session)
                                existing_task = task_repo.get_task_by_id(task_id)
                                if not existing_task:
                                    logger.warning(f"ä»»åŠ¡ä¸å­˜åœ¨ï¼Œæ— æ³•æ›´æ–°è¿›åº¦: {task_id}")
                                    raise TaskError(
                                        message=f"ä»»åŠ¡ {task_id} å·²è¢«åˆ é™¤ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ",
                                        severity=ErrorSeverity.LOW,
                                    )
                                elif not _is_task_running(existing_task.status):
                                    logger.warning(
                                        f"ä»»åŠ¡çŠ¶æ€ä¸º {existing_task.status}ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ: {task_id}"
                                    )
                                    raise TaskError(
                                        message=f"ä»»åŠ¡ {task_id} çŠ¶æ€ä¸º {existing_task.status}ï¼Œåœæ­¢å›æµ‹æ‰§è¡Œ",
                                        severity=ErrorSeverity.LOW,
                                    )
                                else:
                                    result_data = existing_task.result or {}
                                    if not isinstance(result_data, dict):
                                        result_data = {}
                                    result_data["progress_data"] = progress_update_data

                                    task_repo.update_task_status(
                                        task_id=task_id,
                                        status=TaskStatus.RUNNING,
                                        progress=overall_progress,
                                        result=result_data,
                                    )
                                    session.commit()
                                    task_progress_cache.mark_flushed(task_id)
                                    logger.info(
                                        f"è¿›åº¦å·²å†™å…¥DB: task_id={task_id}, "
                                        f"progress={overall_progress:.1f}%, "
                                        f"days={i + 1}/{len(trading_dates)}"
                                    )
                            except Exception as inner_error:
                                session.rollback()
                                logger.error(
                                    f"æ›´æ–°ä»»åŠ¡è¿›åº¦åˆ°æ•°æ®åº“å¤±è´¥: {inner_error}",
                                    exc_info=True,
                                )
                                raise
                            finally:
                                session.close()
                        except TaskError:
                            raise
                        except Exception as db_error:
                            logger.error(f"æ›´æ–°ä»»åŠ¡è¿›åº¦åˆ°æ•°æ®åº“å¤±è´¥: {db_error}", exc_info=True)

                    # è¿›åº¦ç›‘æ§å·²é€šè¿‡åŒæ­¥DBå†™å…¥å®Œæˆï¼Œè·³è¿‡asyncè°ƒç”¨é¿å…å­è¿›ç¨‹æ­»é”

                # å®šæœŸè¾“å‡ºè¿›åº¦æ—¥å¿—
                if i % 50 == 0:
                    progress = (i + 1) / len(trading_dates) * 100
                    portfolio_value = portfolio_manager.get_portfolio_value(
                        current_prices
                    )
                    logger.debug(f"å›æµ‹è¿›åº¦: {progress:.1f}%, ç»„åˆä»·å€¼: {portfolio_value:.2f}")

            except Exception as e:
                error_msg = f"å›æµ‹å¾ªç¯é”™è¯¯ï¼Œæ—¥æœŸ: {current_date}, é”™è¯¯: {e}"
                logger.error(error_msg)

                # è­¦å‘Šå·²é€šè¿‡loggerè®°å½•ï¼Œè·³è¿‡asyncè°ƒç”¨é¿å…å­è¿›ç¨‹æ­»é”
                if task_id:
                    logger.warning(f"å›æµ‹è­¦å‘Š task={task_id}: {error_msg}")

                continue

        # ========== PERFä¼˜åŒ–ï¼šå¾ªç¯ç»“æŸåå†™å…¥å‰©ä½™ä¿¡å·æ•°æ® ==========
        if task_id and _batch_signals_data:
            if signal_writer is not None:
                signal_writer.buffer_many(_batch_signals_data)
                signal_writer.finalize()
                _total_flushed_signals = signal_writer.total_written
            else:
                _flushed = self._flush_signals_to_db(
                    _batch_signals_data, task_id, _current_backtest_id
                )
                _total_flushed_signals += _flushed
            _batch_signals_data.clear()
        elif task_id and signal_writer is not None:
            # ç¼“å†²åŒºä¸ºç©ºä½† signal_writer å¯èƒ½è¿˜æœ‰æœª finalize çš„æ•°æ®
            signal_writer.finalize()
            _total_flushed_signals = signal_writer.total_written

        if task_id and _total_flushed_signals > 0:
            logger.info(f"âœ… ä¿¡å·å†™å…¥å®Œæˆ: å…± {_total_flushed_signals} æ¡è®°å½•")
        # ========== END PERFä¼˜åŒ– ==========

        # æœ€ç»ˆè¿›åº¦æ›´æ–° + æ¸…ç†å†…å­˜ç¼“å­˜
        if task_id:
            from app.utils.task_progress_cache import task_progress_cache

            task_progress_cache.remove(task_id)

            final_portfolio_value = portfolio_manager.get_portfolio_value({})
            # è·³è¿‡async progress monitorè°ƒç”¨ï¼Œé¿å…å­è¿›ç¨‹æ­»é”
            logger.info(f"å›æµ‹å¾ªç¯å®Œæˆ task={task_id}, days={len(trading_dates)}, portfolio={final_portfolio_value:.2f}")

        # è®°å½•æ€§èƒ½ç»Ÿè®¡åˆ°æ€§èƒ½åˆ†æå™¨
        if self.enable_performance_profiling and self.performance_profiler:
            if signal_generation_times:
                avg_signal_time = sum(signal_generation_times) / len(
                    signal_generation_times
                )
                self.performance_profiler.end_stage(
                    "backtest_execution",
                    {
                        "avg_signal_generation_time": avg_signal_time,
                        "total_signal_generation_calls": len(signal_generation_times),
                    },
                )
            if trade_execution_times:
                avg_trade_time = sum(trade_execution_times) / len(trade_execution_times)
                self.performance_profiler.end_stage(
                    "backtest_execution",
                    {
                        "avg_trade_execution_time": avg_trade_time,
                        "total_trade_execution_calls": len(trade_execution_times),
                    },
                )

        return {
            "total_signals": total_signals,
            "executed_trades": executed_trades,
            "trading_days": len(trading_dates),
            "circuit_breaker_summary": risk_manager.get_circuit_breaker_summary(),
        }

    @staticmethod
    def _flush_signals_to_db(
        batch_signals_data: List[dict],
        task_id: str,
        backtest_id: str,
    ) -> int:
        """å°†ä¿¡å·æ•°æ®æ‰¹é‡å†™å…¥DBå¹¶è¿”å›å†™å…¥æ¡æ•°ã€‚

        å†…å­˜ä¼˜åŒ–ï¼šè°ƒç”¨æ–¹åœ¨ flush ååº” clear() åˆ—è¡¨é‡Šæ”¾å†…å­˜ã€‚
        ä½¿ç”¨ psycopg2 ç›´æ¥è¿æ¥ PostgreSQL æ‰¹é‡æ’å…¥ã€‚
        """
        if not batch_signals_data:
            return 0

        import json as _json

        import psycopg2
        import psycopg2.extras

        from app.core.config import settings as _settings

        count = len(batch_signals_data)

        try:
            # é¢„å¤„ç†æ•°æ®
            _insert_rows = []
            for _sd in batch_signals_data:
                _ts = _sd["timestamp"]
                _ts_str = _ts.isoformat() if hasattr(_ts, "isoformat") else str(_ts)

                _meta = _sd.get("metadata")
                _meta_str = None
                if _meta is not None:
                    try:
                        _meta_str = _json.dumps(_meta, ensure_ascii=False, default=str)
                    except Exception:
                        pass

                _insert_rows.append((
                    backtest_id,
                    _sd["signal_id"],
                    _sd["stock_code"],
                    _sd.get("stock_name"),
                    _sd["signal_type"],
                    _ts_str,
                    float(_sd["price"]),
                    float(_sd.get("strength", 0.0)),
                    _sd.get("reason"),
                    _meta_str,
                    True if _sd.get("executed") else False,
                    _sd.get("execution_reason"),
                ))

            # ä» DATABASE_URL æ„å»º psycopg2 è¿æ¥å­—ç¬¦ä¸²
            _dsn = _settings.database_url_sync

            _raw_insert_sql = """
                INSERT INTO signal_records
                    (backtest_id, signal_id, stock_code, stock_name,
                     signal_type, timestamp, price, strength, reason,
                     signal_metadata, executed, execution_reason)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            """

            _WRITE_BATCH_SIZE = 5000
            _max_retries = 3

            for _attempt in range(_max_retries + 1):
                try:
                    _conn = psycopg2.connect(_dsn)
                    try:
                        _cur = _conn.cursor()
                        for _bi in range(0, len(_insert_rows), _WRITE_BATCH_SIZE):
                            psycopg2.extras.execute_batch(
                                _cur,
                                _raw_insert_sql,
                                _insert_rows[_bi : _bi + _WRITE_BATCH_SIZE],
                            )
                        _conn.commit()
                        _cur.close()
                    finally:
                        _conn.close()
                    logger.debug(f"ä¿¡å·æ‰¹é‡å†™å…¥: {count} æ¡")
                    return count
                except Exception as e:
                    err_msg = str(e).lower()
                    if ("deadlock" in err_msg or "could not serialize" in err_msg) and _attempt < _max_retries:
                        time.sleep(0.5 * (2 ** _attempt))
                    else:
                        logger.error(f"ä¿¡å·å†™å…¥DBå¤±è´¥: {e}")
                        return 0
        except Exception as e:
            logger.error(f"ä¿¡å·å†™å…¥é¢„å¤„ç†å¤±è´¥: {e}")
            return 0

    def _rebalance_topk_buffer(
        self,
        portfolio_manager: PortfolioManager,
        current_prices: Dict[str, float],
        current_date: datetime,
        scores: Dict[str, float],
        topk: int = 10,
        buffer_n: int = 20,
        max_changes: int = 2,
        strategy: Optional[BaseStrategy] = None,
        debug: bool = False,
        min_buy_score: float = 0.0,
    ) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]], int]:
        """æ¯æ—¥ TopK é€‰è‚¡ + buffer æ¢ä»“ + æ¯å¤©æœ€å¤šæ¢ max_changes åªã€‚

        è§„åˆ™ï¼ˆå®ç›˜å¯¹é½ç‰ˆï¼‰ï¼š
        - ç›®æ ‡æŒä»“æ•°é‡=topk
        - è‹¥æŒä»“ä»åœ¨ Top(topk+buffer_n) å†…ï¼Œåˆ™å°½é‡ä¿ç•™ï¼ˆå‡å°‘æ¢æ‰‹ï¼‰
        - æ¯å¤©æœ€å¤šåš max_changes ä¸ª "å–å‡º+ä¹°å…¥" çš„æ›¿æ¢
        - min_buy_score: æœ€ä½ä¹°å…¥åˆ†æ•°é˜ˆå€¼ï¼Œä½äºæ­¤åˆ†æ•°çš„è‚¡ç¥¨ä¸ä¼šè¢«ä¹°å…¥ï¼ˆä½†å·²æŒæœ‰çš„å¯ä¿ç•™åœ¨bufferå†…ï¼‰

        Returns:
            executed_trade_signals, unexecuted_signals, trades_this_day
        """
        executed_trade_signals: List[Dict[str, Any]] = []
        unexecuted_signals: List[Dict[str, Any]] = []
        trades_this_day = 0

        if topk <= 0:
            return executed_trade_signals, unexecuted_signals, trades_this_day

        # rank by score desc, tie-break by stock_code for determinism
        ranked = sorted(scores.items(), key=lambda kv: (kv[1], kv[0]), reverse=True)
        # è¿‡æ»¤ï¼šåªæœ‰åˆ†æ•° > min_buy_score çš„è‚¡ç¥¨æ‰èƒ½è¿›å…¥ topk å€™é€‰
        qualified = [(c, s) for c, s in ranked if s > min_buy_score]
        effective_topk = min(topk, len(qualified))
        topk_list = [c for c, _ in qualified[:effective_topk]]
        # buffer ä»ç„¶åŸºäºå…¨æ’åï¼ˆå·²æŒæœ‰çš„ä½åˆ†è‚¡ç¥¨å¯ä»¥åœ¨ buffer å†…ä¿ç•™ï¼Œé¿å…é¢‘ç¹å–å‡ºï¼‰
        buffer_list = [c for c, _ in ranked[: max(topk, topk + buffer_n)]]
        buffer_set = set(buffer_list)

        holdings = list(portfolio_manager.positions.keys())

        # Keep holdings inside buffer zone, but force-sell if score is actively negative
        score_map = dict(ranked)
        kept = [c for c in holdings if c in buffer_set and score_map.get(c, 0.0) >= -min_buy_score]

        # If kept > topk, trim lowest-ranked among kept
        rank_index = {c: i for i, (c, _) in enumerate(ranked)}
        if len(kept) > topk:
            kept_sorted = sorted(kept, key=lambda c: rank_index.get(c, 10**9))
            kept = kept_sorted[:topk]

        kept_set = set(kept)

        # Sell candidates: holdings outside buffer OR trimmed OR actively bearish
        to_sell = [c for c in holdings if c not in kept_set]

        # Buy candidates: topk names not already kept
        to_buy = [c for c in topk_list if c not in kept_set]

        # ç‹¬ç«‹é™åˆ¶å–å‡ºå’Œä¹°å…¥ï¼ˆä¿®å¤ï¼šä¹°å–è€¦åˆå¯¼è‡´åˆå§‹å»ºä»“å¤±è´¥ï¼‰
        n_sell = min(max_changes, len(to_sell))
        n_buy = min(max_changes, len(to_buy))

        # åˆå§‹å»ºä»“ï¼šholdings ä¸ºç©ºæ—¶ï¼Œå…è®¸ç›´æ¥ä¹°å…¥ topk åªè‚¡ç¥¨
        if not holdings:
            n_buy = min(topk, len(to_buy))

        to_sell = to_sell[:n_sell]
        to_buy = to_buy[:n_buy]

        # Execute sells first
        for code in to_sell:
            sig = TradingSignal(
                timestamp=current_date,
                stock_code=code,
                signal_type=SignalType.SELL,
                strength=1.0,
                price=float(current_prices.get(code, 0.0) or 0.0),
                reason="topk_buffer rebalance sell (out of buffer/topk)",
                metadata={"trade_mode": "topk_buffer"},
            )
            if strategy is not None:
                is_valid, validation_reason = strategy.validate_signal(
                    sig,
                    portfolio_manager.get_portfolio_value(current_prices),
                    portfolio_manager.positions,
                    entry_dates=getattr(portfolio_manager, "entry_dates", None),
                )
                if not is_valid:
                    unexecuted_signals.append(
                        {
                            "stock_code": code,
                            "timestamp": current_date,
                            "signal_type": sig.signal_type.name,
                            "execution_reason": validation_reason or "ä¿¡å·éªŒè¯å¤±è´¥",
                        }
                    )
                    continue

            trade, failure_reason = portfolio_manager.execute_signal(
                sig, current_prices
            )
            if trade:
                trades_this_day += 1
                executed_trade_signals.append(
                    {
                        "stock_code": code,
                        "timestamp": current_date,
                        "signal_type": sig.signal_type.name,
                    }
                )
            else:
                unexecuted_signals.append(
                    {
                        "stock_code": code,
                        "timestamp": current_date,
                        "signal_type": sig.signal_type.name,
                        "execution_reason": failure_reason or "æ‰§è¡Œå¤±è´¥ï¼ˆæœªçŸ¥åŸå› ï¼‰",
                    }
                )

        # Execute buys
        for code in to_buy:
            sig = TradingSignal(
                timestamp=current_date,
                stock_code=code,
                signal_type=SignalType.BUY,
                strength=1.0,
                price=float(current_prices.get(code, 0.0) or 0.0),
                reason=f"topk_buffer rebalance buy (enter top{topk})",
                metadata={"trade_mode": "topk_buffer"},
            )
            if strategy is not None:
                is_valid, validation_reason = strategy.validate_signal(
                    sig,
                    portfolio_manager.get_portfolio_value(current_prices),
                    portfolio_manager.positions,
                    entry_dates=getattr(portfolio_manager, "entry_dates", None),
                )
                if not is_valid:
                    unexecuted_signals.append(
                        {
                            "stock_code": code,
                            "timestamp": current_date,
                            "signal_type": sig.signal_type.name,
                            "execution_reason": validation_reason or "ä¿¡å·éªŒè¯å¤±è´¥",
                        }
                    )
                    continue

            trade, failure_reason = portfolio_manager.execute_signal(
                sig, current_prices
            )
            if trade:
                trades_this_day += 1
                executed_trade_signals.append(
                    {
                        "stock_code": code,
                        "timestamp": current_date,
                        "signal_type": sig.signal_type.name,
                    }
                )
            else:
                unexecuted_signals.append(
                    {
                        "stock_code": code,
                        "timestamp": current_date,
                        "signal_type": sig.signal_type.name,
                        "execution_reason": failure_reason or "æ‰§è¡Œå¤±è´¥ï¼ˆæœªçŸ¥åŸå› ï¼‰",
                    }
                )

        return executed_trade_signals, unexecuted_signals, trades_this_day

"""
å¤šè¿›ç¨‹å¹¶è¡Œå›æµ‹æ‰§è¡Œå™¨ - Phase 4 ä¼˜åŒ–

æ ¸å¿ƒæ€è·¯ï¼š
1. å°† 500 åªè‚¡ç¥¨åˆ†é…åˆ°å¤šä¸ªè¿›ç¨‹ï¼ˆ8æ ¸ CPUï¼‰
2. æ¯ä¸ªè¿›ç¨‹ç‹¬ç«‹æ‰§è¡Œå›æµ‹ï¼ˆçªç ´ GIL é™åˆ¶ï¼‰
3. æœ€ååˆå¹¶ç»“æœ

é¢„æœŸåŠ é€Ÿï¼š5-6x
"""

import multiprocessing as mp
import time
from datetime import datetime
from typing import Any, Dict, List, Optional, Tuple

import numpy as np
import pandas as pd
from loguru import logger

from ..core.base_strategy import BaseStrategy
from ..core.portfolio_manager_array import PortfolioManagerArray
from ..models import BacktestConfig, SignalType, TradingSignal


def _worker_backtest(
    worker_id: int,
    stock_codes: List[str],
    stock_data_serialized: Dict[str, Dict],
    trading_dates_list: List[str],
    strategy_info: Dict[str, Any],
    backtest_config_dict: Dict[str, Any],
) -> Dict[str, Any]:
    """
    Worker è¿›ç¨‹æ‰§è¡Œå›æµ‹
    
    Args:
        worker_id: Worker ID
        stock_codes: åˆ†é…ç»™è¯¥ worker çš„è‚¡ç¥¨åˆ—è¡¨
        stock_data_serialized: åºåˆ—åŒ–çš„è‚¡ç¥¨æ•°æ®
        trading_dates_list: äº¤æ˜“æ—¥æœŸåˆ—è¡¨ï¼ˆå­—ç¬¦ä¸²æ ¼å¼ï¼‰
        strategy_info: ç­–ç•¥é…ç½®ä¿¡æ¯
        backtest_config_dict: å›æµ‹é…ç½®å­—å…¸
        
    Returns:
        å›æµ‹ç»“æœå­—å…¸
    """
    try:
        # 1. é‡å»ºæ•°æ®ç»“æ„
        stock_data = {}
        for code in stock_codes:
            data_dict = stock_data_serialized[code]
            df = pd.DataFrame(data_dict['values'], columns=data_dict['columns'])
            df.index = pd.to_datetime(data_dict['index'])
            df.attrs['stock_code'] = code
            stock_data[code] = df
        
        trading_dates = [pd.to_datetime(d) for d in trading_dates_list]
        
        # 2. é‡å»ºç­–ç•¥
        from ..strategies.strategy_factory import StrategyFactory, AdvancedStrategyFactory
        
        strategy_name = strategy_info['name']
        strategy_config = strategy_info['config']
        
        strategy = None
        try:
            strategy = AdvancedStrategyFactory.create_strategy(strategy_name, strategy_config)
        except Exception:
            strategy = StrategyFactory.create_strategy(strategy_name, strategy_config)
        
        # 3. é‡å»ºå›æµ‹é…ç½®
        config = BacktestConfig(**backtest_config_dict)
        
        # 4. åˆ›å»ºç»„åˆç®¡ç†å™¨
        portfolio_manager = PortfolioManagerArray(config, stock_codes)
        
        # 5. é¢„è®¡ç®—ä¿¡å·ï¼ˆå‘é‡åŒ–ï¼‰
        logger.info(f"Worker {worker_id}: å¼€å§‹é¢„è®¡ç®—ä¿¡å·ï¼Œè‚¡ç¥¨æ•°: {len(stock_codes)}")
        precompute_start = time.perf_counter()
        
        for code, data in stock_data.items():
            try:
                signals = strategy.precompute_all_signals(data)
                if signals is not None:
                    cache = data.attrs.setdefault("_precomputed_signals", {})
                    cache[id(strategy)] = signals
            except Exception as e:
                logger.warning(f"Worker {worker_id}: é¢„è®¡ç®—ä¿¡å·å¤±è´¥ {code}: {e}")
        
        precompute_time = time.perf_counter() - precompute_start
        logger.info(f"Worker {worker_id}: é¢„è®¡ç®—å®Œæˆï¼Œè€—æ—¶ {precompute_time:.2f}ç§’")
        
        # 6. æ‰§è¡Œå›æµ‹ä¸»å¾ªç¯
        logger.info(f"Worker {worker_id}: å¼€å§‹å›æµ‹ä¸»å¾ªç¯ï¼Œäº¤æ˜“æ—¥: {len(trading_dates)}")
        loop_start = time.perf_counter()
        
        total_signals = 0
        executed_trades = 0
        
        for i, current_date in enumerate(trading_dates):
            # è·å–å½“å‰ä»·æ ¼
            current_prices = {}
            for code, data in stock_data.items():
                if current_date in data.index:
                    try:
                        idx = data.index.get_loc(current_date)
                        current_prices[code] = float(data['close'].iloc[idx])
                    except Exception:
                        pass
            
            if not current_prices:
                continue
            
            # ç”Ÿæˆäº¤æ˜“ä¿¡å·ï¼ˆä¼˜å…ˆä½¿ç”¨é¢„è®¡ç®—ï¼‰
            all_signals = []
            strategy_id = id(strategy)
            
            for code, data in stock_data.items():
                if current_date not in data.index:
                    continue
                
                try:
                    idx = data.index.get_loc(current_date)
                    if idx < 20:  # è·³è¿‡é¢„çƒ­æœŸ
                        continue
                    
                    # ä»é¢„è®¡ç®—ç¼“å­˜è¯»å–ä¿¡å·
                    precomputed = data.attrs.get("_precomputed_signals", {})
                    sig_series = precomputed.get(strategy_id)
                    
                    if sig_series is not None and current_date in sig_series.index:
                        sig_type = sig_series.loc[current_date]
                        if isinstance(sig_type, SignalType):
                            price = current_prices.get(code, 0.0)
                            signal = TradingSignal(
                                timestamp=current_date,
                                stock_code=code,
                                signal_type=sig_type,
                                strength=0.8,
                                price=price,
                                reason=f"Precomputed signal",
                                metadata={}
                            )
                            all_signals.append(signal)
                except Exception as e:
                    logger.warning(f"Worker {worker_id}: ç”Ÿæˆä¿¡å·å¤±è´¥ {code}: {e}")
            
            total_signals += len(all_signals)
            
            # æ‰§è¡Œäº¤æ˜“
            for signal in all_signals:
                # éªŒè¯ä¿¡å·
                is_valid, _ = strategy.validate_signal(
                    signal,
                    portfolio_manager.get_portfolio_value(current_prices),
                    portfolio_manager.positions,
                )
                
                if is_valid:
                    trade, _ = portfolio_manager.execute_signal(signal, current_prices)
                    if trade:
                        executed_trades += 1
            
            # è®°å½•ç»„åˆå¿«ç…§
            portfolio_manager.record_portfolio_snapshot(current_date, current_prices)
            
            # å®šæœŸè¾“å‡ºè¿›åº¦
            if i % 50 == 0 and i > 0:
                progress = (i + 1) / len(trading_dates) * 100
                logger.info(f"Worker {worker_id}: è¿›åº¦ {progress:.1f}%")
        
        loop_time = time.perf_counter() - loop_start
        logger.info(f"Worker {worker_id}: å›æµ‹å®Œæˆï¼Œè€—æ—¶ {loop_time:.2f}ç§’")
        
        # 7. è®¡ç®—ç»©æ•ˆæŒ‡æ ‡
        performance_metrics = portfolio_manager.get_performance_metrics()
        
        # 8. è¿”å›ç»“æœ
        result = {
            'worker_id': worker_id,
            'stock_codes': stock_codes,
            'total_signals': total_signals,
            'executed_trades': executed_trades,
            'trading_days': len(trading_dates),
            'performance_metrics': performance_metrics,
            'equity_curve': portfolio_manager.equity_curve,
            'trades': portfolio_manager.trades,
            'final_cash': portfolio_manager.cash,
            'final_positions': {
                code: {
                    'quantity': int(portfolio_manager.quantities[i]),
                    'avg_cost': float(portfolio_manager.avg_costs[i]),
                }
                for i, code in enumerate(stock_codes)
                if portfolio_manager.quantities[i] > 0
            },
            'timing': {
                'precompute_time': precompute_time,
                'loop_time': loop_time,
                'total_time': precompute_time + loop_time,
            }
        }
        
        logger.info(f"Worker {worker_id}: è¿”å›ç»“æœï¼Œä¿¡å·æ•°: {total_signals}, äº¤æ˜“æ•°: {executed_trades}")
        return result
        
    except Exception as e:
        logger.error(f"Worker {worker_id} æ‰§è¡Œå¤±è´¥: {e}", exc_info=True)
        return {
            'worker_id': worker_id,
            'error': str(e),
            'stock_codes': stock_codes,
        }


def run_multiprocess_backtest(
    strategy_name: str,
    stock_codes: List[str],
    start_date: datetime,
    end_date: datetime,
    strategy_config: Dict[str, Any],
    backtest_config: Optional[BacktestConfig] = None,
    num_workers: Optional[int] = None,
    data_dir: Optional[str] = None,
) -> Dict[str, Any]:
    """
    å¤šè¿›ç¨‹å¹¶è¡Œå›æµ‹
    
    Args:
        strategy_name: ç­–ç•¥åç§°
        stock_codes: è‚¡ç¥¨ä»£ç åˆ—è¡¨
        start_date: å¼€å§‹æ—¥æœŸ
        end_date: ç»“æŸæ—¥æœŸ
        strategy_config: ç­–ç•¥é…ç½®
        backtest_config: å›æµ‹é…ç½®
        num_workers: å·¥ä½œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤ä½¿ç”¨ CPU æ ¸å¿ƒæ•°ï¼‰
        data_dir: æ•°æ®ç›®å½•ï¼ˆç»å¯¹è·¯å¾„ï¼Œå¯é€‰ï¼‰
        
    Returns:
        åˆå¹¶åçš„å›æµ‹ç»“æœ
    """
    total_start = time.perf_counter()
    
    # 1. ç¡®å®šï¿½ï¿½ï¿½ä½œè¿›ç¨‹æ•°
    if num_workers is None:
        num_workers = min(mp.cpu_count(), 8)  # æœ€å¤š 8 ä¸ªè¿›ç¨‹
    
    logger.info(f"ğŸš€ å¯åŠ¨å¤šè¿›ç¨‹å›æµ‹: {num_workers} ä¸ªè¿›ç¨‹, {len(stock_codes)} åªè‚¡ç¥¨")
    
    # 2. ä½¿ç”¨é»˜è®¤é…ç½®
    if backtest_config is None:
        backtest_config = BacktestConfig()
    
    # 3. åŠ è½½æ•°æ®
    logger.info("ğŸ“Š åŠ è½½è‚¡ç¥¨æ•°æ®...")
    data_load_start = time.perf_counter()
    
    from .data_loader import DataLoader
    # ä½¿ç”¨ä¼ å…¥çš„æ•°æ®ç›®å½•æˆ–é»˜è®¤ç»å¯¹è·¯å¾„
    if data_dir is None:
        data_dir = "/Users/ronghui/Projects/willrone/data"
    
    logger.info(f"æ•°æ®ç›®å½•: {data_dir}")
    data_loader = DataLoader(data_dir=data_dir, max_workers=num_workers)
    stock_data = data_loader.load_multiple_stocks(stock_codes, start_date, end_date)
    
    data_load_time = time.perf_counter() - data_load_start
    logger.info(f"âœ… æ•°æ®åŠ è½½å®Œæˆ: {len(stock_data)} åªè‚¡ç¥¨, è€—æ—¶ {data_load_time:.2f}ç§’")
    
    # 4. è·å–äº¤æ˜“æ—¥å†
    all_dates = set()
    for data in stock_data.values():
        all_dates.update(data.index.tolist())
    trading_dates = sorted([date for date in all_dates if start_date <= date <= end_date])
    
    logger.info(f"ğŸ“… äº¤æ˜“æ—¥å†: {len(trading_dates)} å¤©")
    
    # 5. åºåˆ—åŒ–æ•°æ®ï¼ˆå‡†å¤‡ä¼ é€’ç»™å­è¿›ç¨‹ï¼‰
    logger.info("ğŸ”„ åºåˆ—åŒ–æ•°æ®...")
    serialize_start = time.perf_counter()
    
    stock_data_serialized = {}
    for code, data in stock_data.items():
        stock_data_serialized[code] = {
            'values': data.values.tolist(),
            'columns': data.columns.tolist(),
            'index': [str(d) for d in data.index],
            'stock_code': code,
        }
    
    trading_dates_list = [str(d) for d in trading_dates]
    
    serialize_time = time.perf_counter() - serialize_start
    logger.info(f"âœ… åºåˆ—åŒ–å®Œæˆ, è€—æ—¶ {serialize_time:.2f}ç§’")
    
    # 6. åˆ†é…è‚¡ç¥¨åˆ°å„ä¸ªè¿›ç¨‹ï¼ˆè´Ÿè½½å‡è¡¡ï¼‰
    actual_stock_codes = list(stock_data.keys())
    stocks_per_worker = len(actual_stock_codes) // num_workers
    stock_assignments = []
    
    for i in range(num_workers):
        start_idx = i * stocks_per_worker
        if i == num_workers - 1:
            # æœ€åä¸€ä¸ªè¿›ç¨‹å¤„ç†å‰©ä½™çš„æ‰€æœ‰è‚¡ç¥¨
            end_idx = len(actual_stock_codes)
        else:
            end_idx = (i + 1) * stocks_per_worker
        
        assigned_stocks = actual_stock_codes[start_idx:end_idx]
        stock_assignments.append(assigned_stocks)
        logger.info(f"Worker {i}: {len(assigned_stocks)} åªè‚¡ç¥¨")
    
    # 7. å‡†å¤‡ç­–ç•¥å’Œé…ç½®ä¿¡æ¯
    strategy_info = {
        'name': strategy_name,
        'config': strategy_config,
    }
    
    backtest_config_dict = {
        'initial_cash': backtest_config.initial_cash,
        'commission_rate': backtest_config.commission_rate,
        'slippage_rate': backtest_config.slippage_rate,
        'max_position_size': backtest_config.max_position_size,
    }
    
    # 8. å¯åŠ¨å¤šè¿›ç¨‹æ‰§è¡Œ
    logger.info("ğŸš€ å¯åŠ¨å¤šè¿›ç¨‹å›æµ‹...")
    mp_start = time.perf_counter()
    
    # ä½¿ç”¨ spawn æ–¹æ³•ï¼ˆæ›´å®‰å…¨ï¼Œé¿å… fork é—®é¢˜ï¼‰
    ctx = mp.get_context('spawn')
    
    with ctx.Pool(processes=num_workers) as pool:
        # å‡†å¤‡ä»»åŠ¡å‚æ•°
        tasks = [
            (
                i,
                stock_assignments[i],
                stock_data_serialized,
                trading_dates_list,
                strategy_info,
                backtest_config_dict,
            )
            for i in range(num_workers)
        ]
        
        # å¹¶è¡Œæ‰§è¡Œ
        results = pool.starmap(_worker_backtest, tasks)
    
    mp_time = time.perf_counter() - mp_start
    logger.info(f"âœ… å¤šè¿›ç¨‹æ‰§è¡Œå®Œæˆ, è€—æ—¶ {mp_time:.2f}ç§’")
    
    # 9. åˆå¹¶ç»“æœ
    logger.info("ğŸ”„ åˆå¹¶ç»“æœ...")
    merge_start = time.perf_counter()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯
    errors = [r for r in results if 'error' in r]
    if errors:
        logger.error(f"âŒ {len(errors)} ä¸ªè¿›ç¨‹æ‰§è¡Œå¤±è´¥:")
        for err in errors:
            logger.error(f"  Worker {err['worker_id']}: {err['error']}")
    
    # åˆå¹¶æˆåŠŸçš„ç»“æœ
    successful_results = [r for r in results if 'error' not in r]
    
    if not successful_results:
        raise RuntimeError("æ‰€æœ‰è¿›ç¨‹éƒ½æ‰§è¡Œå¤±è´¥")
    
    # åˆå¹¶ç»Ÿè®¡æ•°æ®
    total_signals = sum(r['total_signals'] for r in successful_results)
    total_trades = sum(r['executed_trades'] for r in successful_results)
    
    # åˆå¹¶æƒç›Šæ›²çº¿ï¼ˆå¹³å‡å„è¿›ç¨‹çš„æ”¶ç›Šç‡ï¼‰
    all_equity_curves = [r['equity_curve'] for r in successful_results]
    merged_equity_curve = []
    
    if all_equity_curves:
        # æŒ‰æ—¥æœŸå¯¹é½å¹¶è®¡ç®—å¹³å‡å€¼
        date_to_values = {}
        for curve in all_equity_curves:
            for date, value in curve:
                if date not in date_to_values:
                    date_to_values[date] = []
                date_to_values[date].append(value)
        
        # è®¡ç®—æ¯æ—¥å¹³å‡ä»·å€¼ï¼ˆè€Œä¸æ˜¯æ±‚å’Œï¼‰
        for date in sorted(date_to_values.keys()):
            avg_value = sum(date_to_values[date]) / len(date_to_values[date])
            merged_equity_curve.append((date, avg_value))
    
    # åˆå¹¶äº¤æ˜“è®°å½•
    all_trades = []
    for r in successful_results:
        all_trades.extend(r['trades'])
    
    # è®¡ç®—åˆå¹¶åçš„ç»©æ•ˆæŒ‡æ ‡
    if merged_equity_curve:
        values = [v for _, v in merged_equity_curve]
        returns = pd.Series(values).pct_change().dropna()
        
        total_return = (values[-1] - backtest_config.initial_cash) / backtest_config.initial_cash
        
        days = (merged_equity_curve[-1][0] - merged_equity_curve[0][0]).days
        annualized_return = (1 + total_return) ** (365 / max(days, 1)) - 1 if days > 0 else 0
        
        volatility = returns.std() * np.sqrt(252)
        sharpe_ratio = annualized_return / volatility if volatility > 0 else 0
        
        cumulative_returns = (1 + returns).cumprod()
        running_max = cumulative_returns.expanding().max()
        drawdown = (cumulative_returns - running_max) / running_max
        max_drawdown = drawdown.min()
        
        merged_metrics = {
            'total_return': float(total_return),
            'annualized_return': float(annualized_return),
            'volatility': float(volatility),
            'sharpe_ratio': float(sharpe_ratio),
            'max_drawdown': float(max_drawdown),
            'total_trades': len(all_trades),
        }
    else:
        merged_metrics = {}
    
    merge_time = time.perf_counter() - merge_start
    total_time = time.perf_counter() - total_start
    
    logger.info(f"âœ… ç»“æœåˆå¹¶å®Œæˆ, è€—æ—¶ {merge_time:.2f}ç§’")
    logger.info(f"ğŸ‰ å¤šè¿›ç¨‹å›æµ‹å®Œæˆ! æ€»è€—æ—¶: {total_time:.2f}ç§’")
    logger.info(f"ğŸ“Š ç»Ÿè®¡: ä¿¡å·æ•° {total_signals}, äº¤æ˜“æ•° {total_trades}")
    logger.info(f"ğŸ’° æ€»æ”¶ç›Šç‡: {merged_metrics.get('total_return', 0):.2%}")
    
    # 10. è¿”å›ç»“æœ
    result = {
        'strategy_name': strategy_name,
        'stock_codes': actual_stock_codes,
        'start_date': start_date.isoformat(),
        'end_date': end_date.isoformat(),
        'total_signals': total_signals,
        'executed_trades': total_trades,
        'trading_days': len(trading_dates),
        'performance_metrics': merged_metrics,
        'equity_curve': merged_equity_curve,
        'trades': all_trades,
        'worker_results': successful_results,
        'perf_breakdown': {
            'data_loading_s': data_load_time,
            'serialize_s': serialize_time,
            'multiprocess_s': mp_time,
            'merge_s': merge_time,
            'total_wall_s': total_time,
        },
        'num_workers': num_workers,
    }
    
    return result
